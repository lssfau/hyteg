/*
 * Copyright (c) 2017-2024 Nils Kohl, Daniel Bauer, Fabian BÃ¶hm.
 *
 * This file is part of HyTeG
 * (see https://i10git.cs.fau.de/hyteg/hyteg).
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program. If not, see <http://www.gnu.org/licenses/>.
 */

/*
 * The entire file was generated with the HyTeG Operator Generator.
 *
 * Avoid modifying this file. If buggy, consider fixing the generator itself.
 */

// Unfortunately, the inverse diagonal kernel wrapper triggers a GCC bug (maybe
// (related to) https://gcc.gnu.org/bugzilla/show_bug.cgi?id=107087) causing a
// warning in an internal standard library header (bits/stl_algobase.h). As a
// workaround, we disable the warning and include this header indirectly through
// a public header.
#include <waLBerlaDefinitions.h>
#ifdef WALBERLA_CXX_COMPILER_IS_GNU
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wnonnull"
#endif
#include <cmath>
#ifdef WALBERLA_CXX_COMPILER_IS_GNU
#pragma GCC diagnostic pop
#endif

#include "P1ElementwiseDivKGrad_cubes_const_vect_fused_quadloops_tab.hpp"

#define FUNC_PREFIX

using std::max;

namespace hyteg {

namespace operatorgeneration {

P1ElementwiseDivKGrad_cubes_const_vect_fused_quadloops_tab::
    P1ElementwiseDivKGrad_cubes_const_vect_fused_quadloops_tab(
        const std::shared_ptr<PrimitiveStorage> &storage, size_t minLevel,
        size_t maxLevel, const P1Function<double> &_k)
    : Operator(storage, minLevel, maxLevel), k(_k) {}

void P1ElementwiseDivKGrad_cubes_const_vect_fused_quadloops_tab::apply(
    const P1Function<double> &src, const P1Function<double> &dst, uint_t level,
    DoFType flag, UpdateType updateType) const {
  this->startTiming("apply");

  // Make sure that halos are up-to-date
  this->timingTree_->start("pre-communication");
  if (this->storage_->hasGlobalCells()) {
    // Note that the order of communication is important, since the face -> cell
    // communication may overwrite parts of the halos that carry the
    // macro-vertex and macro-edge unknowns.
    src.communicate<Face, Cell>(level);
    src.communicate<Edge, Cell>(level);
    src.communicate<Vertex, Cell>(level);
    k.communicate<Face, Cell>(level);
    k.communicate<Edge, Cell>(level);
    k.communicate<Vertex, Cell>(level);
  } else {
    communication::syncFunctionBetweenPrimitives(
        src, level, communication::syncDirection_t::LOW2HIGH);
    communication::syncFunctionBetweenPrimitives(
        k, level, communication::syncDirection_t::LOW2HIGH);
  }
  this->timingTree_->stop("pre-communication");

  if (updateType == Replace) {
    // We need to zero the destination array (including halos).
    // However, we must not zero out anything that is not flagged with the
    // specified BCs. Therefore, we first zero out everything that flagged, and
    // then, later, the halos of the highest dim primitives.
    dst.interpolate(walberla::numeric_cast<double>(0), level, flag);
  }

  if (storage_->hasGlobalCells()) {
    for (auto &it : storage_->getCells()) {
      Cell &cell = *it.second;

      // get hold of the actual numerical data in the functions
      double *_data_src = cell.getData(src.getCellDataID())->getPointer(level);
      double *_data_dst = cell.getData(dst.getCellDataID())->getPointer(level);
      double *_data_k = cell.getData(k.getCellDataID())->getPointer(level);

      // Zero out dst halos only
      //
      // This is also necessary when using update type == Add.
      // During additive comm we then skip zeroing the data on the lower-dim
      // primitives.
      for (const auto &idx : vertexdof::macrocell::Iterator(level)) {
        if (!vertexdof::macrocell::isOnCellFace(idx, level).empty()) {
          auto arrayIdx =
              vertexdof::macrocell::index(level, idx.x(), idx.y(), idx.z());
          _data_dst[arrayIdx] = double(0);
        }
      }

      const auto micro_edges_per_macro_edge =
          (int64_t)levelinfo::num_microedges_per_edge(level);
      const auto num_microfaces_per_face =
          (int64_t)levelinfo::num_microfaces_per_face(level);
      const auto micro_edges_per_macro_edge_float =
          (double)levelinfo::num_microedges_per_edge(level);
      const double macro_vertex_coord_id_0comp0 =
          (double)cell.getCoordinates()[0][0];
      const double macro_vertex_coord_id_0comp1 =
          (double)cell.getCoordinates()[0][1];
      const double macro_vertex_coord_id_0comp2 =
          (double)cell.getCoordinates()[0][2];
      const double macro_vertex_coord_id_1comp0 =
          (double)cell.getCoordinates()[1][0];
      const double macro_vertex_coord_id_1comp1 =
          (double)cell.getCoordinates()[1][1];
      const double macro_vertex_coord_id_1comp2 =
          (double)cell.getCoordinates()[1][2];
      const double macro_vertex_coord_id_2comp0 =
          (double)cell.getCoordinates()[2][0];
      const double macro_vertex_coord_id_2comp1 =
          (double)cell.getCoordinates()[2][1];
      const double macro_vertex_coord_id_2comp2 =
          (double)cell.getCoordinates()[2][2];
      const double macro_vertex_coord_id_3comp0 =
          (double)cell.getCoordinates()[3][0];
      const double macro_vertex_coord_id_3comp1 =
          (double)cell.getCoordinates()[3][1];
      const double macro_vertex_coord_id_3comp2 =
          (double)cell.getCoordinates()[3][2];

      this->timingTree_->start("kernel");

      apply_P1ElementwiseDivKGrad_cubes_const_vect_fused_quadloops_tab_macro_3D(

          _data_dst, _data_k, _data_src, macro_vertex_coord_id_0comp0,
          macro_vertex_coord_id_0comp1, macro_vertex_coord_id_0comp2,
          macro_vertex_coord_id_1comp0, macro_vertex_coord_id_1comp1,
          macro_vertex_coord_id_1comp2, macro_vertex_coord_id_2comp0,
          macro_vertex_coord_id_2comp1, macro_vertex_coord_id_2comp2,
          macro_vertex_coord_id_3comp0, macro_vertex_coord_id_3comp1,
          macro_vertex_coord_id_3comp2, micro_edges_per_macro_edge,
          micro_edges_per_macro_edge_float);

      this->timingTree_->stop("kernel");
    }

    // Push result to lower-dimensional primitives
    //
    this->timingTree_->start("post-communication");
    // Note: We could avoid communication here by implementing the apply() also
    // for the respective
    //       lower dimensional primitives!
    dst.communicateAdditively<Cell, Face>(level, DoFType::All ^ flag, *storage_,
                                          updateType == Replace);
    dst.communicateAdditively<Cell, Edge>(level, DoFType::All ^ flag, *storage_,
                                          updateType == Replace);
    dst.communicateAdditively<Cell, Vertex>(level, DoFType::All ^ flag,
                                            *storage_, updateType == Replace);
    this->timingTree_->stop("post-communication");
  } else {
    for (auto &it : storage_->getFaces()) {
      Face &face = *it.second;

      // get hold of the actual numerical data in the functions
      double *_data_src = face.getData(src.getFaceDataID())->getPointer(level);
      double *_data_dst = face.getData(dst.getFaceDataID())->getPointer(level);
      double *_data_k = face.getData(k.getFaceDataID())->getPointer(level);

      // Zero out dst halos only
      //
      // This is also necessary when using update type == Add.
      // During additive comm we then skip zeroing the data on the lower-dim
      // primitives.
      for (const auto &idx : vertexdof::macroface::Iterator(level)) {
        if (vertexdof::macroface::isVertexOnBoundary(level, idx)) {
          auto arrayIdx = vertexdof::macroface::index(level, idx.x(), idx.y());
          _data_dst[arrayIdx] = double(0);
        }
      }

      const auto micro_edges_per_macro_edge =
          (int64_t)levelinfo::num_microedges_per_edge(level);
      const auto num_microfaces_per_face =
          (int64_t)levelinfo::num_microfaces_per_face(level);
      const auto micro_edges_per_macro_edge_float =
          (double)levelinfo::num_microedges_per_edge(level);
      const double macro_vertex_coord_id_0comp0 =
          (double)face.getCoordinates()[0][0];
      const double macro_vertex_coord_id_0comp1 =
          (double)face.getCoordinates()[0][1];
      const double macro_vertex_coord_id_1comp0 =
          (double)face.getCoordinates()[1][0];
      const double macro_vertex_coord_id_1comp1 =
          (double)face.getCoordinates()[1][1];
      const double macro_vertex_coord_id_2comp0 =
          (double)face.getCoordinates()[2][0];
      const double macro_vertex_coord_id_2comp1 =
          (double)face.getCoordinates()[2][1];

      this->timingTree_->start("kernel");

      apply_P1ElementwiseDivKGrad_cubes_const_vect_fused_quadloops_tab_macro_2D(

          _data_dst, _data_k, _data_src, macro_vertex_coord_id_0comp0,
          macro_vertex_coord_id_0comp1, macro_vertex_coord_id_1comp0,
          macro_vertex_coord_id_1comp1, macro_vertex_coord_id_2comp0,
          macro_vertex_coord_id_2comp1, micro_edges_per_macro_edge,
          micro_edges_per_macro_edge_float);

      this->timingTree_->stop("kernel");
    }

    // Push result to lower-dimensional primitives
    //
    this->timingTree_->start("post-communication");
    // Note: We could avoid communication here by implementing the apply() also
    // for the respective
    //       lower dimensional primitives!
    dst.communicateAdditively<Face, Edge>(level, DoFType::All ^ flag, *storage_,
                                          updateType == Replace);
    dst.communicateAdditively<Face, Vertex>(level, DoFType::All ^ flag,
                                            *storage_, updateType == Replace);
    this->timingTree_->stop("post-communication");
  }

  this->stopTiming("apply");
}
void P1ElementwiseDivKGrad_cubes_const_vect_fused_quadloops_tab::
    computeInverseDiagonalOperatorValues() {
  this->startTiming("computeInverseDiagonalOperatorValues");

  if (invDiag_ == nullptr) {
    invDiag_ = std::make_shared<P1Function<double>>(
        "inverse diagonal entries", storage_, minLevel_, maxLevel_);
  }

  for (uint_t level = minLevel_; level <= maxLevel_; level++) {
    invDiag_->setToZero(level);

    if (storage_->hasGlobalCells()) {
      this->timingTree_->start("pre-communication");
      k.communicate<Face, Cell>(level);
      k.communicate<Edge, Cell>(level);
      k.communicate<Vertex, Cell>(level);
      this->timingTree_->stop("pre-communication");

      for (auto &it : storage_->getCells()) {
        Cell &cell = *it.second;

        // get hold of the actual numerical data
        double *_data_invDiag_ =
            cell.getData((*invDiag_).getCellDataID())->getPointer(level);
        double *_data_k = cell.getData(k.getCellDataID())->getPointer(level);

        const auto micro_edges_per_macro_edge =
            (int64_t)levelinfo::num_microedges_per_edge(level);
        const auto num_microfaces_per_face =
            (int64_t)levelinfo::num_microfaces_per_face(level);
        const auto micro_edges_per_macro_edge_float =
            (double)levelinfo::num_microedges_per_edge(level);
        const double macro_vertex_coord_id_0comp0 =
            (double)cell.getCoordinates()[0][0];
        const double macro_vertex_coord_id_0comp1 =
            (double)cell.getCoordinates()[0][1];
        const double macro_vertex_coord_id_0comp2 =
            (double)cell.getCoordinates()[0][2];
        const double macro_vertex_coord_id_1comp0 =
            (double)cell.getCoordinates()[1][0];
        const double macro_vertex_coord_id_1comp1 =
            (double)cell.getCoordinates()[1][1];
        const double macro_vertex_coord_id_1comp2 =
            (double)cell.getCoordinates()[1][2];
        const double macro_vertex_coord_id_2comp0 =
            (double)cell.getCoordinates()[2][0];
        const double macro_vertex_coord_id_2comp1 =
            (double)cell.getCoordinates()[2][1];
        const double macro_vertex_coord_id_2comp2 =
            (double)cell.getCoordinates()[2][2];
        const double macro_vertex_coord_id_3comp0 =
            (double)cell.getCoordinates()[3][0];
        const double macro_vertex_coord_id_3comp1 =
            (double)cell.getCoordinates()[3][1];
        const double macro_vertex_coord_id_3comp2 =
            (double)cell.getCoordinates()[3][2];

        this->timingTree_->start("kernel");

        computeInverseDiagonalOperatorValues_P1ElementwiseDivKGrad_cubes_const_vect_fused_quadloops_tab_macro_3D(

            _data_invDiag_, _data_k, macro_vertex_coord_id_0comp0,
            macro_vertex_coord_id_0comp1, macro_vertex_coord_id_0comp2,
            macro_vertex_coord_id_1comp0, macro_vertex_coord_id_1comp1,
            macro_vertex_coord_id_1comp2, macro_vertex_coord_id_2comp0,
            macro_vertex_coord_id_2comp1, macro_vertex_coord_id_2comp2,
            macro_vertex_coord_id_3comp0, macro_vertex_coord_id_3comp1,
            macro_vertex_coord_id_3comp2, micro_edges_per_macro_edge,
            micro_edges_per_macro_edge_float);

        this->timingTree_->stop("kernel");
      }

      // Push result to lower-dimensional primitives
      //
      this->timingTree_->start("post-communication");
      // Note: We could avoid communication here by implementing the apply()
      // also for the respective
      //       lower dimensional primitives!
      (*invDiag_).communicateAdditively<Cell, Face>(level);
      (*invDiag_).communicateAdditively<Cell, Edge>(level);
      (*invDiag_).communicateAdditively<Cell, Vertex>(level);
      this->timingTree_->stop("post-communication");
      (*invDiag_).invertElementwise(level);
    } else {
      this->timingTree_->start("pre-communication");
      communication::syncFunctionBetweenPrimitives(
          k, level, communication::syncDirection_t::LOW2HIGH);
      this->timingTree_->stop("pre-communication");

      for (auto &it : storage_->getFaces()) {
        Face &face = *it.second;

        // get hold of the actual numerical data
        double *_data_invDiag_ =
            face.getData((*invDiag_).getFaceDataID())->getPointer(level);
        double *_data_k = face.getData(k.getFaceDataID())->getPointer(level);

        const auto micro_edges_per_macro_edge =
            (int64_t)levelinfo::num_microedges_per_edge(level);
        const auto num_microfaces_per_face =
            (int64_t)levelinfo::num_microfaces_per_face(level);
        const auto micro_edges_per_macro_edge_float =
            (double)levelinfo::num_microedges_per_edge(level);
        const double macro_vertex_coord_id_0comp0 =
            (double)face.getCoordinates()[0][0];
        const double macro_vertex_coord_id_0comp1 =
            (double)face.getCoordinates()[0][1];
        const double macro_vertex_coord_id_1comp0 =
            (double)face.getCoordinates()[1][0];
        const double macro_vertex_coord_id_1comp1 =
            (double)face.getCoordinates()[1][1];
        const double macro_vertex_coord_id_2comp0 =
            (double)face.getCoordinates()[2][0];
        const double macro_vertex_coord_id_2comp1 =
            (double)face.getCoordinates()[2][1];

        this->timingTree_->start("kernel");

        computeInverseDiagonalOperatorValues_P1ElementwiseDivKGrad_cubes_const_vect_fused_quadloops_tab_macro_2D(

            _data_invDiag_, _data_k, macro_vertex_coord_id_0comp0,
            macro_vertex_coord_id_0comp1, macro_vertex_coord_id_1comp0,
            macro_vertex_coord_id_1comp1, macro_vertex_coord_id_2comp0,
            macro_vertex_coord_id_2comp1, micro_edges_per_macro_edge,
            micro_edges_per_macro_edge_float);

        this->timingTree_->stop("kernel");
      }

      // Push result to lower-dimensional primitives
      //
      this->timingTree_->start("post-communication");
      // Note: We could avoid communication here by implementing the apply()
      // also for the respective
      //       lower dimensional primitives!
      (*invDiag_).communicateAdditively<Face, Edge>(level);
      (*invDiag_).communicateAdditively<Face, Vertex>(level);
      this->timingTree_->stop("post-communication");
      (*invDiag_).invertElementwise(level);
    }
  }

  this->stopTiming("computeInverseDiagonalOperatorValues");
}
std::shared_ptr<P1Function<double>>
P1ElementwiseDivKGrad_cubes_const_vect_fused_quadloops_tab::
    getInverseDiagonalValues() const {
  return invDiag_;
}
void P1ElementwiseDivKGrad_cubes_const_vect_fused_quadloops_tab::
    apply_P1ElementwiseDivKGrad_cubes_const_vect_fused_quadloops_tab_macro_3D(
        double *RESTRICT const _data_dst, double *RESTRICT const _data_k,
        double *RESTRICT const _data_src,
        const double macro_vertex_coord_id_0comp0,
        const double macro_vertex_coord_id_0comp1,
        const double macro_vertex_coord_id_0comp2,
        const double macro_vertex_coord_id_1comp0,
        const double macro_vertex_coord_id_1comp1,
        const double macro_vertex_coord_id_1comp2,
        const double macro_vertex_coord_id_2comp0,
        const double macro_vertex_coord_id_2comp1,
        const double macro_vertex_coord_id_2comp2,
        const double macro_vertex_coord_id_3comp0,
        const double macro_vertex_coord_id_3comp1,
        const double macro_vertex_coord_id_3comp2,
        const int64_t micro_edges_per_macro_edge,
        const double micro_edges_per_macro_edge_float) const {
  {
    double q_w[1] = {0.16666666666666663};
    const double tmp_coords_jac_0__10 =
        macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_1__10 =
        1.0 * (1.0 / micro_edges_per_macro_edge_float);
    const double tmp_coords_jac_2__10 = tmp_coords_jac_1__10 * 0.0;
    const double tmp_coords_jac_3__10 =
        tmp_coords_jac_0__10 * tmp_coords_jac_2__10;
    const double tmp_coords_jac_4__10 =
        macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_5__10 =
        tmp_coords_jac_2__10 * tmp_coords_jac_4__10;
    const double tmp_coords_jac_6__10 =
        macro_vertex_coord_id_3comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_7__10 =
        tmp_coords_jac_2__10 * tmp_coords_jac_6__10;
    const double tmp_coords_jac_8__10 = macro_vertex_coord_id_0comp0 +
                                        tmp_coords_jac_5__10 +
                                        tmp_coords_jac_7__10;
    const double tmp_coords_jac_9__10 =
        macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_10__10 =
        tmp_coords_jac_2__10 * tmp_coords_jac_9__10;
    const double tmp_coords_jac_11__10 =
        macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_12__10 =
        tmp_coords_jac_11__10 * tmp_coords_jac_2__10;
    const double tmp_coords_jac_13__10 =
        macro_vertex_coord_id_3comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_14__10 =
        tmp_coords_jac_13__10 * tmp_coords_jac_2__10;
    const double tmp_coords_jac_15__10 = macro_vertex_coord_id_0comp1 +
                                         tmp_coords_jac_12__10 +
                                         tmp_coords_jac_14__10;
    const double tmp_coords_jac_16__10 =
        macro_vertex_coord_id_1comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_17__10 =
        tmp_coords_jac_16__10 * tmp_coords_jac_2__10;
    const double tmp_coords_jac_18__10 =
        macro_vertex_coord_id_2comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_19__10 =
        tmp_coords_jac_18__10 * tmp_coords_jac_2__10;
    const double tmp_coords_jac_20__10 =
        macro_vertex_coord_id_3comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_21__10 =
        tmp_coords_jac_2__10 * tmp_coords_jac_20__10;
    const double tmp_coords_jac_22__10 = macro_vertex_coord_id_0comp2 +
                                         tmp_coords_jac_19__10 +
                                         tmp_coords_jac_21__10;
    const double tmp_coords_jac_23__10 = tmp_coords_jac_1__10 * 1.0;
    const double tmp_coords_jac_24__10 =
        macro_vertex_coord_id_0comp0 + tmp_coords_jac_3__10;
    const double tmp_coords_jac_25__10 =
        macro_vertex_coord_id_0comp1 + tmp_coords_jac_10__10;
    const double tmp_coords_jac_26__10 =
        macro_vertex_coord_id_0comp2 + tmp_coords_jac_17__10;
    const double p_affine_const_0_0__10 =
        tmp_coords_jac_3__10 + tmp_coords_jac_8__10;
    const double p_affine_const_0_1__10 =
        tmp_coords_jac_10__10 + tmp_coords_jac_15__10;
    const double p_affine_const_0_2__10 =
        tmp_coords_jac_17__10 + tmp_coords_jac_22__10;
    const double p_affine_const_1_0__10 =
        tmp_coords_jac_8__10 + tmp_coords_jac_0__10 * tmp_coords_jac_23__10;
    const double p_affine_const_1_1__10 =
        tmp_coords_jac_15__10 + tmp_coords_jac_23__10 * tmp_coords_jac_9__10;
    const double p_affine_const_1_2__10 =
        tmp_coords_jac_22__10 + tmp_coords_jac_16__10 * tmp_coords_jac_23__10;
    const double p_affine_const_2_0__10 =
        tmp_coords_jac_24__10 + tmp_coords_jac_7__10 +
        tmp_coords_jac_23__10 * tmp_coords_jac_4__10;
    const double p_affine_const_2_1__10 =
        tmp_coords_jac_14__10 + tmp_coords_jac_25__10 +
        tmp_coords_jac_11__10 * tmp_coords_jac_23__10;
    const double p_affine_const_2_2__10 =
        tmp_coords_jac_21__10 + tmp_coords_jac_26__10 +
        tmp_coords_jac_18__10 * tmp_coords_jac_23__10;
    const double p_affine_const_3_0__10 =
        tmp_coords_jac_24__10 + tmp_coords_jac_5__10 +
        tmp_coords_jac_23__10 * tmp_coords_jac_6__10;
    const double p_affine_const_3_1__10 =
        tmp_coords_jac_12__10 + tmp_coords_jac_25__10 +
        tmp_coords_jac_13__10 * tmp_coords_jac_23__10;
    const double p_affine_const_3_2__10 =
        tmp_coords_jac_19__10 + tmp_coords_jac_26__10 +
        tmp_coords_jac_20__10 * tmp_coords_jac_23__10;
    const double jac_affine_0_0__10 =
        p_affine_const_1_0__10 - p_affine_const_0_0__10;
    const double jac_affine_0_1__10 =
        p_affine_const_2_0__10 - p_affine_const_0_0__10;
    const double jac_affine_0_2__10 =
        p_affine_const_3_0__10 - p_affine_const_0_0__10;
    const double jac_affine_1_0__10 =
        p_affine_const_1_1__10 - p_affine_const_0_1__10;
    const double jac_affine_1_1__10 =
        p_affine_const_2_1__10 - p_affine_const_0_1__10;
    const double tmp_coords_jac_31__7 = jac_affine_0_2__10 * jac_affine_1_1__10;
    const double jac_affine_1_2__10 =
        p_affine_const_3_1__10 - p_affine_const_0_1__10;
    const double tmp_coords_jac_29__10 =
        jac_affine_0_1__10 * jac_affine_1_2__10;
    const double jac_affine_2_0__10 =
        p_affine_const_1_2__10 - p_affine_const_0_2__10;
    const double jac_affine_2_1__10 =
        p_affine_const_2_2__10 - p_affine_const_0_2__10;
    const double tmp_coords_jac_28__10 =
        jac_affine_1_2__10 * jac_affine_2_1__10;
    const double jac_affine_2_2__10 =
        p_affine_const_3_2__10 - p_affine_const_0_2__10;
    const double tmp_coords_jac_27__10 =
        jac_affine_1_1__10 * jac_affine_2_2__10;
    const double tmp_coords_jac_30__10 =
        jac_affine_0_1__10 * jac_affine_2_2__10;
    const double tmp_coords_jac_32__7 =
        jac_affine_0_0__10 * tmp_coords_jac_27__10 +
        jac_affine_2_0__10 * tmp_coords_jac_29__10 -
        jac_affine_0_0__10 * tmp_coords_jac_28__10 -
        jac_affine_1_0__10 * tmp_coords_jac_30__10 -
        jac_affine_2_0__10 * tmp_coords_jac_31__7 +
        jac_affine_0_2__10 * jac_affine_1_0__10 * jac_affine_2_1__10;
    const double tmp_coords_jac_33__7 = 1.0 / tmp_coords_jac_32__7;
    const double jac_affine_inv_0_0__10 =
        tmp_coords_jac_33__7 * (tmp_coords_jac_27__10 - tmp_coords_jac_28__10);
    const double jac_affine_inv_0_1__10 =
        tmp_coords_jac_33__7 * (-1.0 * tmp_coords_jac_30__10 +
                                jac_affine_0_2__10 * jac_affine_2_1__10);
    const double jac_affine_inv_0_2__10 =
        tmp_coords_jac_33__7 * (tmp_coords_jac_29__10 - tmp_coords_jac_31__7);
    const double jac_affine_inv_1_0__10 =
        tmp_coords_jac_33__7 * (jac_affine_1_2__10 * jac_affine_2_0__10 -
                                jac_affine_1_0__10 * jac_affine_2_2__10);
    const double jac_affine_inv_1_1__10 =
        tmp_coords_jac_33__7 * (jac_affine_0_0__10 * jac_affine_2_2__10 -
                                jac_affine_0_2__10 * jac_affine_2_0__10);
    const double jac_affine_inv_1_2__10 =
        tmp_coords_jac_33__7 * (jac_affine_0_2__10 * jac_affine_1_0__10 -
                                jac_affine_0_0__10 * jac_affine_1_2__10);
    const double jac_affine_inv_2_0__10 =
        tmp_coords_jac_33__7 * (jac_affine_1_0__10 * jac_affine_2_1__10 -
                                jac_affine_1_1__10 * jac_affine_2_0__10);
    const double jac_affine_inv_2_1__10 =
        tmp_coords_jac_33__7 * (jac_affine_0_1__10 * jac_affine_2_0__10 -
                                jac_affine_0_0__10 * jac_affine_2_1__10);
    const double jac_affine_inv_2_2__10 =
        tmp_coords_jac_33__7 * (jac_affine_0_0__10 * jac_affine_1_1__10 -
                                jac_affine_0_1__10 * jac_affine_1_0__10);
    const double abs_det_jac_affine__10 = abs(tmp_coords_jac_32__7);
    double phi_0_0__10[4] = {0.25, 0.25, 0.25, 0.25};
    double tabulated_and_untitled_0_0__10[10] = {
        abs_det_jac_affine__10 *
            ((-1.0 * jac_affine_inv_0_0__10 - jac_affine_inv_1_0__10 -
              jac_affine_inv_2_0__10) *
                 (-1.0 * jac_affine_inv_0_0__10 - jac_affine_inv_1_0__10 -
                  jac_affine_inv_2_0__10) +
             (-1.0 * jac_affine_inv_0_1__10 - jac_affine_inv_1_1__10 -
              jac_affine_inv_2_1__10) *
                 (-1.0 * jac_affine_inv_0_1__10 - jac_affine_inv_1_1__10 -
                  jac_affine_inv_2_1__10) +
             (-1.0 * jac_affine_inv_0_2__10 - jac_affine_inv_1_2__10 -
              jac_affine_inv_2_2__10) *
                 (-1.0 * jac_affine_inv_0_2__10 - jac_affine_inv_1_2__10 -
                  jac_affine_inv_2_2__10)),
        abs_det_jac_affine__10 *
            (jac_affine_inv_0_0__10 *
                 (-1.0 * jac_affine_inv_0_0__10 - jac_affine_inv_1_0__10 -
                  jac_affine_inv_2_0__10) +
             jac_affine_inv_0_1__10 *
                 (-1.0 * jac_affine_inv_0_1__10 - jac_affine_inv_1_1__10 -
                  jac_affine_inv_2_1__10) +
             jac_affine_inv_0_2__10 *
                 (-1.0 * jac_affine_inv_0_2__10 - jac_affine_inv_1_2__10 -
                  jac_affine_inv_2_2__10)),
        abs_det_jac_affine__10 *
            (jac_affine_inv_1_0__10 *
                 (-1.0 * jac_affine_inv_0_0__10 - jac_affine_inv_1_0__10 -
                  jac_affine_inv_2_0__10) +
             jac_affine_inv_1_1__10 *
                 (-1.0 * jac_affine_inv_0_1__10 - jac_affine_inv_1_1__10 -
                  jac_affine_inv_2_1__10) +
             jac_affine_inv_1_2__10 *
                 (-1.0 * jac_affine_inv_0_2__10 - jac_affine_inv_1_2__10 -
                  jac_affine_inv_2_2__10)),
        abs_det_jac_affine__10 *
            (jac_affine_inv_2_0__10 *
                 (-1.0 * jac_affine_inv_0_0__10 - jac_affine_inv_1_0__10 -
                  jac_affine_inv_2_0__10) +
             jac_affine_inv_2_1__10 *
                 (-1.0 * jac_affine_inv_0_1__10 - jac_affine_inv_1_1__10 -
                  jac_affine_inv_2_1__10) +
             jac_affine_inv_2_2__10 *
                 (-1.0 * jac_affine_inv_0_2__10 - jac_affine_inv_1_2__10 -
                  jac_affine_inv_2_2__10)),
        abs_det_jac_affine__10 *
            (jac_affine_inv_0_0__10 * jac_affine_inv_0_0__10 +
             jac_affine_inv_0_1__10 * jac_affine_inv_0_1__10 +
             jac_affine_inv_0_2__10 * jac_affine_inv_0_2__10),
        abs_det_jac_affine__10 *
            (jac_affine_inv_0_0__10 * jac_affine_inv_1_0__10 +
             jac_affine_inv_0_1__10 * jac_affine_inv_1_1__10 +
             jac_affine_inv_0_2__10 * jac_affine_inv_1_2__10),
        abs_det_jac_affine__10 *
            (jac_affine_inv_0_0__10 * jac_affine_inv_2_0__10 +
             jac_affine_inv_0_1__10 * jac_affine_inv_2_1__10 +
             jac_affine_inv_0_2__10 * jac_affine_inv_2_2__10),
        abs_det_jac_affine__10 *
            (jac_affine_inv_1_0__10 * jac_affine_inv_1_0__10 +
             jac_affine_inv_1_1__10 * jac_affine_inv_1_1__10 +
             jac_affine_inv_1_2__10 * jac_affine_inv_1_2__10),
        abs_det_jac_affine__10 *
            (jac_affine_inv_1_0__10 * jac_affine_inv_2_0__10 +
             jac_affine_inv_1_1__10 * jac_affine_inv_2_1__10 +
             jac_affine_inv_1_2__10 * jac_affine_inv_2_2__10),
        abs_det_jac_affine__10 *
            (jac_affine_inv_2_0__10 * jac_affine_inv_2_0__10 +
             jac_affine_inv_2_1__10 * jac_affine_inv_2_1__10 +
             jac_affine_inv_2_2__10 * jac_affine_inv_2_2__10)};
    const double tmp_coords_jac_0__9 =
        macro_vertex_coord_id_3comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_1__9 =
        1.0 * (1.0 / micro_edges_per_macro_edge_float);
    const double tmp_coords_jac_2__9 = tmp_coords_jac_1__9 * 0.0;
    const double tmp_coords_jac_3__9 =
        macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_4__9 = tmp_coords_jac_1__9 * 1.0;
    const double tmp_coords_jac_5__9 =
        tmp_coords_jac_3__9 * tmp_coords_jac_4__9;
    const double tmp_coords_jac_6__9 =
        macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_7__9 =
        macro_vertex_coord_id_0comp0 +
        tmp_coords_jac_4__9 * tmp_coords_jac_6__9;
    const double tmp_coords_jac_8__9 =
        tmp_coords_jac_5__9 + tmp_coords_jac_7__9;
    const double tmp_coords_jac_9__9 =
        macro_vertex_coord_id_3comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_10__9 =
        macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_11__9 =
        tmp_coords_jac_10__9 * tmp_coords_jac_4__9;
    const double tmp_coords_jac_12__9 =
        macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_13__9 =
        macro_vertex_coord_id_0comp1 +
        tmp_coords_jac_12__9 * tmp_coords_jac_4__9;
    const double tmp_coords_jac_14__9 =
        tmp_coords_jac_11__9 + tmp_coords_jac_13__9;
    const double tmp_coords_jac_15__9 =
        macro_vertex_coord_id_3comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_16__9 =
        macro_vertex_coord_id_2comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_17__9 =
        tmp_coords_jac_16__9 * tmp_coords_jac_4__9;
    const double tmp_coords_jac_18__9 =
        macro_vertex_coord_id_1comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_19__9 =
        macro_vertex_coord_id_0comp2 +
        tmp_coords_jac_18__9 * tmp_coords_jac_4__9;
    const double tmp_coords_jac_20__9 =
        tmp_coords_jac_17__9 + tmp_coords_jac_19__9;
    const double tmp_coords_jac_21__9 =
        tmp_coords_jac_0__9 * tmp_coords_jac_4__9;
    const double tmp_coords_jac_22__9 =
        tmp_coords_jac_4__9 * tmp_coords_jac_9__9;
    const double tmp_coords_jac_23__9 =
        tmp_coords_jac_15__9 * tmp_coords_jac_4__9;
    const double p_affine_const_0_0__9 =
        tmp_coords_jac_8__9 + tmp_coords_jac_0__9 * tmp_coords_jac_2__9;
    const double p_affine_const_0_1__9 =
        tmp_coords_jac_14__9 + tmp_coords_jac_2__9 * tmp_coords_jac_9__9;
    const double p_affine_const_0_2__9 =
        tmp_coords_jac_20__9 + tmp_coords_jac_15__9 * tmp_coords_jac_2__9;
    const double p_affine_const_1_0__9 =
        tmp_coords_jac_21__9 + tmp_coords_jac_7__9 +
        tmp_coords_jac_2__9 * tmp_coords_jac_3__9;
    const double p_affine_const_1_1__9 =
        tmp_coords_jac_13__9 + tmp_coords_jac_22__9 +
        tmp_coords_jac_10__9 * tmp_coords_jac_2__9;
    const double p_affine_const_1_2__9 =
        tmp_coords_jac_19__9 + tmp_coords_jac_23__9 +
        tmp_coords_jac_16__9 * tmp_coords_jac_2__9;
    const double p_affine_const_2_0__9 =
        macro_vertex_coord_id_0comp0 + tmp_coords_jac_21__9 +
        tmp_coords_jac_5__9 + tmp_coords_jac_2__9 * tmp_coords_jac_6__9;
    const double p_affine_const_2_1__9 =
        macro_vertex_coord_id_0comp1 + tmp_coords_jac_11__9 +
        tmp_coords_jac_22__9 + tmp_coords_jac_12__9 * tmp_coords_jac_2__9;
    const double p_affine_const_2_2__9 =
        macro_vertex_coord_id_0comp2 + tmp_coords_jac_17__9 +
        tmp_coords_jac_23__9 + tmp_coords_jac_18__9 * tmp_coords_jac_2__9;
    const double p_affine_const_3_0__9 =
        tmp_coords_jac_21__9 + tmp_coords_jac_8__9;
    const double p_affine_const_3_1__9 =
        tmp_coords_jac_14__9 + tmp_coords_jac_22__9;
    const double p_affine_const_3_2__9 =
        tmp_coords_jac_20__9 + tmp_coords_jac_23__9;
    const double jac_affine_0_0__9 =
        p_affine_const_1_0__9 - p_affine_const_0_0__9;
    const double jac_affine_0_1__9 =
        p_affine_const_2_0__9 - p_affine_const_0_0__9;
    const double jac_affine_0_2__9 =
        p_affine_const_3_0__9 - p_affine_const_0_0__9;
    const double jac_affine_1_0__9 =
        p_affine_const_1_1__9 - p_affine_const_0_1__9;
    const double jac_affine_1_1__9 =
        p_affine_const_2_1__9 - p_affine_const_0_1__9;
    const double tmp_coords_jac_28__9 = jac_affine_0_2__9 * jac_affine_1_1__9;
    const double jac_affine_1_2__9 =
        p_affine_const_3_1__9 - p_affine_const_0_1__9;
    const double tmp_coords_jac_26__9 = jac_affine_0_1__9 * jac_affine_1_2__9;
    const double jac_affine_2_0__9 =
        p_affine_const_1_2__9 - p_affine_const_0_2__9;
    const double jac_affine_2_1__9 =
        p_affine_const_2_2__9 - p_affine_const_0_2__9;
    const double tmp_coords_jac_25__9 = jac_affine_1_2__9 * jac_affine_2_1__9;
    const double jac_affine_2_2__9 =
        p_affine_const_3_2__9 - p_affine_const_0_2__9;
    const double tmp_coords_jac_24__9 = jac_affine_1_1__9 * jac_affine_2_2__9;
    const double tmp_coords_jac_27__9 = jac_affine_0_1__9 * jac_affine_2_2__9;
    const double tmp_coords_jac_29__9 =
        jac_affine_0_0__9 * tmp_coords_jac_24__9 +
        jac_affine_2_0__9 * tmp_coords_jac_26__9 -
        jac_affine_0_0__9 * tmp_coords_jac_25__9 -
        jac_affine_1_0__9 * tmp_coords_jac_27__9 -
        jac_affine_2_0__9 * tmp_coords_jac_28__9 +
        jac_affine_0_2__9 * jac_affine_1_0__9 * jac_affine_2_1__9;
    const double tmp_coords_jac_30__9 = 1.0 / tmp_coords_jac_29__9;
    const double jac_affine_inv_0_0__9 =
        tmp_coords_jac_30__9 * (tmp_coords_jac_24__9 - tmp_coords_jac_25__9);
    const double jac_affine_inv_0_1__9 =
        tmp_coords_jac_30__9 *
        (-1.0 * tmp_coords_jac_27__9 + jac_affine_0_2__9 * jac_affine_2_1__9);
    const double jac_affine_inv_0_2__9 =
        tmp_coords_jac_30__9 * (tmp_coords_jac_26__9 - tmp_coords_jac_28__9);
    const double jac_affine_inv_1_0__9 =
        tmp_coords_jac_30__9 * (jac_affine_1_2__9 * jac_affine_2_0__9 -
                                jac_affine_1_0__9 * jac_affine_2_2__9);
    const double jac_affine_inv_1_1__9 =
        tmp_coords_jac_30__9 * (jac_affine_0_0__9 * jac_affine_2_2__9 -
                                jac_affine_0_2__9 * jac_affine_2_0__9);
    const double jac_affine_inv_1_2__9 =
        tmp_coords_jac_30__9 * (jac_affine_0_2__9 * jac_affine_1_0__9 -
                                jac_affine_0_0__9 * jac_affine_1_2__9);
    const double jac_affine_inv_2_0__9 =
        tmp_coords_jac_30__9 * (jac_affine_1_0__9 * jac_affine_2_1__9 -
                                jac_affine_1_1__9 * jac_affine_2_0__9);
    const double jac_affine_inv_2_1__9 =
        tmp_coords_jac_30__9 * (jac_affine_0_1__9 * jac_affine_2_0__9 -
                                jac_affine_0_0__9 * jac_affine_2_1__9);
    const double jac_affine_inv_2_2__9 =
        tmp_coords_jac_30__9 * (jac_affine_0_0__9 * jac_affine_1_1__9 -
                                jac_affine_0_1__9 * jac_affine_1_0__9);
    const double abs_det_jac_affine__9 = abs(tmp_coords_jac_29__9);
    double phi_0_0__9[4] = {0.25, 0.25, 0.25, 0.25};
    double tabulated_and_untitled_0_0__9[10] = {
        abs_det_jac_affine__9 *
            ((-1.0 * jac_affine_inv_0_0__9 - jac_affine_inv_1_0__9 -
              jac_affine_inv_2_0__9) *
                 (-1.0 * jac_affine_inv_0_0__9 - jac_affine_inv_1_0__9 -
                  jac_affine_inv_2_0__9) +
             (-1.0 * jac_affine_inv_0_1__9 - jac_affine_inv_1_1__9 -
              jac_affine_inv_2_1__9) *
                 (-1.0 * jac_affine_inv_0_1__9 - jac_affine_inv_1_1__9 -
                  jac_affine_inv_2_1__9) +
             (-1.0 * jac_affine_inv_0_2__9 - jac_affine_inv_1_2__9 -
              jac_affine_inv_2_2__9) *
                 (-1.0 * jac_affine_inv_0_2__9 - jac_affine_inv_1_2__9 -
                  jac_affine_inv_2_2__9)),
        abs_det_jac_affine__9 *
            (jac_affine_inv_0_0__9 *
                 (-1.0 * jac_affine_inv_0_0__9 - jac_affine_inv_1_0__9 -
                  jac_affine_inv_2_0__9) +
             jac_affine_inv_0_1__9 *
                 (-1.0 * jac_affine_inv_0_1__9 - jac_affine_inv_1_1__9 -
                  jac_affine_inv_2_1__9) +
             jac_affine_inv_0_2__9 *
                 (-1.0 * jac_affine_inv_0_2__9 - jac_affine_inv_1_2__9 -
                  jac_affine_inv_2_2__9)),
        abs_det_jac_affine__9 *
            (jac_affine_inv_1_0__9 *
                 (-1.0 * jac_affine_inv_0_0__9 - jac_affine_inv_1_0__9 -
                  jac_affine_inv_2_0__9) +
             jac_affine_inv_1_1__9 *
                 (-1.0 * jac_affine_inv_0_1__9 - jac_affine_inv_1_1__9 -
                  jac_affine_inv_2_1__9) +
             jac_affine_inv_1_2__9 *
                 (-1.0 * jac_affine_inv_0_2__9 - jac_affine_inv_1_2__9 -
                  jac_affine_inv_2_2__9)),
        abs_det_jac_affine__9 *
            (jac_affine_inv_2_0__9 *
                 (-1.0 * jac_affine_inv_0_0__9 - jac_affine_inv_1_0__9 -
                  jac_affine_inv_2_0__9) +
             jac_affine_inv_2_1__9 *
                 (-1.0 * jac_affine_inv_0_1__9 - jac_affine_inv_1_1__9 -
                  jac_affine_inv_2_1__9) +
             jac_affine_inv_2_2__9 *
                 (-1.0 * jac_affine_inv_0_2__9 - jac_affine_inv_1_2__9 -
                  jac_affine_inv_2_2__9)),
        abs_det_jac_affine__9 * (jac_affine_inv_0_0__9 * jac_affine_inv_0_0__9 +
                                 jac_affine_inv_0_1__9 * jac_affine_inv_0_1__9 +
                                 jac_affine_inv_0_2__9 * jac_affine_inv_0_2__9),
        abs_det_jac_affine__9 * (jac_affine_inv_0_0__9 * jac_affine_inv_1_0__9 +
                                 jac_affine_inv_0_1__9 * jac_affine_inv_1_1__9 +
                                 jac_affine_inv_0_2__9 * jac_affine_inv_1_2__9),
        abs_det_jac_affine__9 * (jac_affine_inv_0_0__9 * jac_affine_inv_2_0__9 +
                                 jac_affine_inv_0_1__9 * jac_affine_inv_2_1__9 +
                                 jac_affine_inv_0_2__9 * jac_affine_inv_2_2__9),
        abs_det_jac_affine__9 * (jac_affine_inv_1_0__9 * jac_affine_inv_1_0__9 +
                                 jac_affine_inv_1_1__9 * jac_affine_inv_1_1__9 +
                                 jac_affine_inv_1_2__9 * jac_affine_inv_1_2__9),
        abs_det_jac_affine__9 * (jac_affine_inv_1_0__9 * jac_affine_inv_2_0__9 +
                                 jac_affine_inv_1_1__9 * jac_affine_inv_2_1__9 +
                                 jac_affine_inv_1_2__9 * jac_affine_inv_2_2__9),
        abs_det_jac_affine__9 *
            (jac_affine_inv_2_0__9 * jac_affine_inv_2_0__9 +
             jac_affine_inv_2_1__9 * jac_affine_inv_2_1__9 +
             jac_affine_inv_2_2__9 * jac_affine_inv_2_2__9)};
    const double tmp_coords_jac_0__8 =
        macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_1__8 =
        1.0 * (1.0 / micro_edges_per_macro_edge_float);
    const double tmp_coords_jac_2__8 = tmp_coords_jac_1__8 * 0.0;
    const double tmp_coords_jac_3__8 =
        tmp_coords_jac_0__8 * tmp_coords_jac_2__8;
    const double tmp_coords_jac_4__8 =
        macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_5__8 = tmp_coords_jac_1__8 * 1.0;
    const double tmp_coords_jac_6__8 =
        tmp_coords_jac_4__8 * tmp_coords_jac_5__8;
    const double tmp_coords_jac_7__8 =
        macro_vertex_coord_id_3comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_8__8 =
        macro_vertex_coord_id_0comp0 +
        tmp_coords_jac_2__8 * tmp_coords_jac_7__8;
    const double tmp_coords_jac_9__8 =
        tmp_coords_jac_6__8 + tmp_coords_jac_8__8;
    const double tmp_coords_jac_10__8 =
        macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_11__8 =
        tmp_coords_jac_10__8 * tmp_coords_jac_2__8;
    const double tmp_coords_jac_12__8 =
        macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_13__8 =
        tmp_coords_jac_12__8 * tmp_coords_jac_5__8;
    const double tmp_coords_jac_14__8 =
        macro_vertex_coord_id_3comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_15__8 =
        macro_vertex_coord_id_0comp1 +
        tmp_coords_jac_14__8 * tmp_coords_jac_2__8;
    const double tmp_coords_jac_16__8 =
        tmp_coords_jac_13__8 + tmp_coords_jac_15__8;
    const double tmp_coords_jac_17__8 =
        macro_vertex_coord_id_2comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_18__8 =
        tmp_coords_jac_17__8 * tmp_coords_jac_2__8;
    const double tmp_coords_jac_19__8 =
        macro_vertex_coord_id_1comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_20__8 =
        tmp_coords_jac_19__8 * tmp_coords_jac_5__8;
    const double tmp_coords_jac_21__8 =
        macro_vertex_coord_id_3comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_22__8 =
        macro_vertex_coord_id_0comp2 +
        tmp_coords_jac_2__8 * tmp_coords_jac_21__8;
    const double tmp_coords_jac_23__8 =
        tmp_coords_jac_20__8 + tmp_coords_jac_22__8;
    const double tmp_coords_jac_24__8 =
        tmp_coords_jac_0__8 * tmp_coords_jac_5__8;
    const double tmp_coords_jac_25__8 =
        tmp_coords_jac_10__8 * tmp_coords_jac_5__8;
    const double tmp_coords_jac_26__8 =
        tmp_coords_jac_17__8 * tmp_coords_jac_5__8;
    const double p_affine_const_0_0__8 =
        tmp_coords_jac_3__8 + tmp_coords_jac_9__8;
    const double p_affine_const_0_1__8 =
        tmp_coords_jac_11__8 + tmp_coords_jac_16__8;
    const double p_affine_const_0_2__8 =
        tmp_coords_jac_18__8 + tmp_coords_jac_23__8;
    const double p_affine_const_1_0__8 =
        tmp_coords_jac_24__8 + tmp_coords_jac_8__8 +
        tmp_coords_jac_2__8 * tmp_coords_jac_4__8;
    const double p_affine_const_1_1__8 =
        tmp_coords_jac_15__8 + tmp_coords_jac_25__8 +
        tmp_coords_jac_12__8 * tmp_coords_jac_2__8;
    const double p_affine_const_1_2__8 =
        tmp_coords_jac_22__8 + tmp_coords_jac_26__8 +
        tmp_coords_jac_19__8 * tmp_coords_jac_2__8;
    const double p_affine_const_2_0__8 =
        tmp_coords_jac_24__8 + tmp_coords_jac_9__8;
    const double p_affine_const_2_1__8 =
        tmp_coords_jac_16__8 + tmp_coords_jac_25__8;
    const double p_affine_const_2_2__8 =
        tmp_coords_jac_23__8 + tmp_coords_jac_26__8;
    const double p_affine_const_3_0__8 =
        macro_vertex_coord_id_0comp0 + tmp_coords_jac_3__8 +
        tmp_coords_jac_6__8 + tmp_coords_jac_5__8 * tmp_coords_jac_7__8;
    const double p_affine_const_3_1__8 =
        macro_vertex_coord_id_0comp1 + tmp_coords_jac_11__8 +
        tmp_coords_jac_13__8 + tmp_coords_jac_14__8 * tmp_coords_jac_5__8;
    const double p_affine_const_3_2__8 =
        macro_vertex_coord_id_0comp2 + tmp_coords_jac_18__8 +
        tmp_coords_jac_20__8 + tmp_coords_jac_21__8 * tmp_coords_jac_5__8;
    const double jac_affine_0_0__8 =
        p_affine_const_1_0__8 - p_affine_const_0_0__8;
    const double jac_affine_0_1__8 =
        p_affine_const_2_0__8 - p_affine_const_0_0__8;
    const double jac_affine_0_2__8 =
        p_affine_const_3_0__8 - p_affine_const_0_0__8;
    const double jac_affine_1_0__8 =
        p_affine_const_1_1__8 - p_affine_const_0_1__8;
    const double jac_affine_1_1__8 =
        p_affine_const_2_1__8 - p_affine_const_0_1__8;
    const double tmp_coords_jac_31__6 = jac_affine_0_2__8 * jac_affine_1_1__8;
    const double jac_affine_1_2__8 =
        p_affine_const_3_1__8 - p_affine_const_0_1__8;
    const double tmp_coords_jac_29__8 = jac_affine_0_1__8 * jac_affine_1_2__8;
    const double jac_affine_2_0__8 =
        p_affine_const_1_2__8 - p_affine_const_0_2__8;
    const double jac_affine_2_1__8 =
        p_affine_const_2_2__8 - p_affine_const_0_2__8;
    const double tmp_coords_jac_28__8 = jac_affine_1_2__8 * jac_affine_2_1__8;
    const double jac_affine_2_2__8 =
        p_affine_const_3_2__8 - p_affine_const_0_2__8;
    const double tmp_coords_jac_27__8 = jac_affine_1_1__8 * jac_affine_2_2__8;
    const double tmp_coords_jac_30__8 = jac_affine_0_1__8 * jac_affine_2_2__8;
    const double tmp_coords_jac_32__6 =
        jac_affine_0_0__8 * tmp_coords_jac_27__8 +
        jac_affine_2_0__8 * tmp_coords_jac_29__8 -
        jac_affine_0_0__8 * tmp_coords_jac_28__8 -
        jac_affine_1_0__8 * tmp_coords_jac_30__8 -
        jac_affine_2_0__8 * tmp_coords_jac_31__6 +
        jac_affine_0_2__8 * jac_affine_1_0__8 * jac_affine_2_1__8;
    const double tmp_coords_jac_33__6 = 1.0 / tmp_coords_jac_32__6;
    const double jac_affine_inv_0_0__8 =
        tmp_coords_jac_33__6 * (tmp_coords_jac_27__8 - tmp_coords_jac_28__8);
    const double jac_affine_inv_0_1__8 =
        tmp_coords_jac_33__6 *
        (-1.0 * tmp_coords_jac_30__8 + jac_affine_0_2__8 * jac_affine_2_1__8);
    const double jac_affine_inv_0_2__8 =
        tmp_coords_jac_33__6 * (tmp_coords_jac_29__8 - tmp_coords_jac_31__6);
    const double jac_affine_inv_1_0__8 =
        tmp_coords_jac_33__6 * (jac_affine_1_2__8 * jac_affine_2_0__8 -
                                jac_affine_1_0__8 * jac_affine_2_2__8);
    const double jac_affine_inv_1_1__8 =
        tmp_coords_jac_33__6 * (jac_affine_0_0__8 * jac_affine_2_2__8 -
                                jac_affine_0_2__8 * jac_affine_2_0__8);
    const double jac_affine_inv_1_2__8 =
        tmp_coords_jac_33__6 * (jac_affine_0_2__8 * jac_affine_1_0__8 -
                                jac_affine_0_0__8 * jac_affine_1_2__8);
    const double jac_affine_inv_2_0__8 =
        tmp_coords_jac_33__6 * (jac_affine_1_0__8 * jac_affine_2_1__8 -
                                jac_affine_1_1__8 * jac_affine_2_0__8);
    const double jac_affine_inv_2_1__8 =
        tmp_coords_jac_33__6 * (jac_affine_0_1__8 * jac_affine_2_0__8 -
                                jac_affine_0_0__8 * jac_affine_2_1__8);
    const double jac_affine_inv_2_2__8 =
        tmp_coords_jac_33__6 * (jac_affine_0_0__8 * jac_affine_1_1__8 -
                                jac_affine_0_1__8 * jac_affine_1_0__8);
    const double abs_det_jac_affine__8 = abs(tmp_coords_jac_32__6);
    double phi_0_0__8[4] = {0.25, 0.25, 0.25, 0.25};
    double tabulated_and_untitled_0_0__8[10] = {
        abs_det_jac_affine__8 *
            ((-1.0 * jac_affine_inv_0_0__8 - jac_affine_inv_1_0__8 -
              jac_affine_inv_2_0__8) *
                 (-1.0 * jac_affine_inv_0_0__8 - jac_affine_inv_1_0__8 -
                  jac_affine_inv_2_0__8) +
             (-1.0 * jac_affine_inv_0_1__8 - jac_affine_inv_1_1__8 -
              jac_affine_inv_2_1__8) *
                 (-1.0 * jac_affine_inv_0_1__8 - jac_affine_inv_1_1__8 -
                  jac_affine_inv_2_1__8) +
             (-1.0 * jac_affine_inv_0_2__8 - jac_affine_inv_1_2__8 -
              jac_affine_inv_2_2__8) *
                 (-1.0 * jac_affine_inv_0_2__8 - jac_affine_inv_1_2__8 -
                  jac_affine_inv_2_2__8)),
        abs_det_jac_affine__8 *
            (jac_affine_inv_0_0__8 *
                 (-1.0 * jac_affine_inv_0_0__8 - jac_affine_inv_1_0__8 -
                  jac_affine_inv_2_0__8) +
             jac_affine_inv_0_1__8 *
                 (-1.0 * jac_affine_inv_0_1__8 - jac_affine_inv_1_1__8 -
                  jac_affine_inv_2_1__8) +
             jac_affine_inv_0_2__8 *
                 (-1.0 * jac_affine_inv_0_2__8 - jac_affine_inv_1_2__8 -
                  jac_affine_inv_2_2__8)),
        abs_det_jac_affine__8 *
            (jac_affine_inv_1_0__8 *
                 (-1.0 * jac_affine_inv_0_0__8 - jac_affine_inv_1_0__8 -
                  jac_affine_inv_2_0__8) +
             jac_affine_inv_1_1__8 *
                 (-1.0 * jac_affine_inv_0_1__8 - jac_affine_inv_1_1__8 -
                  jac_affine_inv_2_1__8) +
             jac_affine_inv_1_2__8 *
                 (-1.0 * jac_affine_inv_0_2__8 - jac_affine_inv_1_2__8 -
                  jac_affine_inv_2_2__8)),
        abs_det_jac_affine__8 *
            (jac_affine_inv_2_0__8 *
                 (-1.0 * jac_affine_inv_0_0__8 - jac_affine_inv_1_0__8 -
                  jac_affine_inv_2_0__8) +
             jac_affine_inv_2_1__8 *
                 (-1.0 * jac_affine_inv_0_1__8 - jac_affine_inv_1_1__8 -
                  jac_affine_inv_2_1__8) +
             jac_affine_inv_2_2__8 *
                 (-1.0 * jac_affine_inv_0_2__8 - jac_affine_inv_1_2__8 -
                  jac_affine_inv_2_2__8)),
        abs_det_jac_affine__8 * (jac_affine_inv_0_0__8 * jac_affine_inv_0_0__8 +
                                 jac_affine_inv_0_1__8 * jac_affine_inv_0_1__8 +
                                 jac_affine_inv_0_2__8 * jac_affine_inv_0_2__8),
        abs_det_jac_affine__8 * (jac_affine_inv_0_0__8 * jac_affine_inv_1_0__8 +
                                 jac_affine_inv_0_1__8 * jac_affine_inv_1_1__8 +
                                 jac_affine_inv_0_2__8 * jac_affine_inv_1_2__8),
        abs_det_jac_affine__8 * (jac_affine_inv_0_0__8 * jac_affine_inv_2_0__8 +
                                 jac_affine_inv_0_1__8 * jac_affine_inv_2_1__8 +
                                 jac_affine_inv_0_2__8 * jac_affine_inv_2_2__8),
        abs_det_jac_affine__8 * (jac_affine_inv_1_0__8 * jac_affine_inv_1_0__8 +
                                 jac_affine_inv_1_1__8 * jac_affine_inv_1_1__8 +
                                 jac_affine_inv_1_2__8 * jac_affine_inv_1_2__8),
        abs_det_jac_affine__8 * (jac_affine_inv_1_0__8 * jac_affine_inv_2_0__8 +
                                 jac_affine_inv_1_1__8 * jac_affine_inv_2_1__8 +
                                 jac_affine_inv_1_2__8 * jac_affine_inv_2_2__8),
        abs_det_jac_affine__8 *
            (jac_affine_inv_2_0__8 * jac_affine_inv_2_0__8 +
             jac_affine_inv_2_1__8 * jac_affine_inv_2_1__8 +
             jac_affine_inv_2_2__8 * jac_affine_inv_2_2__8)};
    const double tmp_coords_jac_0__7 =
        macro_vertex_coord_id_3comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_1__7 =
        1.0 * (1.0 / micro_edges_per_macro_edge_float);
    const double tmp_coords_jac_2__7 = tmp_coords_jac_1__7 * 0.0;
    const double tmp_coords_jac_3__7 =
        macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_4__7 = tmp_coords_jac_1__7 * 1.0;
    const double tmp_coords_jac_5__7 =
        macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_6__7 =
        macro_vertex_coord_id_0comp0 +
        tmp_coords_jac_2__7 * tmp_coords_jac_5__7;
    const double tmp_coords_jac_7__7 =
        tmp_coords_jac_6__7 + tmp_coords_jac_3__7 * tmp_coords_jac_4__7;
    const double tmp_coords_jac_8__7 =
        macro_vertex_coord_id_3comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_9__7 =
        macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_10__7 =
        macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_11__7 =
        macro_vertex_coord_id_0comp1 +
        tmp_coords_jac_10__7 * tmp_coords_jac_2__7;
    const double tmp_coords_jac_12__7 =
        tmp_coords_jac_11__7 + tmp_coords_jac_4__7 * tmp_coords_jac_9__7;
    const double tmp_coords_jac_13__7 =
        macro_vertex_coord_id_3comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_14__7 =
        macro_vertex_coord_id_2comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_15__7 =
        macro_vertex_coord_id_1comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_16__7 =
        macro_vertex_coord_id_0comp2 +
        tmp_coords_jac_15__7 * tmp_coords_jac_2__7;
    const double tmp_coords_jac_17__7 =
        tmp_coords_jac_16__7 + tmp_coords_jac_14__7 * tmp_coords_jac_4__7;
    const double tmp_coords_jac_18__7 =
        tmp_coords_jac_0__7 * tmp_coords_jac_4__7;
    const double tmp_coords_jac_19__7 =
        tmp_coords_jac_18__7 + tmp_coords_jac_2__7 * tmp_coords_jac_3__7;
    const double tmp_coords_jac_20__7 =
        tmp_coords_jac_4__7 * tmp_coords_jac_8__7;
    const double tmp_coords_jac_21__7 =
        tmp_coords_jac_20__7 + tmp_coords_jac_2__7 * tmp_coords_jac_9__7;
    const double tmp_coords_jac_22__7 =
        tmp_coords_jac_13__7 * tmp_coords_jac_4__7;
    const double tmp_coords_jac_23__7 =
        tmp_coords_jac_22__7 + tmp_coords_jac_14__7 * tmp_coords_jac_2__7;
    const double p_affine_const_0_0__7 =
        tmp_coords_jac_7__7 + tmp_coords_jac_0__7 * tmp_coords_jac_2__7;
    const double p_affine_const_0_1__7 =
        tmp_coords_jac_12__7 + tmp_coords_jac_2__7 * tmp_coords_jac_8__7;
    const double p_affine_const_0_2__7 =
        tmp_coords_jac_17__7 + tmp_coords_jac_13__7 * tmp_coords_jac_2__7;
    const double p_affine_const_1_0__7 =
        tmp_coords_jac_19__7 + tmp_coords_jac_6__7;
    const double p_affine_const_1_1__7 =
        tmp_coords_jac_11__7 + tmp_coords_jac_21__7;
    const double p_affine_const_1_2__7 =
        tmp_coords_jac_16__7 + tmp_coords_jac_23__7;
    const double p_affine_const_2_0__7 =
        macro_vertex_coord_id_0comp0 + tmp_coords_jac_19__7 +
        tmp_coords_jac_4__7 * tmp_coords_jac_5__7;
    const double p_affine_const_2_1__7 =
        macro_vertex_coord_id_0comp1 + tmp_coords_jac_21__7 +
        tmp_coords_jac_10__7 * tmp_coords_jac_4__7;
    const double p_affine_const_2_2__7 =
        macro_vertex_coord_id_0comp2 + tmp_coords_jac_23__7 +
        tmp_coords_jac_15__7 * tmp_coords_jac_4__7;
    const double p_affine_const_3_0__7 =
        tmp_coords_jac_18__7 + tmp_coords_jac_7__7;
    const double p_affine_const_3_1__7 =
        tmp_coords_jac_12__7 + tmp_coords_jac_20__7;
    const double p_affine_const_3_2__7 =
        tmp_coords_jac_17__7 + tmp_coords_jac_22__7;
    const double jac_affine_0_0__7 =
        p_affine_const_1_0__7 - p_affine_const_0_0__7;
    const double jac_affine_0_1__7 =
        p_affine_const_2_0__7 - p_affine_const_0_0__7;
    const double jac_affine_0_2__7 =
        p_affine_const_3_0__7 - p_affine_const_0_0__7;
    const double jac_affine_1_0__7 =
        p_affine_const_1_1__7 - p_affine_const_0_1__7;
    const double jac_affine_1_1__7 =
        p_affine_const_2_1__7 - p_affine_const_0_1__7;
    const double tmp_coords_jac_28__7 = jac_affine_0_2__7 * jac_affine_1_1__7;
    const double jac_affine_1_2__7 =
        p_affine_const_3_1__7 - p_affine_const_0_1__7;
    const double tmp_coords_jac_26__7 = jac_affine_0_1__7 * jac_affine_1_2__7;
    const double jac_affine_2_0__7 =
        p_affine_const_1_2__7 - p_affine_const_0_2__7;
    const double jac_affine_2_1__7 =
        p_affine_const_2_2__7 - p_affine_const_0_2__7;
    const double tmp_coords_jac_25__7 = jac_affine_1_2__7 * jac_affine_2_1__7;
    const double jac_affine_2_2__7 =
        p_affine_const_3_2__7 - p_affine_const_0_2__7;
    const double tmp_coords_jac_24__7 = jac_affine_1_1__7 * jac_affine_2_2__7;
    const double tmp_coords_jac_27__7 = jac_affine_0_1__7 * jac_affine_2_2__7;
    const double tmp_coords_jac_29__7 =
        jac_affine_0_0__7 * tmp_coords_jac_24__7 +
        jac_affine_2_0__7 * tmp_coords_jac_26__7 -
        jac_affine_0_0__7 * tmp_coords_jac_25__7 -
        jac_affine_1_0__7 * tmp_coords_jac_27__7 -
        jac_affine_2_0__7 * tmp_coords_jac_28__7 +
        jac_affine_0_2__7 * jac_affine_1_0__7 * jac_affine_2_1__7;
    const double tmp_coords_jac_30__7 = 1.0 / tmp_coords_jac_29__7;
    const double jac_affine_inv_0_0__7 =
        tmp_coords_jac_30__7 * (tmp_coords_jac_24__7 - tmp_coords_jac_25__7);
    const double jac_affine_inv_0_1__7 =
        tmp_coords_jac_30__7 *
        (-1.0 * tmp_coords_jac_27__7 + jac_affine_0_2__7 * jac_affine_2_1__7);
    const double jac_affine_inv_0_2__7 =
        tmp_coords_jac_30__7 * (tmp_coords_jac_26__7 - tmp_coords_jac_28__7);
    const double jac_affine_inv_1_0__7 =
        tmp_coords_jac_30__7 * (jac_affine_1_2__7 * jac_affine_2_0__7 -
                                jac_affine_1_0__7 * jac_affine_2_2__7);
    const double jac_affine_inv_1_1__7 =
        tmp_coords_jac_30__7 * (jac_affine_0_0__7 * jac_affine_2_2__7 -
                                jac_affine_0_2__7 * jac_affine_2_0__7);
    const double jac_affine_inv_1_2__7 =
        tmp_coords_jac_30__7 * (jac_affine_0_2__7 * jac_affine_1_0__7 -
                                jac_affine_0_0__7 * jac_affine_1_2__7);
    const double jac_affine_inv_2_0__7 =
        tmp_coords_jac_30__7 * (jac_affine_1_0__7 * jac_affine_2_1__7 -
                                jac_affine_1_1__7 * jac_affine_2_0__7);
    const double jac_affine_inv_2_1__7 =
        tmp_coords_jac_30__7 * (jac_affine_0_1__7 * jac_affine_2_0__7 -
                                jac_affine_0_0__7 * jac_affine_2_1__7);
    const double jac_affine_inv_2_2__7 =
        tmp_coords_jac_30__7 * (jac_affine_0_0__7 * jac_affine_1_1__7 -
                                jac_affine_0_1__7 * jac_affine_1_0__7);
    const double abs_det_jac_affine__7 = abs(tmp_coords_jac_29__7);
    double phi_0_0__7[4] = {0.25, 0.25, 0.25, 0.25};
    double tabulated_and_untitled_0_0__7[10] = {
        abs_det_jac_affine__7 *
            ((-1.0 * jac_affine_inv_0_0__7 - jac_affine_inv_1_0__7 -
              jac_affine_inv_2_0__7) *
                 (-1.0 * jac_affine_inv_0_0__7 - jac_affine_inv_1_0__7 -
                  jac_affine_inv_2_0__7) +
             (-1.0 * jac_affine_inv_0_1__7 - jac_affine_inv_1_1__7 -
              jac_affine_inv_2_1__7) *
                 (-1.0 * jac_affine_inv_0_1__7 - jac_affine_inv_1_1__7 -
                  jac_affine_inv_2_1__7) +
             (-1.0 * jac_affine_inv_0_2__7 - jac_affine_inv_1_2__7 -
              jac_affine_inv_2_2__7) *
                 (-1.0 * jac_affine_inv_0_2__7 - jac_affine_inv_1_2__7 -
                  jac_affine_inv_2_2__7)),
        abs_det_jac_affine__7 *
            (jac_affine_inv_0_0__7 *
                 (-1.0 * jac_affine_inv_0_0__7 - jac_affine_inv_1_0__7 -
                  jac_affine_inv_2_0__7) +
             jac_affine_inv_0_1__7 *
                 (-1.0 * jac_affine_inv_0_1__7 - jac_affine_inv_1_1__7 -
                  jac_affine_inv_2_1__7) +
             jac_affine_inv_0_2__7 *
                 (-1.0 * jac_affine_inv_0_2__7 - jac_affine_inv_1_2__7 -
                  jac_affine_inv_2_2__7)),
        abs_det_jac_affine__7 *
            (jac_affine_inv_1_0__7 *
                 (-1.0 * jac_affine_inv_0_0__7 - jac_affine_inv_1_0__7 -
                  jac_affine_inv_2_0__7) +
             jac_affine_inv_1_1__7 *
                 (-1.0 * jac_affine_inv_0_1__7 - jac_affine_inv_1_1__7 -
                  jac_affine_inv_2_1__7) +
             jac_affine_inv_1_2__7 *
                 (-1.0 * jac_affine_inv_0_2__7 - jac_affine_inv_1_2__7 -
                  jac_affine_inv_2_2__7)),
        abs_det_jac_affine__7 *
            (jac_affine_inv_2_0__7 *
                 (-1.0 * jac_affine_inv_0_0__7 - jac_affine_inv_1_0__7 -
                  jac_affine_inv_2_0__7) +
             jac_affine_inv_2_1__7 *
                 (-1.0 * jac_affine_inv_0_1__7 - jac_affine_inv_1_1__7 -
                  jac_affine_inv_2_1__7) +
             jac_affine_inv_2_2__7 *
                 (-1.0 * jac_affine_inv_0_2__7 - jac_affine_inv_1_2__7 -
                  jac_affine_inv_2_2__7)),
        abs_det_jac_affine__7 * (jac_affine_inv_0_0__7 * jac_affine_inv_0_0__7 +
                                 jac_affine_inv_0_1__7 * jac_affine_inv_0_1__7 +
                                 jac_affine_inv_0_2__7 * jac_affine_inv_0_2__7),
        abs_det_jac_affine__7 * (jac_affine_inv_0_0__7 * jac_affine_inv_1_0__7 +
                                 jac_affine_inv_0_1__7 * jac_affine_inv_1_1__7 +
                                 jac_affine_inv_0_2__7 * jac_affine_inv_1_2__7),
        abs_det_jac_affine__7 * (jac_affine_inv_0_0__7 * jac_affine_inv_2_0__7 +
                                 jac_affine_inv_0_1__7 * jac_affine_inv_2_1__7 +
                                 jac_affine_inv_0_2__7 * jac_affine_inv_2_2__7),
        abs_det_jac_affine__7 * (jac_affine_inv_1_0__7 * jac_affine_inv_1_0__7 +
                                 jac_affine_inv_1_1__7 * jac_affine_inv_1_1__7 +
                                 jac_affine_inv_1_2__7 * jac_affine_inv_1_2__7),
        abs_det_jac_affine__7 * (jac_affine_inv_1_0__7 * jac_affine_inv_2_0__7 +
                                 jac_affine_inv_1_1__7 * jac_affine_inv_2_1__7 +
                                 jac_affine_inv_1_2__7 * jac_affine_inv_2_2__7),
        abs_det_jac_affine__7 *
            (jac_affine_inv_2_0__7 * jac_affine_inv_2_0__7 +
             jac_affine_inv_2_1__7 * jac_affine_inv_2_1__7 +
             jac_affine_inv_2_2__7 * jac_affine_inv_2_2__7)};
    const double tmp_coords_jac_0__6 =
        macro_vertex_coord_id_3comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_1__6 =
        1.0 * (1.0 / micro_edges_per_macro_edge_float);
    const double tmp_coords_jac_2__6 = tmp_coords_jac_1__6 * 0.0;
    const double tmp_coords_jac_3__6 =
        macro_vertex_coord_id_0comp0 +
        tmp_coords_jac_0__6 * tmp_coords_jac_2__6;
    const double tmp_coords_jac_4__6 =
        macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_5__6 = tmp_coords_jac_1__6 * 1.0;
    const double tmp_coords_jac_6__6 =
        macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_7__6 =
        tmp_coords_jac_2__6 * tmp_coords_jac_6__6;
    const double tmp_coords_jac_8__6 =
        tmp_coords_jac_7__6 + tmp_coords_jac_4__6 * tmp_coords_jac_5__6;
    const double tmp_coords_jac_9__6 =
        macro_vertex_coord_id_3comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_10__6 =
        macro_vertex_coord_id_0comp1 +
        tmp_coords_jac_2__6 * tmp_coords_jac_9__6;
    const double tmp_coords_jac_11__6 =
        macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_12__6 =
        macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_13__6 =
        tmp_coords_jac_12__6 * tmp_coords_jac_2__6;
    const double tmp_coords_jac_14__6 =
        tmp_coords_jac_13__6 + tmp_coords_jac_11__6 * tmp_coords_jac_5__6;
    const double tmp_coords_jac_15__6 =
        macro_vertex_coord_id_3comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_16__6 =
        macro_vertex_coord_id_0comp2 +
        tmp_coords_jac_15__6 * tmp_coords_jac_2__6;
    const double tmp_coords_jac_17__6 =
        macro_vertex_coord_id_1comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_18__6 =
        macro_vertex_coord_id_2comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_19__6 =
        tmp_coords_jac_18__6 * tmp_coords_jac_2__6;
    const double tmp_coords_jac_20__6 =
        tmp_coords_jac_19__6 + tmp_coords_jac_17__6 * tmp_coords_jac_5__6;
    const double tmp_coords_jac_21__6 =
        tmp_coords_jac_2__6 * tmp_coords_jac_4__6;
    const double tmp_coords_jac_22__6 =
        tmp_coords_jac_11__6 * tmp_coords_jac_2__6;
    const double tmp_coords_jac_23__6 =
        tmp_coords_jac_17__6 * tmp_coords_jac_2__6;
    const double tmp_coords_jac_24__6 =
        macro_vertex_coord_id_0comp0 +
        tmp_coords_jac_0__6 * tmp_coords_jac_5__6;
    const double tmp_coords_jac_25__6 =
        macro_vertex_coord_id_0comp1 +
        tmp_coords_jac_5__6 * tmp_coords_jac_9__6;
    const double tmp_coords_jac_26__6 =
        macro_vertex_coord_id_0comp2 +
        tmp_coords_jac_15__6 * tmp_coords_jac_5__6;
    const double p_affine_const_0_0__6 =
        tmp_coords_jac_3__6 + tmp_coords_jac_8__6;
    const double p_affine_const_0_1__6 =
        tmp_coords_jac_10__6 + tmp_coords_jac_14__6;
    const double p_affine_const_0_2__6 =
        tmp_coords_jac_16__6 + tmp_coords_jac_20__6;
    const double p_affine_const_1_0__6 =
        tmp_coords_jac_21__6 + tmp_coords_jac_3__6 +
        tmp_coords_jac_5__6 * tmp_coords_jac_6__6;
    const double p_affine_const_1_1__6 =
        tmp_coords_jac_10__6 + tmp_coords_jac_22__6 +
        tmp_coords_jac_12__6 * tmp_coords_jac_5__6;
    const double p_affine_const_1_2__6 =
        tmp_coords_jac_16__6 + tmp_coords_jac_23__6 +
        tmp_coords_jac_18__6 * tmp_coords_jac_5__6;
    const double p_affine_const_2_0__6 =
        tmp_coords_jac_21__6 + tmp_coords_jac_24__6 + tmp_coords_jac_7__6;
    const double p_affine_const_2_1__6 =
        tmp_coords_jac_13__6 + tmp_coords_jac_22__6 + tmp_coords_jac_25__6;
    const double p_affine_const_2_2__6 =
        tmp_coords_jac_19__6 + tmp_coords_jac_23__6 + tmp_coords_jac_26__6;
    const double p_affine_const_3_0__6 =
        tmp_coords_jac_24__6 + tmp_coords_jac_8__6;
    const double p_affine_const_3_1__6 =
        tmp_coords_jac_14__6 + tmp_coords_jac_25__6;
    const double p_affine_const_3_2__6 =
        tmp_coords_jac_20__6 + tmp_coords_jac_26__6;
    const double jac_affine_0_0__6 =
        p_affine_const_1_0__6 - p_affine_const_0_0__6;
    const double jac_affine_0_1__6 =
        p_affine_const_2_0__6 - p_affine_const_0_0__6;
    const double jac_affine_0_2__6 =
        p_affine_const_3_0__6 - p_affine_const_0_0__6;
    const double jac_affine_1_0__6 =
        p_affine_const_1_1__6 - p_affine_const_0_1__6;
    const double jac_affine_1_1__6 =
        p_affine_const_2_1__6 - p_affine_const_0_1__6;
    const double tmp_coords_jac_31__5 = jac_affine_0_2__6 * jac_affine_1_1__6;
    const double jac_affine_1_2__6 =
        p_affine_const_3_1__6 - p_affine_const_0_1__6;
    const double tmp_coords_jac_29__6 = jac_affine_0_1__6 * jac_affine_1_2__6;
    const double jac_affine_2_0__6 =
        p_affine_const_1_2__6 - p_affine_const_0_2__6;
    const double jac_affine_2_1__6 =
        p_affine_const_2_2__6 - p_affine_const_0_2__6;
    const double tmp_coords_jac_28__6 = jac_affine_1_2__6 * jac_affine_2_1__6;
    const double jac_affine_2_2__6 =
        p_affine_const_3_2__6 - p_affine_const_0_2__6;
    const double tmp_coords_jac_27__6 = jac_affine_1_1__6 * jac_affine_2_2__6;
    const double tmp_coords_jac_30__6 = jac_affine_0_1__6 * jac_affine_2_2__6;
    const double tmp_coords_jac_32__5 =
        jac_affine_0_0__6 * tmp_coords_jac_27__6 +
        jac_affine_2_0__6 * tmp_coords_jac_29__6 -
        jac_affine_0_0__6 * tmp_coords_jac_28__6 -
        jac_affine_1_0__6 * tmp_coords_jac_30__6 -
        jac_affine_2_0__6 * tmp_coords_jac_31__5 +
        jac_affine_0_2__6 * jac_affine_1_0__6 * jac_affine_2_1__6;
    const double tmp_coords_jac_33__5 = 1.0 / tmp_coords_jac_32__5;
    const double jac_affine_inv_0_0__6 =
        tmp_coords_jac_33__5 * (tmp_coords_jac_27__6 - tmp_coords_jac_28__6);
    const double jac_affine_inv_0_1__6 =
        tmp_coords_jac_33__5 *
        (-1.0 * tmp_coords_jac_30__6 + jac_affine_0_2__6 * jac_affine_2_1__6);
    const double jac_affine_inv_0_2__6 =
        tmp_coords_jac_33__5 * (tmp_coords_jac_29__6 - tmp_coords_jac_31__5);
    const double jac_affine_inv_1_0__6 =
        tmp_coords_jac_33__5 * (jac_affine_1_2__6 * jac_affine_2_0__6 -
                                jac_affine_1_0__6 * jac_affine_2_2__6);
    const double jac_affine_inv_1_1__6 =
        tmp_coords_jac_33__5 * (jac_affine_0_0__6 * jac_affine_2_2__6 -
                                jac_affine_0_2__6 * jac_affine_2_0__6);
    const double jac_affine_inv_1_2__6 =
        tmp_coords_jac_33__5 * (jac_affine_0_2__6 * jac_affine_1_0__6 -
                                jac_affine_0_0__6 * jac_affine_1_2__6);
    const double jac_affine_inv_2_0__6 =
        tmp_coords_jac_33__5 * (jac_affine_1_0__6 * jac_affine_2_1__6 -
                                jac_affine_1_1__6 * jac_affine_2_0__6);
    const double jac_affine_inv_2_1__6 =
        tmp_coords_jac_33__5 * (jac_affine_0_1__6 * jac_affine_2_0__6 -
                                jac_affine_0_0__6 * jac_affine_2_1__6);
    const double jac_affine_inv_2_2__6 =
        tmp_coords_jac_33__5 * (jac_affine_0_0__6 * jac_affine_1_1__6 -
                                jac_affine_0_1__6 * jac_affine_1_0__6);
    const double abs_det_jac_affine__6 = abs(tmp_coords_jac_32__5);
    double phi_0_0__6[4] = {0.25, 0.25, 0.25, 0.25};
    double tabulated_and_untitled_0_0__6[10] = {
        abs_det_jac_affine__6 *
            ((-1.0 * jac_affine_inv_0_0__6 - jac_affine_inv_1_0__6 -
              jac_affine_inv_2_0__6) *
                 (-1.0 * jac_affine_inv_0_0__6 - jac_affine_inv_1_0__6 -
                  jac_affine_inv_2_0__6) +
             (-1.0 * jac_affine_inv_0_1__6 - jac_affine_inv_1_1__6 -
              jac_affine_inv_2_1__6) *
                 (-1.0 * jac_affine_inv_0_1__6 - jac_affine_inv_1_1__6 -
                  jac_affine_inv_2_1__6) +
             (-1.0 * jac_affine_inv_0_2__6 - jac_affine_inv_1_2__6 -
              jac_affine_inv_2_2__6) *
                 (-1.0 * jac_affine_inv_0_2__6 - jac_affine_inv_1_2__6 -
                  jac_affine_inv_2_2__6)),
        abs_det_jac_affine__6 *
            (jac_affine_inv_0_0__6 *
                 (-1.0 * jac_affine_inv_0_0__6 - jac_affine_inv_1_0__6 -
                  jac_affine_inv_2_0__6) +
             jac_affine_inv_0_1__6 *
                 (-1.0 * jac_affine_inv_0_1__6 - jac_affine_inv_1_1__6 -
                  jac_affine_inv_2_1__6) +
             jac_affine_inv_0_2__6 *
                 (-1.0 * jac_affine_inv_0_2__6 - jac_affine_inv_1_2__6 -
                  jac_affine_inv_2_2__6)),
        abs_det_jac_affine__6 *
            (jac_affine_inv_1_0__6 *
                 (-1.0 * jac_affine_inv_0_0__6 - jac_affine_inv_1_0__6 -
                  jac_affine_inv_2_0__6) +
             jac_affine_inv_1_1__6 *
                 (-1.0 * jac_affine_inv_0_1__6 - jac_affine_inv_1_1__6 -
                  jac_affine_inv_2_1__6) +
             jac_affine_inv_1_2__6 *
                 (-1.0 * jac_affine_inv_0_2__6 - jac_affine_inv_1_2__6 -
                  jac_affine_inv_2_2__6)),
        abs_det_jac_affine__6 *
            (jac_affine_inv_2_0__6 *
                 (-1.0 * jac_affine_inv_0_0__6 - jac_affine_inv_1_0__6 -
                  jac_affine_inv_2_0__6) +
             jac_affine_inv_2_1__6 *
                 (-1.0 * jac_affine_inv_0_1__6 - jac_affine_inv_1_1__6 -
                  jac_affine_inv_2_1__6) +
             jac_affine_inv_2_2__6 *
                 (-1.0 * jac_affine_inv_0_2__6 - jac_affine_inv_1_2__6 -
                  jac_affine_inv_2_2__6)),
        abs_det_jac_affine__6 * (jac_affine_inv_0_0__6 * jac_affine_inv_0_0__6 +
                                 jac_affine_inv_0_1__6 * jac_affine_inv_0_1__6 +
                                 jac_affine_inv_0_2__6 * jac_affine_inv_0_2__6),
        abs_det_jac_affine__6 * (jac_affine_inv_0_0__6 * jac_affine_inv_1_0__6 +
                                 jac_affine_inv_0_1__6 * jac_affine_inv_1_1__6 +
                                 jac_affine_inv_0_2__6 * jac_affine_inv_1_2__6),
        abs_det_jac_affine__6 * (jac_affine_inv_0_0__6 * jac_affine_inv_2_0__6 +
                                 jac_affine_inv_0_1__6 * jac_affine_inv_2_1__6 +
                                 jac_affine_inv_0_2__6 * jac_affine_inv_2_2__6),
        abs_det_jac_affine__6 * (jac_affine_inv_1_0__6 * jac_affine_inv_1_0__6 +
                                 jac_affine_inv_1_1__6 * jac_affine_inv_1_1__6 +
                                 jac_affine_inv_1_2__6 * jac_affine_inv_1_2__6),
        abs_det_jac_affine__6 * (jac_affine_inv_1_0__6 * jac_affine_inv_2_0__6 +
                                 jac_affine_inv_1_1__6 * jac_affine_inv_2_1__6 +
                                 jac_affine_inv_1_2__6 * jac_affine_inv_2_2__6),
        abs_det_jac_affine__6 *
            (jac_affine_inv_2_0__6 * jac_affine_inv_2_0__6 +
             jac_affine_inv_2_1__6 * jac_affine_inv_2_1__6 +
             jac_affine_inv_2_2__6 * jac_affine_inv_2_2__6)};
    const double tmp_coords_jac_0__5 =
        macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_1__5 =
        1.0 * (1.0 / micro_edges_per_macro_edge_float);
    const double tmp_coords_jac_2__5 = tmp_coords_jac_1__5 * 0.0;
    const double tmp_coords_jac_3__5 =
        tmp_coords_jac_0__5 * tmp_coords_jac_2__5;
    const double tmp_coords_jac_4__5 =
        macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_5__5 = tmp_coords_jac_1__5 * 1.0;
    const double tmp_coords_jac_6__5 =
        tmp_coords_jac_4__5 * tmp_coords_jac_5__5;
    const double tmp_coords_jac_7__5 =
        macro_vertex_coord_id_3comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_8__5 =
        macro_vertex_coord_id_0comp0 + tmp_coords_jac_6__5 +
        tmp_coords_jac_2__5 * tmp_coords_jac_7__5;
    const double tmp_coords_jac_9__5 =
        macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_10__5 =
        tmp_coords_jac_2__5 * tmp_coords_jac_9__5;
    const double tmp_coords_jac_11__5 =
        macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_12__5 =
        tmp_coords_jac_11__5 * tmp_coords_jac_5__5;
    const double tmp_coords_jac_13__5 =
        macro_vertex_coord_id_3comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_14__5 =
        macro_vertex_coord_id_0comp1 + tmp_coords_jac_12__5 +
        tmp_coords_jac_13__5 * tmp_coords_jac_2__5;
    const double tmp_coords_jac_15__5 =
        macro_vertex_coord_id_1comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_16__5 =
        tmp_coords_jac_15__5 * tmp_coords_jac_2__5;
    const double tmp_coords_jac_17__5 =
        macro_vertex_coord_id_2comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_18__5 =
        tmp_coords_jac_17__5 * tmp_coords_jac_5__5;
    const double tmp_coords_jac_19__5 =
        macro_vertex_coord_id_3comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_20__5 =
        macro_vertex_coord_id_0comp2 + tmp_coords_jac_18__5 +
        tmp_coords_jac_19__5 * tmp_coords_jac_2__5;
    const double tmp_coords_jac_21__5 =
        tmp_coords_jac_0__5 * tmp_coords_jac_5__5;
    const double tmp_coords_jac_22__5 =
        tmp_coords_jac_5__5 * tmp_coords_jac_9__5;
    const double tmp_coords_jac_23__5 =
        tmp_coords_jac_15__5 * tmp_coords_jac_5__5;
    const double tmp_coords_jac_24__5 =
        macro_vertex_coord_id_0comp0 +
        tmp_coords_jac_5__5 * tmp_coords_jac_7__5;
    const double tmp_coords_jac_25__5 =
        macro_vertex_coord_id_0comp1 +
        tmp_coords_jac_13__5 * tmp_coords_jac_5__5;
    const double tmp_coords_jac_26__5 =
        macro_vertex_coord_id_0comp2 +
        tmp_coords_jac_19__5 * tmp_coords_jac_5__5;
    const double p_affine_const_0_0__5 =
        tmp_coords_jac_3__5 + tmp_coords_jac_8__5;
    const double p_affine_const_0_1__5 =
        tmp_coords_jac_10__5 + tmp_coords_jac_14__5;
    const double p_affine_const_0_2__5 =
        tmp_coords_jac_16__5 + tmp_coords_jac_20__5;
    const double p_affine_const_1_0__5 =
        tmp_coords_jac_21__5 + tmp_coords_jac_8__5;
    const double p_affine_const_1_1__5 =
        tmp_coords_jac_14__5 + tmp_coords_jac_22__5;
    const double p_affine_const_1_2__5 =
        tmp_coords_jac_20__5 + tmp_coords_jac_23__5;
    const double p_affine_const_2_0__5 =
        tmp_coords_jac_21__5 + tmp_coords_jac_24__5 +
        tmp_coords_jac_2__5 * tmp_coords_jac_4__5;
    const double p_affine_const_2_1__5 =
        tmp_coords_jac_22__5 + tmp_coords_jac_25__5 +
        tmp_coords_jac_11__5 * tmp_coords_jac_2__5;
    const double p_affine_const_2_2__5 =
        tmp_coords_jac_23__5 + tmp_coords_jac_26__5 +
        tmp_coords_jac_17__5 * tmp_coords_jac_2__5;
    const double p_affine_const_3_0__5 =
        tmp_coords_jac_24__5 + tmp_coords_jac_3__5 + tmp_coords_jac_6__5;
    const double p_affine_const_3_1__5 =
        tmp_coords_jac_10__5 + tmp_coords_jac_12__5 + tmp_coords_jac_25__5;
    const double p_affine_const_3_2__5 =
        tmp_coords_jac_16__5 + tmp_coords_jac_18__5 + tmp_coords_jac_26__5;
    const double jac_affine_0_0__5 =
        p_affine_const_1_0__5 - p_affine_const_0_0__5;
    const double jac_affine_0_1__5 =
        p_affine_const_2_0__5 - p_affine_const_0_0__5;
    const double jac_affine_0_2__5 =
        p_affine_const_3_0__5 - p_affine_const_0_0__5;
    const double jac_affine_1_0__5 =
        p_affine_const_1_1__5 - p_affine_const_0_1__5;
    const double jac_affine_1_1__5 =
        p_affine_const_2_1__5 - p_affine_const_0_1__5;
    const double tmp_coords_jac_31__4 = jac_affine_0_2__5 * jac_affine_1_1__5;
    const double jac_affine_1_2__5 =
        p_affine_const_3_1__5 - p_affine_const_0_1__5;
    const double tmp_coords_jac_29__5 = jac_affine_0_1__5 * jac_affine_1_2__5;
    const double jac_affine_2_0__5 =
        p_affine_const_1_2__5 - p_affine_const_0_2__5;
    const double jac_affine_2_1__5 =
        p_affine_const_2_2__5 - p_affine_const_0_2__5;
    const double tmp_coords_jac_28__5 = jac_affine_1_2__5 * jac_affine_2_1__5;
    const double jac_affine_2_2__5 =
        p_affine_const_3_2__5 - p_affine_const_0_2__5;
    const double tmp_coords_jac_27__5 = jac_affine_1_1__5 * jac_affine_2_2__5;
    const double tmp_coords_jac_30__5 = jac_affine_0_1__5 * jac_affine_2_2__5;
    const double tmp_coords_jac_32__4 =
        jac_affine_0_0__5 * tmp_coords_jac_27__5 +
        jac_affine_2_0__5 * tmp_coords_jac_29__5 -
        jac_affine_0_0__5 * tmp_coords_jac_28__5 -
        jac_affine_1_0__5 * tmp_coords_jac_30__5 -
        jac_affine_2_0__5 * tmp_coords_jac_31__4 +
        jac_affine_0_2__5 * jac_affine_1_0__5 * jac_affine_2_1__5;
    const double tmp_coords_jac_33__4 = 1.0 / tmp_coords_jac_32__4;
    const double jac_affine_inv_0_0__5 =
        tmp_coords_jac_33__4 * (tmp_coords_jac_27__5 - tmp_coords_jac_28__5);
    const double jac_affine_inv_0_1__5 =
        tmp_coords_jac_33__4 *
        (-1.0 * tmp_coords_jac_30__5 + jac_affine_0_2__5 * jac_affine_2_1__5);
    const double jac_affine_inv_0_2__5 =
        tmp_coords_jac_33__4 * (tmp_coords_jac_29__5 - tmp_coords_jac_31__4);
    const double jac_affine_inv_1_0__5 =
        tmp_coords_jac_33__4 * (jac_affine_1_2__5 * jac_affine_2_0__5 -
                                jac_affine_1_0__5 * jac_affine_2_2__5);
    const double jac_affine_inv_1_1__5 =
        tmp_coords_jac_33__4 * (jac_affine_0_0__5 * jac_affine_2_2__5 -
                                jac_affine_0_2__5 * jac_affine_2_0__5);
    const double jac_affine_inv_1_2__5 =
        tmp_coords_jac_33__4 * (jac_affine_0_2__5 * jac_affine_1_0__5 -
                                jac_affine_0_0__5 * jac_affine_1_2__5);
    const double jac_affine_inv_2_0__5 =
        tmp_coords_jac_33__4 * (jac_affine_1_0__5 * jac_affine_2_1__5 -
                                jac_affine_1_1__5 * jac_affine_2_0__5);
    const double jac_affine_inv_2_1__5 =
        tmp_coords_jac_33__4 * (jac_affine_0_1__5 * jac_affine_2_0__5 -
                                jac_affine_0_0__5 * jac_affine_2_1__5);
    const double jac_affine_inv_2_2__5 =
        tmp_coords_jac_33__4 * (jac_affine_0_0__5 * jac_affine_1_1__5 -
                                jac_affine_0_1__5 * jac_affine_1_0__5);
    const double abs_det_jac_affine__5 = abs(tmp_coords_jac_32__4);
    double phi_0_0__5[4] = {0.25, 0.25, 0.25, 0.25};
    double tabulated_and_untitled_0_0__5[10] = {
        abs_det_jac_affine__5 *
            ((-1.0 * jac_affine_inv_0_0__5 - jac_affine_inv_1_0__5 -
              jac_affine_inv_2_0__5) *
                 (-1.0 * jac_affine_inv_0_0__5 - jac_affine_inv_1_0__5 -
                  jac_affine_inv_2_0__5) +
             (-1.0 * jac_affine_inv_0_1__5 - jac_affine_inv_1_1__5 -
              jac_affine_inv_2_1__5) *
                 (-1.0 * jac_affine_inv_0_1__5 - jac_affine_inv_1_1__5 -
                  jac_affine_inv_2_1__5) +
             (-1.0 * jac_affine_inv_0_2__5 - jac_affine_inv_1_2__5 -
              jac_affine_inv_2_2__5) *
                 (-1.0 * jac_affine_inv_0_2__5 - jac_affine_inv_1_2__5 -
                  jac_affine_inv_2_2__5)),
        abs_det_jac_affine__5 *
            (jac_affine_inv_0_0__5 *
                 (-1.0 * jac_affine_inv_0_0__5 - jac_affine_inv_1_0__5 -
                  jac_affine_inv_2_0__5) +
             jac_affine_inv_0_1__5 *
                 (-1.0 * jac_affine_inv_0_1__5 - jac_affine_inv_1_1__5 -
                  jac_affine_inv_2_1__5) +
             jac_affine_inv_0_2__5 *
                 (-1.0 * jac_affine_inv_0_2__5 - jac_affine_inv_1_2__5 -
                  jac_affine_inv_2_2__5)),
        abs_det_jac_affine__5 *
            (jac_affine_inv_1_0__5 *
                 (-1.0 * jac_affine_inv_0_0__5 - jac_affine_inv_1_0__5 -
                  jac_affine_inv_2_0__5) +
             jac_affine_inv_1_1__5 *
                 (-1.0 * jac_affine_inv_0_1__5 - jac_affine_inv_1_1__5 -
                  jac_affine_inv_2_1__5) +
             jac_affine_inv_1_2__5 *
                 (-1.0 * jac_affine_inv_0_2__5 - jac_affine_inv_1_2__5 -
                  jac_affine_inv_2_2__5)),
        abs_det_jac_affine__5 *
            (jac_affine_inv_2_0__5 *
                 (-1.0 * jac_affine_inv_0_0__5 - jac_affine_inv_1_0__5 -
                  jac_affine_inv_2_0__5) +
             jac_affine_inv_2_1__5 *
                 (-1.0 * jac_affine_inv_0_1__5 - jac_affine_inv_1_1__5 -
                  jac_affine_inv_2_1__5) +
             jac_affine_inv_2_2__5 *
                 (-1.0 * jac_affine_inv_0_2__5 - jac_affine_inv_1_2__5 -
                  jac_affine_inv_2_2__5)),
        abs_det_jac_affine__5 * (jac_affine_inv_0_0__5 * jac_affine_inv_0_0__5 +
                                 jac_affine_inv_0_1__5 * jac_affine_inv_0_1__5 +
                                 jac_affine_inv_0_2__5 * jac_affine_inv_0_2__5),
        abs_det_jac_affine__5 * (jac_affine_inv_0_0__5 * jac_affine_inv_1_0__5 +
                                 jac_affine_inv_0_1__5 * jac_affine_inv_1_1__5 +
                                 jac_affine_inv_0_2__5 * jac_affine_inv_1_2__5),
        abs_det_jac_affine__5 * (jac_affine_inv_0_0__5 * jac_affine_inv_2_0__5 +
                                 jac_affine_inv_0_1__5 * jac_affine_inv_2_1__5 +
                                 jac_affine_inv_0_2__5 * jac_affine_inv_2_2__5),
        abs_det_jac_affine__5 * (jac_affine_inv_1_0__5 * jac_affine_inv_1_0__5 +
                                 jac_affine_inv_1_1__5 * jac_affine_inv_1_1__5 +
                                 jac_affine_inv_1_2__5 * jac_affine_inv_1_2__5),
        abs_det_jac_affine__5 * (jac_affine_inv_1_0__5 * jac_affine_inv_2_0__5 +
                                 jac_affine_inv_1_1__5 * jac_affine_inv_2_1__5 +
                                 jac_affine_inv_1_2__5 * jac_affine_inv_2_2__5),
        abs_det_jac_affine__5 *
            (jac_affine_inv_2_0__5 * jac_affine_inv_2_0__5 +
             jac_affine_inv_2_1__5 * jac_affine_inv_2_1__5 +
             jac_affine_inv_2_2__5 * jac_affine_inv_2_2__5)};
    const double tmp_coords_jac_0 =
        macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_1 =
        1.0 * (1.0 / micro_edges_per_macro_edge_float);
    const double tmp_coords_jac_2 = tmp_coords_jac_1 * 0.0;
    const double tmp_coords_jac_3 = tmp_coords_jac_0 * tmp_coords_jac_2;
    const double tmp_coords_jac_4 =
        macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_5 = tmp_coords_jac_2 * tmp_coords_jac_4;
    const double tmp_coords_jac_6 =
        macro_vertex_coord_id_3comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_7 = tmp_coords_jac_2 * tmp_coords_jac_6;
    const double tmp_coords_jac_8 =
        macro_vertex_coord_id_0comp0 + tmp_coords_jac_5 + tmp_coords_jac_7;
    const double tmp_coords_jac_9 =
        macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_10 = tmp_coords_jac_2 * tmp_coords_jac_9;
    const double tmp_coords_jac_11 =
        macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_12 = tmp_coords_jac_11 * tmp_coords_jac_2;
    const double tmp_coords_jac_13 =
        macro_vertex_coord_id_3comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_14 = tmp_coords_jac_13 * tmp_coords_jac_2;
    const double tmp_coords_jac_15 =
        macro_vertex_coord_id_0comp1 + tmp_coords_jac_12 + tmp_coords_jac_14;
    const double tmp_coords_jac_16 =
        macro_vertex_coord_id_1comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_17 = tmp_coords_jac_16 * tmp_coords_jac_2;
    const double tmp_coords_jac_18 =
        macro_vertex_coord_id_2comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_19 = tmp_coords_jac_18 * tmp_coords_jac_2;
    const double tmp_coords_jac_20 =
        macro_vertex_coord_id_3comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_21 = tmp_coords_jac_2 * tmp_coords_jac_20;
    const double tmp_coords_jac_22 =
        macro_vertex_coord_id_0comp2 + tmp_coords_jac_19 + tmp_coords_jac_21;
    const double tmp_coords_jac_23 = tmp_coords_jac_1 * 1.0;
    const double tmp_coords_jac_24 =
        macro_vertex_coord_id_0comp0 + tmp_coords_jac_3;
    const double tmp_coords_jac_25 =
        macro_vertex_coord_id_0comp1 + tmp_coords_jac_10;
    const double tmp_coords_jac_26 =
        macro_vertex_coord_id_0comp2 + tmp_coords_jac_17;
    const double p_affine_const_0_0 = tmp_coords_jac_3 + tmp_coords_jac_8;
    const double p_affine_const_0_1 = tmp_coords_jac_10 + tmp_coords_jac_15;
    const double p_affine_const_0_2 = tmp_coords_jac_17 + tmp_coords_jac_22;
    const double p_affine_const_1_0 =
        tmp_coords_jac_8 + tmp_coords_jac_0 * tmp_coords_jac_23;
    const double p_affine_const_1_1 =
        tmp_coords_jac_15 + tmp_coords_jac_23 * tmp_coords_jac_9;
    const double p_affine_const_1_2 =
        tmp_coords_jac_22 + tmp_coords_jac_16 * tmp_coords_jac_23;
    const double p_affine_const_2_0 = tmp_coords_jac_24 + tmp_coords_jac_7 +
                                      tmp_coords_jac_23 * tmp_coords_jac_4;
    const double p_affine_const_2_1 = tmp_coords_jac_14 + tmp_coords_jac_25 +
                                      tmp_coords_jac_11 * tmp_coords_jac_23;
    const double p_affine_const_2_2 = tmp_coords_jac_21 + tmp_coords_jac_26 +
                                      tmp_coords_jac_18 * tmp_coords_jac_23;
    const double p_affine_const_3_0 = tmp_coords_jac_24 + tmp_coords_jac_5 +
                                      tmp_coords_jac_23 * tmp_coords_jac_6;
    const double p_affine_const_3_1 = tmp_coords_jac_12 + tmp_coords_jac_25 +
                                      tmp_coords_jac_13 * tmp_coords_jac_23;
    const double p_affine_const_3_2 = tmp_coords_jac_19 + tmp_coords_jac_26 +
                                      tmp_coords_jac_20 * tmp_coords_jac_23;
    const double jac_affine_0_0 = p_affine_const_1_0 - p_affine_const_0_0;
    const double jac_affine_0_1 = p_affine_const_2_0 - p_affine_const_0_0;
    const double jac_affine_0_2 = p_affine_const_3_0 - p_affine_const_0_0;
    const double jac_affine_1_0 = p_affine_const_1_1 - p_affine_const_0_1;
    const double jac_affine_1_1 = p_affine_const_2_1 - p_affine_const_0_1;
    const double tmp_coords_jac_31 = jac_affine_0_2 * jac_affine_1_1;
    const double jac_affine_1_2 = p_affine_const_3_1 - p_affine_const_0_1;
    const double tmp_coords_jac_29 = jac_affine_0_1 * jac_affine_1_2;
    const double jac_affine_2_0 = p_affine_const_1_2 - p_affine_const_0_2;
    const double jac_affine_2_1 = p_affine_const_2_2 - p_affine_const_0_2;
    const double tmp_coords_jac_28 = jac_affine_1_2 * jac_affine_2_1;
    const double jac_affine_2_2 = p_affine_const_3_2 - p_affine_const_0_2;
    const double tmp_coords_jac_27 = jac_affine_1_1 * jac_affine_2_2;
    const double tmp_coords_jac_30 = jac_affine_0_1 * jac_affine_2_2;
    const double tmp_coords_jac_32 =
        jac_affine_0_0 * tmp_coords_jac_27 +
        jac_affine_2_0 * tmp_coords_jac_29 -
        jac_affine_0_0 * tmp_coords_jac_28 -
        jac_affine_1_0 * tmp_coords_jac_30 -
        jac_affine_2_0 * tmp_coords_jac_31 +
        jac_affine_0_2 * jac_affine_1_0 * jac_affine_2_1;
    const double tmp_coords_jac_33 = 1.0 / tmp_coords_jac_32;
    const double jac_affine_inv_0_0 =
        tmp_coords_jac_33 * (tmp_coords_jac_27 - tmp_coords_jac_28);
    const double jac_affine_inv_0_1 =
        tmp_coords_jac_33 *
        (-1.0 * tmp_coords_jac_30 + jac_affine_0_2 * jac_affine_2_1);
    const double jac_affine_inv_0_2 =
        tmp_coords_jac_33 * (tmp_coords_jac_29 - tmp_coords_jac_31);
    const double jac_affine_inv_1_0 =
        tmp_coords_jac_33 *
        (jac_affine_1_2 * jac_affine_2_0 - jac_affine_1_0 * jac_affine_2_2);
    const double jac_affine_inv_1_1 =
        tmp_coords_jac_33 *
        (jac_affine_0_0 * jac_affine_2_2 - jac_affine_0_2 * jac_affine_2_0);
    const double jac_affine_inv_1_2 =
        tmp_coords_jac_33 *
        (jac_affine_0_2 * jac_affine_1_0 - jac_affine_0_0 * jac_affine_1_2);
    const double jac_affine_inv_2_0 =
        tmp_coords_jac_33 *
        (jac_affine_1_0 * jac_affine_2_1 - jac_affine_1_1 * jac_affine_2_0);
    const double jac_affine_inv_2_1 =
        tmp_coords_jac_33 *
        (jac_affine_0_1 * jac_affine_2_0 - jac_affine_0_0 * jac_affine_2_1);
    const double jac_affine_inv_2_2 =
        tmp_coords_jac_33 *
        (jac_affine_0_0 * jac_affine_1_1 - jac_affine_0_1 * jac_affine_1_0);
    const double abs_det_jac_affine = abs(tmp_coords_jac_32);
    double phi_0_0[4] = {0.25, 0.25, 0.25, 0.25};
    double tabulated_and_untitled_0_0[10] = {
        abs_det_jac_affine * ((-1.0 * jac_affine_inv_0_0 - jac_affine_inv_1_0 -
                               jac_affine_inv_2_0) *
                                  (-1.0 * jac_affine_inv_0_0 -
                                   jac_affine_inv_1_0 - jac_affine_inv_2_0) +
                              (-1.0 * jac_affine_inv_0_1 - jac_affine_inv_1_1 -
                               jac_affine_inv_2_1) *
                                  (-1.0 * jac_affine_inv_0_1 -
                                   jac_affine_inv_1_1 - jac_affine_inv_2_1) +
                              (-1.0 * jac_affine_inv_0_2 - jac_affine_inv_1_2 -
                               jac_affine_inv_2_2) *
                                  (-1.0 * jac_affine_inv_0_2 -
                                   jac_affine_inv_1_2 - jac_affine_inv_2_2)),
        abs_det_jac_affine *
            (jac_affine_inv_0_0 * (-1.0 * jac_affine_inv_0_0 -
                                   jac_affine_inv_1_0 - jac_affine_inv_2_0) +
             jac_affine_inv_0_1 * (-1.0 * jac_affine_inv_0_1 -
                                   jac_affine_inv_1_1 - jac_affine_inv_2_1) +
             jac_affine_inv_0_2 * (-1.0 * jac_affine_inv_0_2 -
                                   jac_affine_inv_1_2 - jac_affine_inv_2_2)),
        abs_det_jac_affine *
            (jac_affine_inv_1_0 * (-1.0 * jac_affine_inv_0_0 -
                                   jac_affine_inv_1_0 - jac_affine_inv_2_0) +
             jac_affine_inv_1_1 * (-1.0 * jac_affine_inv_0_1 -
                                   jac_affine_inv_1_1 - jac_affine_inv_2_1) +
             jac_affine_inv_1_2 * (-1.0 * jac_affine_inv_0_2 -
                                   jac_affine_inv_1_2 - jac_affine_inv_2_2)),
        abs_det_jac_affine *
            (jac_affine_inv_2_0 * (-1.0 * jac_affine_inv_0_0 -
                                   jac_affine_inv_1_0 - jac_affine_inv_2_0) +
             jac_affine_inv_2_1 * (-1.0 * jac_affine_inv_0_1 -
                                   jac_affine_inv_1_1 - jac_affine_inv_2_1) +
             jac_affine_inv_2_2 * (-1.0 * jac_affine_inv_0_2 -
                                   jac_affine_inv_1_2 - jac_affine_inv_2_2)),
        abs_det_jac_affine * (jac_affine_inv_0_0 * jac_affine_inv_0_0 +
                              jac_affine_inv_0_1 * jac_affine_inv_0_1 +
                              jac_affine_inv_0_2 * jac_affine_inv_0_2),
        abs_det_jac_affine * (jac_affine_inv_0_0 * jac_affine_inv_1_0 +
                              jac_affine_inv_0_1 * jac_affine_inv_1_1 +
                              jac_affine_inv_0_2 * jac_affine_inv_1_2),
        abs_det_jac_affine * (jac_affine_inv_0_0 * jac_affine_inv_2_0 +
                              jac_affine_inv_0_1 * jac_affine_inv_2_1 +
                              jac_affine_inv_0_2 * jac_affine_inv_2_2),
        abs_det_jac_affine * (jac_affine_inv_1_0 * jac_affine_inv_1_0 +
                              jac_affine_inv_1_1 * jac_affine_inv_1_1 +
                              jac_affine_inv_1_2 * jac_affine_inv_1_2),
        abs_det_jac_affine * (jac_affine_inv_1_0 * jac_affine_inv_2_0 +
                              jac_affine_inv_1_1 * jac_affine_inv_2_1 +
                              jac_affine_inv_1_2 * jac_affine_inv_2_2),
        abs_det_jac_affine * (jac_affine_inv_2_0 * jac_affine_inv_2_0 +
                              jac_affine_inv_2_1 * jac_affine_inv_2_1 +
                              jac_affine_inv_2_2 * jac_affine_inv_2_2)};
    for (int64_t ctr_2 = 0LL; ctr_2 < micro_edges_per_macro_edge;
         ctr_2 += 1LL) {
      for (int64_t ctr_1 = 0LL;
           ctr_1 < -1LL * ctr_2 + micro_edges_per_macro_edge; ctr_1 += 1LL) {
        {
          const int64_t __ctr_0__1_simd_stop =
              -2LL - ctr_1 - ctr_2 + micro_edges_per_macro_edge - 3LL;
          const int64_t __ctr_0__1_simd_step = 4LL;
          for (int64_t ctr_0__1 = 0LL; ctr_0__1 < __ctr_0__1_simd_stop;
               ctr_0__1 += __ctr_0__1_simd_step) {
            const __m256i ctr_0__4 =
                _mm256_add_epi64(_mm256_set1_epi64x(ctr_0__1),
                                 _mm256_set_epi64x(3LL, 2LL, 1LL, 0LL));
            {
              /* CellType.WHITE_UP */
              {
                const __m256d p_affine_0_0__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_0_1__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_0_2__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_0__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_1__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_2__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_0__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_1__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_2__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_0__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_1__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_2__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d src_dof_0__17 = _mm256_loadu_pd(
                    &_data_src[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d src_dof_1__17 = _mm256_loadu_pd(
                    &_data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d src_dof_2__17 = _mm256_loadu_pd(
                    &_data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d src_dof_3__17 = _mm256_loadu_pd(
                    &_data_src[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_0__17 = _mm256_loadu_pd(
                    &_data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_1__17 = _mm256_loadu_pd(
                    &_data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_2__17 = _mm256_loadu_pd(
                    &_data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL + ctr_1) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_3__17 = _mm256_loadu_pd(
                    &_data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                             (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                __m256d q_acc_0_0__17 = _mm256_set1_pd(0.0);
                __m256d q_acc_0_1__17 = _mm256_set1_pd(0.0);
                __m256d q_acc_0_2__17 = _mm256_set1_pd(0.0);
                __m256d q_acc_0_3__17 = _mm256_set1_pd(0.0);
                __m256d q_acc_1_1__17 = _mm256_set1_pd(0.0);
                __m256d q_acc_1_2__17 = _mm256_set1_pd(0.0);
                __m256d q_acc_1_3__17 = _mm256_set1_pd(0.0);
                __m256d q_acc_2_2__17 = _mm256_set1_pd(0.0);
                __m256d q_acc_2_3__17 = _mm256_set1_pd(0.0);
                __m256d q_acc_3_3__17 = _mm256_set1_pd(0.0);
                for (int64_t q__16 = 0LL; q__16 < 1LL; q__16 += 1LL) {
                  const __m256d tmp_qloop_0__17 = _mm256_mul_pd(
                      _mm256_add_pd(
                          _mm256_add_pd(
                              _mm256_add_pd(
                                  _mm256_mul_pd(
                                      k_dof_0__17,
                                      _mm256_set1_pd(phi_0_0__10[4LL * q__16])),
                                  _mm256_mul_pd(
                                      k_dof_1__17,
                                      _mm256_set1_pd(
                                          phi_0_0__10[1LL + 4LL * q__16]))),
                              _mm256_mul_pd(
                                  k_dof_2__17,
                                  _mm256_set1_pd(
                                      phi_0_0__10[2LL + 4LL * q__16]))),
                          _mm256_mul_pd(
                              k_dof_3__17,
                              _mm256_set1_pd(phi_0_0__10[3LL + 4LL * q__16]))),
                      _mm256_set1_pd(q_w[q__16]));
                  const __m256d q_tmp_0_0__17 = _mm256_mul_pd(
                      tmp_qloop_0__17,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__10[10LL * q__16]));
                  const __m256d q_tmp_0_1__17 = _mm256_mul_pd(
                      tmp_qloop_0__17,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__10[1LL + 10LL * q__16]));
                  const __m256d q_tmp_0_2__17 = _mm256_mul_pd(
                      tmp_qloop_0__17,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__10[2LL + 10LL * q__16]));
                  const __m256d q_tmp_0_3__17 = _mm256_mul_pd(
                      tmp_qloop_0__17,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__10[3LL + 10LL * q__16]));
                  const __m256d q_tmp_1_1__17 = _mm256_mul_pd(
                      tmp_qloop_0__17,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__10[4LL + 10LL * q__16]));
                  const __m256d q_tmp_1_2__17 = _mm256_mul_pd(
                      tmp_qloop_0__17,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__10[5LL + 10LL * q__16]));
                  const __m256d q_tmp_1_3__17 = _mm256_mul_pd(
                      tmp_qloop_0__17,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__10[6LL + 10LL * q__16]));
                  const __m256d q_tmp_2_2__17 = _mm256_mul_pd(
                      tmp_qloop_0__17,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__10[7LL + 10LL * q__16]));
                  const __m256d q_tmp_2_3__17 = _mm256_mul_pd(
                      tmp_qloop_0__17,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__10[8LL + 10LL * q__16]));
                  const __m256d q_tmp_3_3__17 = _mm256_mul_pd(
                      tmp_qloop_0__17,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__10[9LL + 10LL * q__16]));
                  q_acc_0_0__17 = _mm256_add_pd(q_acc_0_0__17, q_tmp_0_0__17);
                  q_acc_0_1__17 = _mm256_add_pd(q_acc_0_1__17, q_tmp_0_1__17);
                  q_acc_0_2__17 = _mm256_add_pd(q_acc_0_2__17, q_tmp_0_2__17);
                  q_acc_0_3__17 = _mm256_add_pd(q_acc_0_3__17, q_tmp_0_3__17);
                  q_acc_1_1__17 = _mm256_add_pd(q_acc_1_1__17, q_tmp_1_1__17);
                  q_acc_1_2__17 = _mm256_add_pd(q_acc_1_2__17, q_tmp_1_2__17);
                  q_acc_1_3__17 = _mm256_add_pd(q_acc_1_3__17, q_tmp_1_3__17);
                  q_acc_2_2__17 = _mm256_add_pd(q_acc_2_2__17, q_tmp_2_2__17);
                  q_acc_2_3__17 = _mm256_add_pd(q_acc_2_3__17, q_tmp_2_3__17);
                  q_acc_3_3__17 = _mm256_add_pd(q_acc_3_3__17, q_tmp_3_3__17);
                }
                const __m256d elMatVec_0__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(q_acc_0_0__17, src_dof_0__17),
                            _mm256_mul_pd(q_acc_0_1__17, src_dof_1__17)),
                        _mm256_mul_pd(q_acc_0_2__17, src_dof_2__17)),
                    _mm256_mul_pd(q_acc_0_3__17, src_dof_3__17));
                const __m256d elMatVec_1__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(q_acc_0_1__17, src_dof_0__17),
                            _mm256_mul_pd(q_acc_1_1__17, src_dof_1__17)),
                        _mm256_mul_pd(q_acc_1_2__17, src_dof_2__17)),
                    _mm256_mul_pd(q_acc_1_3__17, src_dof_3__17));
                const __m256d elMatVec_2__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(q_acc_0_2__17, src_dof_0__17),
                            _mm256_mul_pd(q_acc_1_2__17, src_dof_1__17)),
                        _mm256_mul_pd(q_acc_2_2__17, src_dof_2__17)),
                    _mm256_mul_pd(q_acc_2_3__17, src_dof_3__17));
                const __m256d elMatVec_3__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(q_acc_0_3__17, src_dof_0__17),
                            _mm256_mul_pd(q_acc_1_3__17, src_dof_1__17)),
                        _mm256_mul_pd(q_acc_2_3__17, src_dof_2__17)),
                    _mm256_mul_pd(q_acc_3_3__17, src_dof_3__17));
                _mm256_storeu_pd(
                    &_data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatVec_0__17,
                        _mm256_loadu_pd(
                            &_data_dst
                                [-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (3LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                     ctr_1 +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatVec_1__17,
                        _mm256_loadu_pd(
                            &_data_dst
                                [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (3LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                     ctr_1 +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatVec_2__17,
                        _mm256_loadu_pd(
                            &_data_dst
                                [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (3LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL + ctr_1) * (2LL - ctr_2 +
                                                  micro_edges_per_macro_edge) +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatVec_3__17,
                        _mm256_loadu_pd(
                            &_data_dst
                                [-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                                 (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                     (1LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     ctr_1 +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
              }
            }
            {
              /* CellType.WHITE_DOWN */
              {
                const __m256d p_affine_0_0__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_0_1__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_0_2__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_0__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_1__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_2__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_0__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_1__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_2__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_0__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_1__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_2__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d src_dof_0__18 = _mm256_loadu_pd(
                    &_data_src[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d src_dof_1__18 = _mm256_loadu_pd(
                    &_data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d src_dof_2__18 = _mm256_loadu_pd(
                    &_data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d src_dof_3__18 = _mm256_loadu_pd(
                    &_data_src[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_0__18 = _mm256_loadu_pd(
                    &_data_k[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL + ctr_1) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_1__18 = _mm256_loadu_pd(
                    &_data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                             (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_2__18 = _mm256_loadu_pd(
                    &_data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                             (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL + ctr_1) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_3__18 = _mm256_loadu_pd(
                    &_data_k[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                             (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL + ctr_1) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                __m256d q_acc_0_0__18 = _mm256_set1_pd(0.0);
                __m256d q_acc_0_1__18 = _mm256_set1_pd(0.0);
                __m256d q_acc_0_2__18 = _mm256_set1_pd(0.0);
                __m256d q_acc_0_3__18 = _mm256_set1_pd(0.0);
                __m256d q_acc_1_1__18 = _mm256_set1_pd(0.0);
                __m256d q_acc_1_2__18 = _mm256_set1_pd(0.0);
                __m256d q_acc_1_3__18 = _mm256_set1_pd(0.0);
                __m256d q_acc_2_2__18 = _mm256_set1_pd(0.0);
                __m256d q_acc_2_3__18 = _mm256_set1_pd(0.0);
                __m256d q_acc_3_3__18 = _mm256_set1_pd(0.0);
                for (int64_t q__15 = 0LL; q__15 < 1LL; q__15 += 1LL) {
                  const __m256d tmp_qloop_0__18 = _mm256_mul_pd(
                      _mm256_add_pd(
                          _mm256_add_pd(
                              _mm256_add_pd(
                                  _mm256_mul_pd(
                                      k_dof_0__18,
                                      _mm256_set1_pd(phi_0_0__9[4LL * q__15])),
                                  _mm256_mul_pd(
                                      k_dof_1__18,
                                      _mm256_set1_pd(
                                          phi_0_0__9[1LL + 4LL * q__15]))),
                              _mm256_mul_pd(
                                  k_dof_2__18,
                                  _mm256_set1_pd(
                                      phi_0_0__9[2LL + 4LL * q__15]))),
                          _mm256_mul_pd(
                              k_dof_3__18,
                              _mm256_set1_pd(phi_0_0__9[3LL + 4LL * q__15]))),
                      _mm256_set1_pd(q_w[q__15]));
                  const __m256d q_tmp_0_0__18 = _mm256_mul_pd(
                      tmp_qloop_0__18,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__9[10LL * q__15]));
                  const __m256d q_tmp_0_1__18 = _mm256_mul_pd(
                      tmp_qloop_0__18,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__9[1LL + 10LL * q__15]));
                  const __m256d q_tmp_0_2__18 = _mm256_mul_pd(
                      tmp_qloop_0__18,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__9[2LL + 10LL * q__15]));
                  const __m256d q_tmp_0_3__18 = _mm256_mul_pd(
                      tmp_qloop_0__18,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__9[3LL + 10LL * q__15]));
                  const __m256d q_tmp_1_1__18 = _mm256_mul_pd(
                      tmp_qloop_0__18,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__9[4LL + 10LL * q__15]));
                  const __m256d q_tmp_1_2__18 = _mm256_mul_pd(
                      tmp_qloop_0__18,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__9[5LL + 10LL * q__15]));
                  const __m256d q_tmp_1_3__18 = _mm256_mul_pd(
                      tmp_qloop_0__18,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__9[6LL + 10LL * q__15]));
                  const __m256d q_tmp_2_2__18 = _mm256_mul_pd(
                      tmp_qloop_0__18,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__9[7LL + 10LL * q__15]));
                  const __m256d q_tmp_2_3__18 = _mm256_mul_pd(
                      tmp_qloop_0__18,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__9[8LL + 10LL * q__15]));
                  const __m256d q_tmp_3_3__18 = _mm256_mul_pd(
                      tmp_qloop_0__18,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__9[9LL + 10LL * q__15]));
                  q_acc_0_0__18 = _mm256_add_pd(q_acc_0_0__18, q_tmp_0_0__18);
                  q_acc_0_1__18 = _mm256_add_pd(q_acc_0_1__18, q_tmp_0_1__18);
                  q_acc_0_2__18 = _mm256_add_pd(q_acc_0_2__18, q_tmp_0_2__18);
                  q_acc_0_3__18 = _mm256_add_pd(q_acc_0_3__18, q_tmp_0_3__18);
                  q_acc_1_1__18 = _mm256_add_pd(q_acc_1_1__18, q_tmp_1_1__18);
                  q_acc_1_2__18 = _mm256_add_pd(q_acc_1_2__18, q_tmp_1_2__18);
                  q_acc_1_3__18 = _mm256_add_pd(q_acc_1_3__18, q_tmp_1_3__18);
                  q_acc_2_2__18 = _mm256_add_pd(q_acc_2_2__18, q_tmp_2_2__18);
                  q_acc_2_3__18 = _mm256_add_pd(q_acc_2_3__18, q_tmp_2_3__18);
                  q_acc_3_3__18 = _mm256_add_pd(q_acc_3_3__18, q_tmp_3_3__18);
                }
                const __m256d elMatVec_0__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(q_acc_0_0__18, src_dof_0__18),
                            _mm256_mul_pd(q_acc_0_1__18, src_dof_1__18)),
                        _mm256_mul_pd(q_acc_0_2__18, src_dof_2__18)),
                    _mm256_mul_pd(q_acc_0_3__18, src_dof_3__18));
                const __m256d elMatVec_1__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(q_acc_0_1__18, src_dof_0__18),
                            _mm256_mul_pd(q_acc_1_1__18, src_dof_1__18)),
                        _mm256_mul_pd(q_acc_1_2__18, src_dof_2__18)),
                    _mm256_mul_pd(q_acc_1_3__18, src_dof_3__18));
                const __m256d elMatVec_2__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(q_acc_0_2__18, src_dof_0__18),
                            _mm256_mul_pd(q_acc_1_2__18, src_dof_1__18)),
                        _mm256_mul_pd(q_acc_2_2__18, src_dof_2__18)),
                    _mm256_mul_pd(q_acc_2_3__18, src_dof_3__18));
                const __m256d elMatVec_3__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(q_acc_0_3__18, src_dof_0__18),
                            _mm256_mul_pd(q_acc_1_3__18, src_dof_1__18)),
                        _mm256_mul_pd(q_acc_2_3__18, src_dof_2__18)),
                    _mm256_mul_pd(q_acc_3_3__18, src_dof_3__18));
                _mm256_storeu_pd(
                    &_data_dst[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatVec_0__18,
                        _mm256_loadu_pd(
                            &_data_dst
                                [1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (3LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL + ctr_1) * (2LL - ctr_2 +
                                                  micro_edges_per_macro_edge) +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatVec_1__18,
                        _mm256_loadu_pd(
                            &_data_dst
                                [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                                 (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                     (1LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     ctr_1 +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatVec_2__18,
                        _mm256_loadu_pd(
                            &_data_dst
                                [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                                 (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                     (1LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL + ctr_1) * (1LL - ctr_2 +
                                                  micro_edges_per_macro_edge) +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_dst[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatVec_3__18,
                        _mm256_loadu_pd(
                            &_data_dst
                                [1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                                 (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                     (1LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL + ctr_1) * (1LL - ctr_2 +
                                                  micro_edges_per_macro_edge) +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
              }
            }
            {
              /* CellType.BLUE_UP */
              {
                const __m256d p_affine_0_0__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_0_1__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_0_2__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_0__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_1__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_2__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_0__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_1__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_2__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_0__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_1__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_2__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d src_dof_0__19 = _mm256_loadu_pd(
                    &_data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d src_dof_1__19 = _mm256_loadu_pd(
                    &_data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d src_dof_2__19 = _mm256_loadu_pd(
                    &_data_src[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d src_dof_3__19 = _mm256_loadu_pd(
                    &_data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_0__19 = _mm256_loadu_pd(
                    &_data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_1__19 = _mm256_loadu_pd(
                    &_data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL + ctr_1) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_2__19 = _mm256_loadu_pd(
                    &_data_k[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL + ctr_1) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_3__19 = _mm256_loadu_pd(
                    &_data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                             (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                __m256d q_acc_0_0__19 = _mm256_set1_pd(0.0);
                __m256d q_acc_0_1__19 = _mm256_set1_pd(0.0);
                __m256d q_acc_0_2__19 = _mm256_set1_pd(0.0);
                __m256d q_acc_0_3__19 = _mm256_set1_pd(0.0);
                __m256d q_acc_1_1__19 = _mm256_set1_pd(0.0);
                __m256d q_acc_1_2__19 = _mm256_set1_pd(0.0);
                __m256d q_acc_1_3__19 = _mm256_set1_pd(0.0);
                __m256d q_acc_2_2__19 = _mm256_set1_pd(0.0);
                __m256d q_acc_2_3__19 = _mm256_set1_pd(0.0);
                __m256d q_acc_3_3__19 = _mm256_set1_pd(0.0);
                for (int64_t q__14 = 0LL; q__14 < 1LL; q__14 += 1LL) {
                  const __m256d tmp_qloop_0__19 = _mm256_mul_pd(
                      _mm256_add_pd(
                          _mm256_add_pd(
                              _mm256_add_pd(
                                  _mm256_mul_pd(
                                      k_dof_0__19,
                                      _mm256_set1_pd(phi_0_0__8[4LL * q__14])),
                                  _mm256_mul_pd(
                                      k_dof_1__19,
                                      _mm256_set1_pd(
                                          phi_0_0__8[1LL + 4LL * q__14]))),
                              _mm256_mul_pd(
                                  k_dof_2__19,
                                  _mm256_set1_pd(
                                      phi_0_0__8[2LL + 4LL * q__14]))),
                          _mm256_mul_pd(
                              k_dof_3__19,
                              _mm256_set1_pd(phi_0_0__8[3LL + 4LL * q__14]))),
                      _mm256_set1_pd(q_w[q__14]));
                  const __m256d q_tmp_0_0__19 = _mm256_mul_pd(
                      tmp_qloop_0__19,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__8[10LL * q__14]));
                  const __m256d q_tmp_0_1__19 = _mm256_mul_pd(
                      tmp_qloop_0__19,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__8[1LL + 10LL * q__14]));
                  const __m256d q_tmp_0_2__19 = _mm256_mul_pd(
                      tmp_qloop_0__19,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__8[2LL + 10LL * q__14]));
                  const __m256d q_tmp_0_3__19 = _mm256_mul_pd(
                      tmp_qloop_0__19,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__8[3LL + 10LL * q__14]));
                  const __m256d q_tmp_1_1__19 = _mm256_mul_pd(
                      tmp_qloop_0__19,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__8[4LL + 10LL * q__14]));
                  const __m256d q_tmp_1_2__19 = _mm256_mul_pd(
                      tmp_qloop_0__19,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__8[5LL + 10LL * q__14]));
                  const __m256d q_tmp_1_3__19 = _mm256_mul_pd(
                      tmp_qloop_0__19,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__8[6LL + 10LL * q__14]));
                  const __m256d q_tmp_2_2__19 = _mm256_mul_pd(
                      tmp_qloop_0__19,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__8[7LL + 10LL * q__14]));
                  const __m256d q_tmp_2_3__19 = _mm256_mul_pd(
                      tmp_qloop_0__19,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__8[8LL + 10LL * q__14]));
                  const __m256d q_tmp_3_3__19 = _mm256_mul_pd(
                      tmp_qloop_0__19,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__8[9LL + 10LL * q__14]));
                  q_acc_0_0__19 = _mm256_add_pd(q_acc_0_0__19, q_tmp_0_0__19);
                  q_acc_0_1__19 = _mm256_add_pd(q_acc_0_1__19, q_tmp_0_1__19);
                  q_acc_0_2__19 = _mm256_add_pd(q_acc_0_2__19, q_tmp_0_2__19);
                  q_acc_0_3__19 = _mm256_add_pd(q_acc_0_3__19, q_tmp_0_3__19);
                  q_acc_1_1__19 = _mm256_add_pd(q_acc_1_1__19, q_tmp_1_1__19);
                  q_acc_1_2__19 = _mm256_add_pd(q_acc_1_2__19, q_tmp_1_2__19);
                  q_acc_1_3__19 = _mm256_add_pd(q_acc_1_3__19, q_tmp_1_3__19);
                  q_acc_2_2__19 = _mm256_add_pd(q_acc_2_2__19, q_tmp_2_2__19);
                  q_acc_2_3__19 = _mm256_add_pd(q_acc_2_3__19, q_tmp_2_3__19);
                  q_acc_3_3__19 = _mm256_add_pd(q_acc_3_3__19, q_tmp_3_3__19);
                }
                const __m256d elMatVec_0__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(q_acc_0_0__19, src_dof_0__19),
                            _mm256_mul_pd(q_acc_0_1__19, src_dof_1__19)),
                        _mm256_mul_pd(q_acc_0_2__19, src_dof_2__19)),
                    _mm256_mul_pd(q_acc_0_3__19, src_dof_3__19));
                const __m256d elMatVec_1__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(q_acc_0_1__19, src_dof_0__19),
                            _mm256_mul_pd(q_acc_1_1__19, src_dof_1__19)),
                        _mm256_mul_pd(q_acc_1_2__19, src_dof_2__19)),
                    _mm256_mul_pd(q_acc_1_3__19, src_dof_3__19));
                const __m256d elMatVec_2__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(q_acc_0_2__19, src_dof_0__19),
                            _mm256_mul_pd(q_acc_1_2__19, src_dof_1__19)),
                        _mm256_mul_pd(q_acc_2_2__19, src_dof_2__19)),
                    _mm256_mul_pd(q_acc_2_3__19, src_dof_3__19));
                const __m256d elMatVec_3__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(q_acc_0_3__19, src_dof_0__19),
                            _mm256_mul_pd(q_acc_1_3__19, src_dof_1__19)),
                        _mm256_mul_pd(q_acc_2_3__19, src_dof_2__19)),
                    _mm256_mul_pd(q_acc_3_3__19, src_dof_3__19));
                _mm256_storeu_pd(
                    &_data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatVec_0__19,
                        _mm256_loadu_pd(
                            &_data_dst
                                [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (3LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                     ctr_1 +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatVec_1__19,
                        _mm256_loadu_pd(
                            &_data_dst
                                [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (3LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL + ctr_1) * (2LL - ctr_2 +
                                                  micro_edges_per_macro_edge) +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_dst[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatVec_2__19,
                        _mm256_loadu_pd(
                            &_data_dst
                                [1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (3LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL + ctr_1) * (2LL - ctr_2 +
                                                  micro_edges_per_macro_edge) +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatVec_3__19,
                        _mm256_loadu_pd(
                            &_data_dst
                                [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                                 (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                     (1LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     ctr_1 +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
              }
            }
            {
              /* CellType.BLUE_DOWN */
              {
                const __m256d p_affine_0_0__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_0_1__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_0_2__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_0__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_1__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_2__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_0__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_1__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_2__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_0__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_1__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_2__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d src_dof_0__20 = _mm256_loadu_pd(
                    &_data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d src_dof_1__20 = _mm256_loadu_pd(
                    &_data_src[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d src_dof_2__20 = _mm256_loadu_pd(
                    &_data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d src_dof_3__20 = _mm256_loadu_pd(
                    &_data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_0__20 = _mm256_loadu_pd(
                    &_data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL + ctr_1) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_1__20 = _mm256_loadu_pd(
                    &_data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                             (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_2__20 = _mm256_loadu_pd(
                    &_data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                             (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_3__20 = _mm256_loadu_pd(
                    &_data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                             (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL + ctr_1) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                __m256d q_acc_0_0__20 = _mm256_set1_pd(0.0);
                __m256d q_acc_0_1__20 = _mm256_set1_pd(0.0);
                __m256d q_acc_0_2__20 = _mm256_set1_pd(0.0);
                __m256d q_acc_0_3__20 = _mm256_set1_pd(0.0);
                __m256d q_acc_1_1__20 = _mm256_set1_pd(0.0);
                __m256d q_acc_1_2__20 = _mm256_set1_pd(0.0);
                __m256d q_acc_1_3__20 = _mm256_set1_pd(0.0);
                __m256d q_acc_2_2__20 = _mm256_set1_pd(0.0);
                __m256d q_acc_2_3__20 = _mm256_set1_pd(0.0);
                __m256d q_acc_3_3__20 = _mm256_set1_pd(0.0);
                for (int64_t q__13 = 0LL; q__13 < 1LL; q__13 += 1LL) {
                  const __m256d tmp_qloop_0__20 = _mm256_mul_pd(
                      _mm256_add_pd(
                          _mm256_add_pd(
                              _mm256_add_pd(
                                  _mm256_mul_pd(
                                      k_dof_0__20,
                                      _mm256_set1_pd(phi_0_0__7[4LL * q__13])),
                                  _mm256_mul_pd(
                                      k_dof_1__20,
                                      _mm256_set1_pd(
                                          phi_0_0__7[1LL + 4LL * q__13]))),
                              _mm256_mul_pd(
                                  k_dof_2__20,
                                  _mm256_set1_pd(
                                      phi_0_0__7[2LL + 4LL * q__13]))),
                          _mm256_mul_pd(
                              k_dof_3__20,
                              _mm256_set1_pd(phi_0_0__7[3LL + 4LL * q__13]))),
                      _mm256_set1_pd(q_w[q__13]));
                  const __m256d q_tmp_0_0__20 = _mm256_mul_pd(
                      tmp_qloop_0__20,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__7[10LL * q__13]));
                  const __m256d q_tmp_0_1__20 = _mm256_mul_pd(
                      tmp_qloop_0__20,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__7[1LL + 10LL * q__13]));
                  const __m256d q_tmp_0_2__20 = _mm256_mul_pd(
                      tmp_qloop_0__20,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__7[2LL + 10LL * q__13]));
                  const __m256d q_tmp_0_3__20 = _mm256_mul_pd(
                      tmp_qloop_0__20,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__7[3LL + 10LL * q__13]));
                  const __m256d q_tmp_1_1__20 = _mm256_mul_pd(
                      tmp_qloop_0__20,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__7[4LL + 10LL * q__13]));
                  const __m256d q_tmp_1_2__20 = _mm256_mul_pd(
                      tmp_qloop_0__20,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__7[5LL + 10LL * q__13]));
                  const __m256d q_tmp_1_3__20 = _mm256_mul_pd(
                      tmp_qloop_0__20,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__7[6LL + 10LL * q__13]));
                  const __m256d q_tmp_2_2__20 = _mm256_mul_pd(
                      tmp_qloop_0__20,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__7[7LL + 10LL * q__13]));
                  const __m256d q_tmp_2_3__20 = _mm256_mul_pd(
                      tmp_qloop_0__20,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__7[8LL + 10LL * q__13]));
                  const __m256d q_tmp_3_3__20 = _mm256_mul_pd(
                      tmp_qloop_0__20,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__7[9LL + 10LL * q__13]));
                  q_acc_0_0__20 = _mm256_add_pd(q_acc_0_0__20, q_tmp_0_0__20);
                  q_acc_0_1__20 = _mm256_add_pd(q_acc_0_1__20, q_tmp_0_1__20);
                  q_acc_0_2__20 = _mm256_add_pd(q_acc_0_2__20, q_tmp_0_2__20);
                  q_acc_0_3__20 = _mm256_add_pd(q_acc_0_3__20, q_tmp_0_3__20);
                  q_acc_1_1__20 = _mm256_add_pd(q_acc_1_1__20, q_tmp_1_1__20);
                  q_acc_1_2__20 = _mm256_add_pd(q_acc_1_2__20, q_tmp_1_2__20);
                  q_acc_1_3__20 = _mm256_add_pd(q_acc_1_3__20, q_tmp_1_3__20);
                  q_acc_2_2__20 = _mm256_add_pd(q_acc_2_2__20, q_tmp_2_2__20);
                  q_acc_2_3__20 = _mm256_add_pd(q_acc_2_3__20, q_tmp_2_3__20);
                  q_acc_3_3__20 = _mm256_add_pd(q_acc_3_3__20, q_tmp_3_3__20);
                }
                const __m256d elMatVec_0__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(q_acc_0_0__20, src_dof_0__20),
                            _mm256_mul_pd(q_acc_0_1__20, src_dof_1__20)),
                        _mm256_mul_pd(q_acc_0_2__20, src_dof_2__20)),
                    _mm256_mul_pd(q_acc_0_3__20, src_dof_3__20));
                const __m256d elMatVec_1__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(q_acc_0_1__20, src_dof_0__20),
                            _mm256_mul_pd(q_acc_1_1__20, src_dof_1__20)),
                        _mm256_mul_pd(q_acc_1_2__20, src_dof_2__20)),
                    _mm256_mul_pd(q_acc_1_3__20, src_dof_3__20));
                const __m256d elMatVec_2__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(q_acc_0_2__20, src_dof_0__20),
                            _mm256_mul_pd(q_acc_1_2__20, src_dof_1__20)),
                        _mm256_mul_pd(q_acc_2_2__20, src_dof_2__20)),
                    _mm256_mul_pd(q_acc_2_3__20, src_dof_3__20));
                const __m256d elMatVec_3__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(q_acc_0_3__20, src_dof_0__20),
                            _mm256_mul_pd(q_acc_1_3__20, src_dof_1__20)),
                        _mm256_mul_pd(q_acc_2_3__20, src_dof_2__20)),
                    _mm256_mul_pd(q_acc_3_3__20, src_dof_3__20));
                _mm256_storeu_pd(
                    &_data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatVec_0__20,
                        _mm256_loadu_pd(
                            &_data_dst
                                [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (3LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL + ctr_1) * (2LL - ctr_2 +
                                                  micro_edges_per_macro_edge) +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatVec_1__20,
                        _mm256_loadu_pd(
                            &_data_dst
                                [-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                                 (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                     (1LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     ctr_1 +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatVec_2__20,
                        _mm256_loadu_pd(
                            &_data_dst
                                [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                                 (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                     (1LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     ctr_1 +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatVec_3__20,
                        _mm256_loadu_pd(
                            &_data_dst
                                [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                                 (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                     (1LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL + ctr_1) * (1LL - ctr_2 +
                                                  micro_edges_per_macro_edge) +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
              }
            }
            {
              /* CellType.GREEN_UP */
              {
                const __m256d p_affine_0_0__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_0_1__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_0_2__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_0__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_1__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_2__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_0__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_1__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_2__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_0__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_1__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_2__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d src_dof_0__21 = _mm256_loadu_pd(
                    &_data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d src_dof_1__21 = _mm256_loadu_pd(
                    &_data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d src_dof_2__21 = _mm256_loadu_pd(
                    &_data_src[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d src_dof_3__21 = _mm256_loadu_pd(
                    &_data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_0__21 = _mm256_loadu_pd(
                    &_data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_1__21 = _mm256_loadu_pd(
                    &_data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL + ctr_1) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_2__21 = _mm256_loadu_pd(
                    &_data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                             (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_3__21 = _mm256_loadu_pd(
                    &_data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                             (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                __m256d q_acc_0_0__21 = _mm256_set1_pd(0.0);
                __m256d q_acc_0_1__21 = _mm256_set1_pd(0.0);
                __m256d q_acc_0_2__21 = _mm256_set1_pd(0.0);
                __m256d q_acc_0_3__21 = _mm256_set1_pd(0.0);
                __m256d q_acc_1_1__21 = _mm256_set1_pd(0.0);
                __m256d q_acc_1_2__21 = _mm256_set1_pd(0.0);
                __m256d q_acc_1_3__21 = _mm256_set1_pd(0.0);
                __m256d q_acc_2_2__21 = _mm256_set1_pd(0.0);
                __m256d q_acc_2_3__21 = _mm256_set1_pd(0.0);
                __m256d q_acc_3_3__21 = _mm256_set1_pd(0.0);
                for (int64_t q__12 = 0LL; q__12 < 1LL; q__12 += 1LL) {
                  const __m256d tmp_qloop_0__21 = _mm256_mul_pd(
                      _mm256_add_pd(
                          _mm256_add_pd(
                              _mm256_add_pd(
                                  _mm256_mul_pd(
                                      k_dof_0__21,
                                      _mm256_set1_pd(phi_0_0__6[4LL * q__12])),
                                  _mm256_mul_pd(
                                      k_dof_1__21,
                                      _mm256_set1_pd(
                                          phi_0_0__6[1LL + 4LL * q__12]))),
                              _mm256_mul_pd(
                                  k_dof_2__21,
                                  _mm256_set1_pd(
                                      phi_0_0__6[2LL + 4LL * q__12]))),
                          _mm256_mul_pd(
                              k_dof_3__21,
                              _mm256_set1_pd(phi_0_0__6[3LL + 4LL * q__12]))),
                      _mm256_set1_pd(q_w[q__12]));
                  const __m256d q_tmp_0_0__21 = _mm256_mul_pd(
                      tmp_qloop_0__21,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__6[10LL * q__12]));
                  const __m256d q_tmp_0_1__21 = _mm256_mul_pd(
                      tmp_qloop_0__21,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__6[1LL + 10LL * q__12]));
                  const __m256d q_tmp_0_2__21 = _mm256_mul_pd(
                      tmp_qloop_0__21,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__6[2LL + 10LL * q__12]));
                  const __m256d q_tmp_0_3__21 = _mm256_mul_pd(
                      tmp_qloop_0__21,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__6[3LL + 10LL * q__12]));
                  const __m256d q_tmp_1_1__21 = _mm256_mul_pd(
                      tmp_qloop_0__21,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__6[4LL + 10LL * q__12]));
                  const __m256d q_tmp_1_2__21 = _mm256_mul_pd(
                      tmp_qloop_0__21,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__6[5LL + 10LL * q__12]));
                  const __m256d q_tmp_1_3__21 = _mm256_mul_pd(
                      tmp_qloop_0__21,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__6[6LL + 10LL * q__12]));
                  const __m256d q_tmp_2_2__21 = _mm256_mul_pd(
                      tmp_qloop_0__21,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__6[7LL + 10LL * q__12]));
                  const __m256d q_tmp_2_3__21 = _mm256_mul_pd(
                      tmp_qloop_0__21,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__6[8LL + 10LL * q__12]));
                  const __m256d q_tmp_3_3__21 = _mm256_mul_pd(
                      tmp_qloop_0__21,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__6[9LL + 10LL * q__12]));
                  q_acc_0_0__21 = _mm256_add_pd(q_acc_0_0__21, q_tmp_0_0__21);
                  q_acc_0_1__21 = _mm256_add_pd(q_acc_0_1__21, q_tmp_0_1__21);
                  q_acc_0_2__21 = _mm256_add_pd(q_acc_0_2__21, q_tmp_0_2__21);
                  q_acc_0_3__21 = _mm256_add_pd(q_acc_0_3__21, q_tmp_0_3__21);
                  q_acc_1_1__21 = _mm256_add_pd(q_acc_1_1__21, q_tmp_1_1__21);
                  q_acc_1_2__21 = _mm256_add_pd(q_acc_1_2__21, q_tmp_1_2__21);
                  q_acc_1_3__21 = _mm256_add_pd(q_acc_1_3__21, q_tmp_1_3__21);
                  q_acc_2_2__21 = _mm256_add_pd(q_acc_2_2__21, q_tmp_2_2__21);
                  q_acc_2_3__21 = _mm256_add_pd(q_acc_2_3__21, q_tmp_2_3__21);
                  q_acc_3_3__21 = _mm256_add_pd(q_acc_3_3__21, q_tmp_3_3__21);
                }
                const __m256d elMatVec_0__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(q_acc_0_0__21, src_dof_0__21),
                            _mm256_mul_pd(q_acc_0_1__21, src_dof_1__21)),
                        _mm256_mul_pd(q_acc_0_2__21, src_dof_2__21)),
                    _mm256_mul_pd(q_acc_0_3__21, src_dof_3__21));
                const __m256d elMatVec_1__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(q_acc_0_1__21, src_dof_0__21),
                            _mm256_mul_pd(q_acc_1_1__21, src_dof_1__21)),
                        _mm256_mul_pd(q_acc_1_2__21, src_dof_2__21)),
                    _mm256_mul_pd(q_acc_1_3__21, src_dof_3__21));
                const __m256d elMatVec_2__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(q_acc_0_2__21, src_dof_0__21),
                            _mm256_mul_pd(q_acc_1_2__21, src_dof_1__21)),
                        _mm256_mul_pd(q_acc_2_2__21, src_dof_2__21)),
                    _mm256_mul_pd(q_acc_2_3__21, src_dof_3__21));
                const __m256d elMatVec_3__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(q_acc_0_3__21, src_dof_0__21),
                            _mm256_mul_pd(q_acc_1_3__21, src_dof_1__21)),
                        _mm256_mul_pd(q_acc_2_3__21, src_dof_2__21)),
                    _mm256_mul_pd(q_acc_3_3__21, src_dof_3__21));
                _mm256_storeu_pd(
                    &_data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatVec_0__21,
                        _mm256_loadu_pd(
                            &_data_dst
                                [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (3LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                     ctr_1 +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatVec_1__21,
                        _mm256_loadu_pd(
                            &_data_dst
                                [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (3LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL + ctr_1) * (2LL - ctr_2 +
                                                  micro_edges_per_macro_edge) +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatVec_2__21,
                        _mm256_loadu_pd(
                            &_data_dst
                                [-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                                 (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                     (1LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     ctr_1 +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatVec_3__21,
                        _mm256_loadu_pd(
                            &_data_dst
                                [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                                 (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                     (1LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     ctr_1 +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
              }
            }
            {
              /* CellType.GREEN_DOWN */
              {
                const __m256d p_affine_0_0__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_0_1__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_0_2__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_0__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_1__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_2__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_0__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_1__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_2__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_0__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_1__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_2__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d src_dof_0__22 = _mm256_loadu_pd(
                    &_data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d src_dof_1__22 = _mm256_loadu_pd(
                    &_data_src[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d src_dof_2__22 = _mm256_loadu_pd(
                    &_data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d src_dof_3__22 = _mm256_loadu_pd(
                    &_data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_0__22 = _mm256_loadu_pd(
                    &_data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL + ctr_1) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_1__22 = _mm256_loadu_pd(
                    &_data_k[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL + ctr_1) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_2__22 = _mm256_loadu_pd(
                    &_data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                             (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_3__22 = _mm256_loadu_pd(
                    &_data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                             (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL + ctr_1) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                __m256d q_acc_0_0__22 = _mm256_set1_pd(0.0);
                __m256d q_acc_0_1__22 = _mm256_set1_pd(0.0);
                __m256d q_acc_0_2__22 = _mm256_set1_pd(0.0);
                __m256d q_acc_0_3__22 = _mm256_set1_pd(0.0);
                __m256d q_acc_1_1__22 = _mm256_set1_pd(0.0);
                __m256d q_acc_1_2__22 = _mm256_set1_pd(0.0);
                __m256d q_acc_1_3__22 = _mm256_set1_pd(0.0);
                __m256d q_acc_2_2__22 = _mm256_set1_pd(0.0);
                __m256d q_acc_2_3__22 = _mm256_set1_pd(0.0);
                __m256d q_acc_3_3__22 = _mm256_set1_pd(0.0);
                for (int64_t q__11 = 0LL; q__11 < 1LL; q__11 += 1LL) {
                  const __m256d tmp_qloop_0__22 = _mm256_mul_pd(
                      _mm256_add_pd(
                          _mm256_add_pd(
                              _mm256_add_pd(
                                  _mm256_mul_pd(
                                      k_dof_0__22,
                                      _mm256_set1_pd(phi_0_0__5[4LL * q__11])),
                                  _mm256_mul_pd(
                                      k_dof_1__22,
                                      _mm256_set1_pd(
                                          phi_0_0__5[1LL + 4LL * q__11]))),
                              _mm256_mul_pd(
                                  k_dof_2__22,
                                  _mm256_set1_pd(
                                      phi_0_0__5[2LL + 4LL * q__11]))),
                          _mm256_mul_pd(
                              k_dof_3__22,
                              _mm256_set1_pd(phi_0_0__5[3LL + 4LL * q__11]))),
                      _mm256_set1_pd(q_w[q__11]));
                  const __m256d q_tmp_0_0__22 = _mm256_mul_pd(
                      tmp_qloop_0__22,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__5[10LL * q__11]));
                  const __m256d q_tmp_0_1__22 = _mm256_mul_pd(
                      tmp_qloop_0__22,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__5[1LL + 10LL * q__11]));
                  const __m256d q_tmp_0_2__22 = _mm256_mul_pd(
                      tmp_qloop_0__22,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__5[2LL + 10LL * q__11]));
                  const __m256d q_tmp_0_3__22 = _mm256_mul_pd(
                      tmp_qloop_0__22,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__5[3LL + 10LL * q__11]));
                  const __m256d q_tmp_1_1__22 = _mm256_mul_pd(
                      tmp_qloop_0__22,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__5[4LL + 10LL * q__11]));
                  const __m256d q_tmp_1_2__22 = _mm256_mul_pd(
                      tmp_qloop_0__22,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__5[5LL + 10LL * q__11]));
                  const __m256d q_tmp_1_3__22 = _mm256_mul_pd(
                      tmp_qloop_0__22,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__5[6LL + 10LL * q__11]));
                  const __m256d q_tmp_2_2__22 = _mm256_mul_pd(
                      tmp_qloop_0__22,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__5[7LL + 10LL * q__11]));
                  const __m256d q_tmp_2_3__22 = _mm256_mul_pd(
                      tmp_qloop_0__22,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__5[8LL + 10LL * q__11]));
                  const __m256d q_tmp_3_3__22 = _mm256_mul_pd(
                      tmp_qloop_0__22,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__5[9LL + 10LL * q__11]));
                  q_acc_0_0__22 = _mm256_add_pd(q_acc_0_0__22, q_tmp_0_0__22);
                  q_acc_0_1__22 = _mm256_add_pd(q_acc_0_1__22, q_tmp_0_1__22);
                  q_acc_0_2__22 = _mm256_add_pd(q_acc_0_2__22, q_tmp_0_2__22);
                  q_acc_0_3__22 = _mm256_add_pd(q_acc_0_3__22, q_tmp_0_3__22);
                  q_acc_1_1__22 = _mm256_add_pd(q_acc_1_1__22, q_tmp_1_1__22);
                  q_acc_1_2__22 = _mm256_add_pd(q_acc_1_2__22, q_tmp_1_2__22);
                  q_acc_1_3__22 = _mm256_add_pd(q_acc_1_3__22, q_tmp_1_3__22);
                  q_acc_2_2__22 = _mm256_add_pd(q_acc_2_2__22, q_tmp_2_2__22);
                  q_acc_2_3__22 = _mm256_add_pd(q_acc_2_3__22, q_tmp_2_3__22);
                  q_acc_3_3__22 = _mm256_add_pd(q_acc_3_3__22, q_tmp_3_3__22);
                }
                const __m256d elMatVec_0__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(q_acc_0_0__22, src_dof_0__22),
                            _mm256_mul_pd(q_acc_0_1__22, src_dof_1__22)),
                        _mm256_mul_pd(q_acc_0_2__22, src_dof_2__22)),
                    _mm256_mul_pd(q_acc_0_3__22, src_dof_3__22));
                const __m256d elMatVec_1__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(q_acc_0_1__22, src_dof_0__22),
                            _mm256_mul_pd(q_acc_1_1__22, src_dof_1__22)),
                        _mm256_mul_pd(q_acc_1_2__22, src_dof_2__22)),
                    _mm256_mul_pd(q_acc_1_3__22, src_dof_3__22));
                const __m256d elMatVec_2__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(q_acc_0_2__22, src_dof_0__22),
                            _mm256_mul_pd(q_acc_1_2__22, src_dof_1__22)),
                        _mm256_mul_pd(q_acc_2_2__22, src_dof_2__22)),
                    _mm256_mul_pd(q_acc_2_3__22, src_dof_3__22));
                const __m256d elMatVec_3__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(q_acc_0_3__22, src_dof_0__22),
                            _mm256_mul_pd(q_acc_1_3__22, src_dof_1__22)),
                        _mm256_mul_pd(q_acc_2_3__22, src_dof_2__22)),
                    _mm256_mul_pd(q_acc_3_3__22, src_dof_3__22));
                _mm256_storeu_pd(
                    &_data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatVec_0__22,
                        _mm256_loadu_pd(
                            &_data_dst
                                [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (3LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL + ctr_1) * (2LL - ctr_2 +
                                                  micro_edges_per_macro_edge) +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_dst[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatVec_1__22,
                        _mm256_loadu_pd(
                            &_data_dst
                                [1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (3LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL + ctr_1) * (2LL - ctr_2 +
                                                  micro_edges_per_macro_edge) +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatVec_2__22,
                        _mm256_loadu_pd(
                            &_data_dst
                                [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                                 (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                     (1LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     ctr_1 +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__1 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatVec_3__22,
                        _mm256_loadu_pd(
                            &_data_dst
                                [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                                 (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                     (1LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL + ctr_1) * (1LL - ctr_2 +
                                                  micro_edges_per_macro_edge) +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
              }
            }
          }
          const int64_t __ctr_0__1_trailing_start =
              __ctr_0__1_simd_stop > 0LL
                  ? ((__ctr_0__1_simd_stop - 1LL) / __ctr_0__1_simd_step +
                     1LL) *
                        __ctr_0__1_simd_step
                  : 0LL;
          for (int64_t ctr_0__3 = __ctr_0__1_trailing_start;
               ctr_0__3 < -2LL - ctr_1 - ctr_2 + micro_edges_per_macro_edge;
               ctr_0__3 += 1LL) {
            {
              /* CellType.WHITE_UP */
              {
                const double p_affine_0_0__10 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_0_1__10 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_0_2__10 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_1_0__10 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_1_1__10 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_1_2__10 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_2_0__10 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_2_1__10 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_2_2__10 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_3_0__10 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_1__10 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_2__10 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double src_dof_0__10 =
                    _data_src[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_1__10 =
                    _data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_2__10 =
                    _data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_3__10 =
                    _data_src[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_0__10 =
                    _data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_1__10 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_2__10 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_3__10 =
                    _data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                double q_acc_0_0__10 = 0.0;
                double q_acc_0_1__10 = 0.0;
                double q_acc_0_2__10 = 0.0;
                double q_acc_0_3__10 = 0.0;
                double q_acc_1_1__10 = 0.0;
                double q_acc_1_2__10 = 0.0;
                double q_acc_1_3__10 = 0.0;
                double q_acc_2_2__10 = 0.0;
                double q_acc_2_3__10 = 0.0;
                double q_acc_3_3__10 = 0.0;
                for (int64_t q__10 = 0LL; q__10 < 1LL; q__10 += 1LL) {
                  const double tmp_qloop_0__10 =
                      (k_dof_0__10 * phi_0_0__10[4LL * q__10] +
                       k_dof_1__10 * phi_0_0__10[1LL + 4LL * q__10] +
                       k_dof_2__10 * phi_0_0__10[2LL + 4LL * q__10] +
                       k_dof_3__10 * phi_0_0__10[3LL + 4LL * q__10]) *
                      q_w[q__10];
                  const double q_tmp_0_0__10 =
                      tmp_qloop_0__10 *
                      tabulated_and_untitled_0_0__10[10LL * q__10];
                  const double q_tmp_0_1__10 =
                      tmp_qloop_0__10 *
                      tabulated_and_untitled_0_0__10[1LL + 10LL * q__10];
                  const double q_tmp_0_2__10 =
                      tmp_qloop_0__10 *
                      tabulated_and_untitled_0_0__10[2LL + 10LL * q__10];
                  const double q_tmp_0_3__10 =
                      tmp_qloop_0__10 *
                      tabulated_and_untitled_0_0__10[3LL + 10LL * q__10];
                  const double q_tmp_1_1__10 =
                      tmp_qloop_0__10 *
                      tabulated_and_untitled_0_0__10[4LL + 10LL * q__10];
                  const double q_tmp_1_2__10 =
                      tmp_qloop_0__10 *
                      tabulated_and_untitled_0_0__10[5LL + 10LL * q__10];
                  const double q_tmp_1_3__10 =
                      tmp_qloop_0__10 *
                      tabulated_and_untitled_0_0__10[6LL + 10LL * q__10];
                  const double q_tmp_2_2__10 =
                      tmp_qloop_0__10 *
                      tabulated_and_untitled_0_0__10[7LL + 10LL * q__10];
                  const double q_tmp_2_3__10 =
                      tmp_qloop_0__10 *
                      tabulated_and_untitled_0_0__10[8LL + 10LL * q__10];
                  const double q_tmp_3_3__10 =
                      tmp_qloop_0__10 *
                      tabulated_and_untitled_0_0__10[9LL + 10LL * q__10];
                  q_acc_0_0__10 = q_acc_0_0__10 + q_tmp_0_0__10;
                  q_acc_0_1__10 = q_acc_0_1__10 + q_tmp_0_1__10;
                  q_acc_0_2__10 = q_acc_0_2__10 + q_tmp_0_2__10;
                  q_acc_0_3__10 = q_acc_0_3__10 + q_tmp_0_3__10;
                  q_acc_1_1__10 = q_acc_1_1__10 + q_tmp_1_1__10;
                  q_acc_1_2__10 = q_acc_1_2__10 + q_tmp_1_2__10;
                  q_acc_1_3__10 = q_acc_1_3__10 + q_tmp_1_3__10;
                  q_acc_2_2__10 = q_acc_2_2__10 + q_tmp_2_2__10;
                  q_acc_2_3__10 = q_acc_2_3__10 + q_tmp_2_3__10;
                  q_acc_3_3__10 = q_acc_3_3__10 + q_tmp_3_3__10;
                }
                const double elMatVec_0__10 = q_acc_0_0__10 * src_dof_0__10 +
                                              q_acc_0_1__10 * src_dof_1__10 +
                                              q_acc_0_2__10 * src_dof_2__10 +
                                              q_acc_0_3__10 * src_dof_3__10;
                const double elMatVec_1__10 = q_acc_0_1__10 * src_dof_0__10 +
                                              q_acc_1_1__10 * src_dof_1__10 +
                                              q_acc_1_2__10 * src_dof_2__10 +
                                              q_acc_1_3__10 * src_dof_3__10;
                const double elMatVec_2__10 = q_acc_0_2__10 * src_dof_0__10 +
                                              q_acc_1_2__10 * src_dof_1__10 +
                                              q_acc_2_2__10 * src_dof_2__10 +
                                              q_acc_2_3__10 * src_dof_3__10;
                const double elMatVec_3__10 = q_acc_0_3__10 * src_dof_0__10 +
                                              q_acc_1_3__10 * src_dof_1__10 +
                                              q_acc_2_3__10 * src_dof_2__10 +
                                              q_acc_3_3__10 * src_dof_3__10;
                _data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__3 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_0__10 +
                    _data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__3 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_1__10 +
                    _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL + ctr_1) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) +
                          ctr_0__3 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_2__10 +
                    _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                          (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__3 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_3__10 +
                    _data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
              }
            }
            {
              /* CellType.WHITE_DOWN */
              {
                const double p_affine_0_0__9 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_0_1__9 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_0_2__9 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_1_0__9 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_1_1__9 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_1_2__9 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_0__9 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_1__9 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_2__9 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_0__9 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_1__9 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_2__9 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double src_dof_0__9 =
                    _data_src[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_1__9 =
                    _data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_2__9 =
                    _data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_3__9 =
                    _data_src[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_0__9 =
                    _data_k[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_1__9 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_2__9 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_3__9 =
                    _data_k[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                double q_acc_0_0__9 = 0.0;
                double q_acc_0_1__9 = 0.0;
                double q_acc_0_2__9 = 0.0;
                double q_acc_0_3__9 = 0.0;
                double q_acc_1_1__9 = 0.0;
                double q_acc_1_2__9 = 0.0;
                double q_acc_1_3__9 = 0.0;
                double q_acc_2_2__9 = 0.0;
                double q_acc_2_3__9 = 0.0;
                double q_acc_3_3__9 = 0.0;
                for (int64_t q__9 = 0LL; q__9 < 1LL; q__9 += 1LL) {
                  const double tmp_qloop_0__9 =
                      (k_dof_0__9 * phi_0_0__9[4LL * q__9] +
                       k_dof_1__9 * phi_0_0__9[1LL + 4LL * q__9] +
                       k_dof_2__9 * phi_0_0__9[2LL + 4LL * q__9] +
                       k_dof_3__9 * phi_0_0__9[3LL + 4LL * q__9]) *
                      q_w[q__9];
                  const double q_tmp_0_0__9 =
                      tmp_qloop_0__9 *
                      tabulated_and_untitled_0_0__9[10LL * q__9];
                  const double q_tmp_0_1__9 =
                      tmp_qloop_0__9 *
                      tabulated_and_untitled_0_0__9[1LL + 10LL * q__9];
                  const double q_tmp_0_2__9 =
                      tmp_qloop_0__9 *
                      tabulated_and_untitled_0_0__9[2LL + 10LL * q__9];
                  const double q_tmp_0_3__9 =
                      tmp_qloop_0__9 *
                      tabulated_and_untitled_0_0__9[3LL + 10LL * q__9];
                  const double q_tmp_1_1__9 =
                      tmp_qloop_0__9 *
                      tabulated_and_untitled_0_0__9[4LL + 10LL * q__9];
                  const double q_tmp_1_2__9 =
                      tmp_qloop_0__9 *
                      tabulated_and_untitled_0_0__9[5LL + 10LL * q__9];
                  const double q_tmp_1_3__9 =
                      tmp_qloop_0__9 *
                      tabulated_and_untitled_0_0__9[6LL + 10LL * q__9];
                  const double q_tmp_2_2__9 =
                      tmp_qloop_0__9 *
                      tabulated_and_untitled_0_0__9[7LL + 10LL * q__9];
                  const double q_tmp_2_3__9 =
                      tmp_qloop_0__9 *
                      tabulated_and_untitled_0_0__9[8LL + 10LL * q__9];
                  const double q_tmp_3_3__9 =
                      tmp_qloop_0__9 *
                      tabulated_and_untitled_0_0__9[9LL + 10LL * q__9];
                  q_acc_0_0__9 = q_acc_0_0__9 + q_tmp_0_0__9;
                  q_acc_0_1__9 = q_acc_0_1__9 + q_tmp_0_1__9;
                  q_acc_0_2__9 = q_acc_0_2__9 + q_tmp_0_2__9;
                  q_acc_0_3__9 = q_acc_0_3__9 + q_tmp_0_3__9;
                  q_acc_1_1__9 = q_acc_1_1__9 + q_tmp_1_1__9;
                  q_acc_1_2__9 = q_acc_1_2__9 + q_tmp_1_2__9;
                  q_acc_1_3__9 = q_acc_1_3__9 + q_tmp_1_3__9;
                  q_acc_2_2__9 = q_acc_2_2__9 + q_tmp_2_2__9;
                  q_acc_2_3__9 = q_acc_2_3__9 + q_tmp_2_3__9;
                  q_acc_3_3__9 = q_acc_3_3__9 + q_tmp_3_3__9;
                }
                const double elMatVec_0__9 =
                    q_acc_0_0__9 * src_dof_0__9 + q_acc_0_1__9 * src_dof_1__9 +
                    q_acc_0_2__9 * src_dof_2__9 + q_acc_0_3__9 * src_dof_3__9;
                const double elMatVec_1__9 =
                    q_acc_0_1__9 * src_dof_0__9 + q_acc_1_1__9 * src_dof_1__9 +
                    q_acc_1_2__9 * src_dof_2__9 + q_acc_1_3__9 * src_dof_3__9;
                const double elMatVec_2__9 =
                    q_acc_0_2__9 * src_dof_0__9 + q_acc_1_2__9 * src_dof_1__9 +
                    q_acc_2_2__9 * src_dof_2__9 + q_acc_2_3__9 * src_dof_3__9;
                const double elMatVec_3__9 =
                    q_acc_0_3__9 * src_dof_0__9 + q_acc_1_3__9 * src_dof_1__9 +
                    q_acc_2_3__9 * src_dof_2__9 + q_acc_3_3__9 * src_dof_3__9;
                _data_dst[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL + ctr_1) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) +
                          ctr_0__3 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_0__9 +
                    _data_dst[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                          (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__3 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_1__9 +
                    _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                          (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL + ctr_1) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) +
                          ctr_0__3 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_2__9 +
                    _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                          (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL + ctr_1) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) +
                          ctr_0__3 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_3__9 +
                    _data_dst[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
              }
            }
            {
              /* CellType.BLUE_UP */
              {
                const double p_affine_0_0__8 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_0_1__8 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_0_2__8 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_1_0__8 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_1_1__8 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_1_2__8 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_2_0__8 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_2_1__8 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_2_2__8 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_3_0__8 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_1__8 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_2__8 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double src_dof_0__8 =
                    _data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_1__8 =
                    _data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_2__8 =
                    _data_src[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_3__8 =
                    _data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_0__8 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_1__8 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_2__8 =
                    _data_k[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_3__8 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                double q_acc_0_0__8 = 0.0;
                double q_acc_0_1__8 = 0.0;
                double q_acc_0_2__8 = 0.0;
                double q_acc_0_3__8 = 0.0;
                double q_acc_1_1__8 = 0.0;
                double q_acc_1_2__8 = 0.0;
                double q_acc_1_3__8 = 0.0;
                double q_acc_2_2__8 = 0.0;
                double q_acc_2_3__8 = 0.0;
                double q_acc_3_3__8 = 0.0;
                for (int64_t q__8 = 0LL; q__8 < 1LL; q__8 += 1LL) {
                  const double tmp_qloop_0__8 =
                      (k_dof_0__8 * phi_0_0__8[4LL * q__8] +
                       k_dof_1__8 * phi_0_0__8[1LL + 4LL * q__8] +
                       k_dof_2__8 * phi_0_0__8[2LL + 4LL * q__8] +
                       k_dof_3__8 * phi_0_0__8[3LL + 4LL * q__8]) *
                      q_w[q__8];
                  const double q_tmp_0_0__8 =
                      tmp_qloop_0__8 *
                      tabulated_and_untitled_0_0__8[10LL * q__8];
                  const double q_tmp_0_1__8 =
                      tmp_qloop_0__8 *
                      tabulated_and_untitled_0_0__8[1LL + 10LL * q__8];
                  const double q_tmp_0_2__8 =
                      tmp_qloop_0__8 *
                      tabulated_and_untitled_0_0__8[2LL + 10LL * q__8];
                  const double q_tmp_0_3__8 =
                      tmp_qloop_0__8 *
                      tabulated_and_untitled_0_0__8[3LL + 10LL * q__8];
                  const double q_tmp_1_1__8 =
                      tmp_qloop_0__8 *
                      tabulated_and_untitled_0_0__8[4LL + 10LL * q__8];
                  const double q_tmp_1_2__8 =
                      tmp_qloop_0__8 *
                      tabulated_and_untitled_0_0__8[5LL + 10LL * q__8];
                  const double q_tmp_1_3__8 =
                      tmp_qloop_0__8 *
                      tabulated_and_untitled_0_0__8[6LL + 10LL * q__8];
                  const double q_tmp_2_2__8 =
                      tmp_qloop_0__8 *
                      tabulated_and_untitled_0_0__8[7LL + 10LL * q__8];
                  const double q_tmp_2_3__8 =
                      tmp_qloop_0__8 *
                      tabulated_and_untitled_0_0__8[8LL + 10LL * q__8];
                  const double q_tmp_3_3__8 =
                      tmp_qloop_0__8 *
                      tabulated_and_untitled_0_0__8[9LL + 10LL * q__8];
                  q_acc_0_0__8 = q_acc_0_0__8 + q_tmp_0_0__8;
                  q_acc_0_1__8 = q_acc_0_1__8 + q_tmp_0_1__8;
                  q_acc_0_2__8 = q_acc_0_2__8 + q_tmp_0_2__8;
                  q_acc_0_3__8 = q_acc_0_3__8 + q_tmp_0_3__8;
                  q_acc_1_1__8 = q_acc_1_1__8 + q_tmp_1_1__8;
                  q_acc_1_2__8 = q_acc_1_2__8 + q_tmp_1_2__8;
                  q_acc_1_3__8 = q_acc_1_3__8 + q_tmp_1_3__8;
                  q_acc_2_2__8 = q_acc_2_2__8 + q_tmp_2_2__8;
                  q_acc_2_3__8 = q_acc_2_3__8 + q_tmp_2_3__8;
                  q_acc_3_3__8 = q_acc_3_3__8 + q_tmp_3_3__8;
                }
                const double elMatVec_0__8 =
                    q_acc_0_0__8 * src_dof_0__8 + q_acc_0_1__8 * src_dof_1__8 +
                    q_acc_0_2__8 * src_dof_2__8 + q_acc_0_3__8 * src_dof_3__8;
                const double elMatVec_1__8 =
                    q_acc_0_1__8 * src_dof_0__8 + q_acc_1_1__8 * src_dof_1__8 +
                    q_acc_1_2__8 * src_dof_2__8 + q_acc_1_3__8 * src_dof_3__8;
                const double elMatVec_2__8 =
                    q_acc_0_2__8 * src_dof_0__8 + q_acc_1_2__8 * src_dof_1__8 +
                    q_acc_2_2__8 * src_dof_2__8 + q_acc_2_3__8 * src_dof_3__8;
                const double elMatVec_3__8 =
                    q_acc_0_3__8 * src_dof_0__8 + q_acc_1_3__8 * src_dof_1__8 +
                    q_acc_2_3__8 * src_dof_2__8 + q_acc_3_3__8 * src_dof_3__8;
                _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__3 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_0__8 +
                    _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL + ctr_1) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) +
                          ctr_0__3 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_1__8 +
                    _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL + ctr_1) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) +
                          ctr_0__3 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_2__8 +
                    _data_dst[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                          (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__3 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_3__8 +
                    _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
              }
            }
            {
              /* CellType.BLUE_DOWN */
              {
                const double p_affine_0_0__7 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_0_1__7 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_0_2__7 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_1_0__7 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_1_1__7 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_1_2__7 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_0__7 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_1__7 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_2__7 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_0__7 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_1__7 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_2__7 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double src_dof_0__7 =
                    _data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_1__7 =
                    _data_src[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_2__7 =
                    _data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_3__7 =
                    _data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_0__7 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_1__7 =
                    _data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_2__7 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_3__7 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                double q_acc_0_0__7 = 0.0;
                double q_acc_0_1__7 = 0.0;
                double q_acc_0_2__7 = 0.0;
                double q_acc_0_3__7 = 0.0;
                double q_acc_1_1__7 = 0.0;
                double q_acc_1_2__7 = 0.0;
                double q_acc_1_3__7 = 0.0;
                double q_acc_2_2__7 = 0.0;
                double q_acc_2_3__7 = 0.0;
                double q_acc_3_3__7 = 0.0;
                for (int64_t q__7 = 0LL; q__7 < 1LL; q__7 += 1LL) {
                  const double tmp_qloop_0__7 =
                      (k_dof_0__7 * phi_0_0__7[4LL * q__7] +
                       k_dof_1__7 * phi_0_0__7[1LL + 4LL * q__7] +
                       k_dof_2__7 * phi_0_0__7[2LL + 4LL * q__7] +
                       k_dof_3__7 * phi_0_0__7[3LL + 4LL * q__7]) *
                      q_w[q__7];
                  const double q_tmp_0_0__7 =
                      tmp_qloop_0__7 *
                      tabulated_and_untitled_0_0__7[10LL * q__7];
                  const double q_tmp_0_1__7 =
                      tmp_qloop_0__7 *
                      tabulated_and_untitled_0_0__7[1LL + 10LL * q__7];
                  const double q_tmp_0_2__7 =
                      tmp_qloop_0__7 *
                      tabulated_and_untitled_0_0__7[2LL + 10LL * q__7];
                  const double q_tmp_0_3__7 =
                      tmp_qloop_0__7 *
                      tabulated_and_untitled_0_0__7[3LL + 10LL * q__7];
                  const double q_tmp_1_1__7 =
                      tmp_qloop_0__7 *
                      tabulated_and_untitled_0_0__7[4LL + 10LL * q__7];
                  const double q_tmp_1_2__7 =
                      tmp_qloop_0__7 *
                      tabulated_and_untitled_0_0__7[5LL + 10LL * q__7];
                  const double q_tmp_1_3__7 =
                      tmp_qloop_0__7 *
                      tabulated_and_untitled_0_0__7[6LL + 10LL * q__7];
                  const double q_tmp_2_2__7 =
                      tmp_qloop_0__7 *
                      tabulated_and_untitled_0_0__7[7LL + 10LL * q__7];
                  const double q_tmp_2_3__7 =
                      tmp_qloop_0__7 *
                      tabulated_and_untitled_0_0__7[8LL + 10LL * q__7];
                  const double q_tmp_3_3__7 =
                      tmp_qloop_0__7 *
                      tabulated_and_untitled_0_0__7[9LL + 10LL * q__7];
                  q_acc_0_0__7 = q_acc_0_0__7 + q_tmp_0_0__7;
                  q_acc_0_1__7 = q_acc_0_1__7 + q_tmp_0_1__7;
                  q_acc_0_2__7 = q_acc_0_2__7 + q_tmp_0_2__7;
                  q_acc_0_3__7 = q_acc_0_3__7 + q_tmp_0_3__7;
                  q_acc_1_1__7 = q_acc_1_1__7 + q_tmp_1_1__7;
                  q_acc_1_2__7 = q_acc_1_2__7 + q_tmp_1_2__7;
                  q_acc_1_3__7 = q_acc_1_3__7 + q_tmp_1_3__7;
                  q_acc_2_2__7 = q_acc_2_2__7 + q_tmp_2_2__7;
                  q_acc_2_3__7 = q_acc_2_3__7 + q_tmp_2_3__7;
                  q_acc_3_3__7 = q_acc_3_3__7 + q_tmp_3_3__7;
                }
                const double elMatVec_0__7 =
                    q_acc_0_0__7 * src_dof_0__7 + q_acc_0_1__7 * src_dof_1__7 +
                    q_acc_0_2__7 * src_dof_2__7 + q_acc_0_3__7 * src_dof_3__7;
                const double elMatVec_1__7 =
                    q_acc_0_1__7 * src_dof_0__7 + q_acc_1_1__7 * src_dof_1__7 +
                    q_acc_1_2__7 * src_dof_2__7 + q_acc_1_3__7 * src_dof_3__7;
                const double elMatVec_2__7 =
                    q_acc_0_2__7 * src_dof_0__7 + q_acc_1_2__7 * src_dof_1__7 +
                    q_acc_2_2__7 * src_dof_2__7 + q_acc_2_3__7 * src_dof_3__7;
                const double elMatVec_3__7 =
                    q_acc_0_3__7 * src_dof_0__7 + q_acc_1_3__7 * src_dof_1__7 +
                    q_acc_2_3__7 * src_dof_2__7 + q_acc_3_3__7 * src_dof_3__7;
                _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL + ctr_1) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) +
                          ctr_0__3 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_0__7 +
                    _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                          (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__3 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_1__7 +
                    _data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                          (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__3 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_2__7 +
                    _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                          (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL + ctr_1) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) +
                          ctr_0__3 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_3__7 +
                    _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
              }
            }
            {
              /* CellType.GREEN_UP */
              {
                const double p_affine_0_0__6 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_0_1__6 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_0_2__6 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_1_0__6 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_1_1__6 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_1_2__6 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_2_0__6 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_1__6 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_2__6 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_0__6 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_1__6 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_2__6 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double src_dof_0__6 =
                    _data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_1__6 =
                    _data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_2__6 =
                    _data_src[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_3__6 =
                    _data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_0__6 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_1__6 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_2__6 =
                    _data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_3__6 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                double q_acc_0_0__6 = 0.0;
                double q_acc_0_1__6 = 0.0;
                double q_acc_0_2__6 = 0.0;
                double q_acc_0_3__6 = 0.0;
                double q_acc_1_1__6 = 0.0;
                double q_acc_1_2__6 = 0.0;
                double q_acc_1_3__6 = 0.0;
                double q_acc_2_2__6 = 0.0;
                double q_acc_2_3__6 = 0.0;
                double q_acc_3_3__6 = 0.0;
                for (int64_t q__6 = 0LL; q__6 < 1LL; q__6 += 1LL) {
                  const double tmp_qloop_0__6 =
                      (k_dof_0__6 * phi_0_0__6[4LL * q__6] +
                       k_dof_1__6 * phi_0_0__6[1LL + 4LL * q__6] +
                       k_dof_2__6 * phi_0_0__6[2LL + 4LL * q__6] +
                       k_dof_3__6 * phi_0_0__6[3LL + 4LL * q__6]) *
                      q_w[q__6];
                  const double q_tmp_0_0__6 =
                      tmp_qloop_0__6 *
                      tabulated_and_untitled_0_0__6[10LL * q__6];
                  const double q_tmp_0_1__6 =
                      tmp_qloop_0__6 *
                      tabulated_and_untitled_0_0__6[1LL + 10LL * q__6];
                  const double q_tmp_0_2__6 =
                      tmp_qloop_0__6 *
                      tabulated_and_untitled_0_0__6[2LL + 10LL * q__6];
                  const double q_tmp_0_3__6 =
                      tmp_qloop_0__6 *
                      tabulated_and_untitled_0_0__6[3LL + 10LL * q__6];
                  const double q_tmp_1_1__6 =
                      tmp_qloop_0__6 *
                      tabulated_and_untitled_0_0__6[4LL + 10LL * q__6];
                  const double q_tmp_1_2__6 =
                      tmp_qloop_0__6 *
                      tabulated_and_untitled_0_0__6[5LL + 10LL * q__6];
                  const double q_tmp_1_3__6 =
                      tmp_qloop_0__6 *
                      tabulated_and_untitled_0_0__6[6LL + 10LL * q__6];
                  const double q_tmp_2_2__6 =
                      tmp_qloop_0__6 *
                      tabulated_and_untitled_0_0__6[7LL + 10LL * q__6];
                  const double q_tmp_2_3__6 =
                      tmp_qloop_0__6 *
                      tabulated_and_untitled_0_0__6[8LL + 10LL * q__6];
                  const double q_tmp_3_3__6 =
                      tmp_qloop_0__6 *
                      tabulated_and_untitled_0_0__6[9LL + 10LL * q__6];
                  q_acc_0_0__6 = q_acc_0_0__6 + q_tmp_0_0__6;
                  q_acc_0_1__6 = q_acc_0_1__6 + q_tmp_0_1__6;
                  q_acc_0_2__6 = q_acc_0_2__6 + q_tmp_0_2__6;
                  q_acc_0_3__6 = q_acc_0_3__6 + q_tmp_0_3__6;
                  q_acc_1_1__6 = q_acc_1_1__6 + q_tmp_1_1__6;
                  q_acc_1_2__6 = q_acc_1_2__6 + q_tmp_1_2__6;
                  q_acc_1_3__6 = q_acc_1_3__6 + q_tmp_1_3__6;
                  q_acc_2_2__6 = q_acc_2_2__6 + q_tmp_2_2__6;
                  q_acc_2_3__6 = q_acc_2_3__6 + q_tmp_2_3__6;
                  q_acc_3_3__6 = q_acc_3_3__6 + q_tmp_3_3__6;
                }
                const double elMatVec_0__6 =
                    q_acc_0_0__6 * src_dof_0__6 + q_acc_0_1__6 * src_dof_1__6 +
                    q_acc_0_2__6 * src_dof_2__6 + q_acc_0_3__6 * src_dof_3__6;
                const double elMatVec_1__6 =
                    q_acc_0_1__6 * src_dof_0__6 + q_acc_1_1__6 * src_dof_1__6 +
                    q_acc_1_2__6 * src_dof_2__6 + q_acc_1_3__6 * src_dof_3__6;
                const double elMatVec_2__6 =
                    q_acc_0_2__6 * src_dof_0__6 + q_acc_1_2__6 * src_dof_1__6 +
                    q_acc_2_2__6 * src_dof_2__6 + q_acc_2_3__6 * src_dof_3__6;
                const double elMatVec_3__6 =
                    q_acc_0_3__6 * src_dof_0__6 + q_acc_1_3__6 * src_dof_1__6 +
                    q_acc_2_3__6 * src_dof_2__6 + q_acc_3_3__6 * src_dof_3__6;
                _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__3 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_0__6 +
                    _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL + ctr_1) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) +
                          ctr_0__3 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_1__6 +
                    _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                          (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__3 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_2__6 +
                    _data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                          (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__3 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_3__6 +
                    _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
              }
            }
            {
              /* CellType.GREEN_DOWN */
              {
                const double p_affine_0_0__5 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_0_1__5 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_0_2__5 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_1_0__5 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_1_1__5 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_1_2__5 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_2_0__5 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_1__5 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_2__5 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_0__5 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_1__5 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_2__5 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double src_dof_0__5 =
                    _data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_1__5 =
                    _data_src[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_2__5 =
                    _data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_3__5 =
                    _data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_0__5 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_1__5 =
                    _data_k[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_2__5 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_3__5 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                double q_acc_0_0__5 = 0.0;
                double q_acc_0_1__5 = 0.0;
                double q_acc_0_2__5 = 0.0;
                double q_acc_0_3__5 = 0.0;
                double q_acc_1_1__5 = 0.0;
                double q_acc_1_2__5 = 0.0;
                double q_acc_1_3__5 = 0.0;
                double q_acc_2_2__5 = 0.0;
                double q_acc_2_3__5 = 0.0;
                double q_acc_3_3__5 = 0.0;
                for (int64_t q__5 = 0LL; q__5 < 1LL; q__5 += 1LL) {
                  const double tmp_qloop_0__5 =
                      (k_dof_0__5 * phi_0_0__5[4LL * q__5] +
                       k_dof_1__5 * phi_0_0__5[1LL + 4LL * q__5] +
                       k_dof_2__5 * phi_0_0__5[2LL + 4LL * q__5] +
                       k_dof_3__5 * phi_0_0__5[3LL + 4LL * q__5]) *
                      q_w[q__5];
                  const double q_tmp_0_0__5 =
                      tmp_qloop_0__5 *
                      tabulated_and_untitled_0_0__5[10LL * q__5];
                  const double q_tmp_0_1__5 =
                      tmp_qloop_0__5 *
                      tabulated_and_untitled_0_0__5[1LL + 10LL * q__5];
                  const double q_tmp_0_2__5 =
                      tmp_qloop_0__5 *
                      tabulated_and_untitled_0_0__5[2LL + 10LL * q__5];
                  const double q_tmp_0_3__5 =
                      tmp_qloop_0__5 *
                      tabulated_and_untitled_0_0__5[3LL + 10LL * q__5];
                  const double q_tmp_1_1__5 =
                      tmp_qloop_0__5 *
                      tabulated_and_untitled_0_0__5[4LL + 10LL * q__5];
                  const double q_tmp_1_2__5 =
                      tmp_qloop_0__5 *
                      tabulated_and_untitled_0_0__5[5LL + 10LL * q__5];
                  const double q_tmp_1_3__5 =
                      tmp_qloop_0__5 *
                      tabulated_and_untitled_0_0__5[6LL + 10LL * q__5];
                  const double q_tmp_2_2__5 =
                      tmp_qloop_0__5 *
                      tabulated_and_untitled_0_0__5[7LL + 10LL * q__5];
                  const double q_tmp_2_3__5 =
                      tmp_qloop_0__5 *
                      tabulated_and_untitled_0_0__5[8LL + 10LL * q__5];
                  const double q_tmp_3_3__5 =
                      tmp_qloop_0__5 *
                      tabulated_and_untitled_0_0__5[9LL + 10LL * q__5];
                  q_acc_0_0__5 = q_acc_0_0__5 + q_tmp_0_0__5;
                  q_acc_0_1__5 = q_acc_0_1__5 + q_tmp_0_1__5;
                  q_acc_0_2__5 = q_acc_0_2__5 + q_tmp_0_2__5;
                  q_acc_0_3__5 = q_acc_0_3__5 + q_tmp_0_3__5;
                  q_acc_1_1__5 = q_acc_1_1__5 + q_tmp_1_1__5;
                  q_acc_1_2__5 = q_acc_1_2__5 + q_tmp_1_2__5;
                  q_acc_1_3__5 = q_acc_1_3__5 + q_tmp_1_3__5;
                  q_acc_2_2__5 = q_acc_2_2__5 + q_tmp_2_2__5;
                  q_acc_2_3__5 = q_acc_2_3__5 + q_tmp_2_3__5;
                  q_acc_3_3__5 = q_acc_3_3__5 + q_tmp_3_3__5;
                }
                const double elMatVec_0__5 =
                    q_acc_0_0__5 * src_dof_0__5 + q_acc_0_1__5 * src_dof_1__5 +
                    q_acc_0_2__5 * src_dof_2__5 + q_acc_0_3__5 * src_dof_3__5;
                const double elMatVec_1__5 =
                    q_acc_0_1__5 * src_dof_0__5 + q_acc_1_1__5 * src_dof_1__5 +
                    q_acc_1_2__5 * src_dof_2__5 + q_acc_1_3__5 * src_dof_3__5;
                const double elMatVec_2__5 =
                    q_acc_0_2__5 * src_dof_0__5 + q_acc_1_2__5 * src_dof_1__5 +
                    q_acc_2_2__5 * src_dof_2__5 + q_acc_2_3__5 * src_dof_3__5;
                const double elMatVec_3__5 =
                    q_acc_0_3__5 * src_dof_0__5 + q_acc_1_3__5 * src_dof_1__5 +
                    q_acc_2_3__5 * src_dof_2__5 + q_acc_3_3__5 * src_dof_3__5;
                _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL + ctr_1) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) +
                          ctr_0__3 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_0__5 +
                    _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL + ctr_1) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) +
                          ctr_0__3 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_1__5 +
                    _data_dst[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                          (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__3 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_2__5 +
                    _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                          (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL + ctr_1) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) +
                          ctr_0__3 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_3__5 +
                    _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__3 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
              }
            }
          }
        }
        {
          const int64_t ctr_0__0 =
              -2LL - ctr_1 - ctr_2 + micro_edges_per_macro_edge;
          if (ctr_0__0 >= 0LL) {
            {
              /* CellType.WHITE_UP */
              const double tmp_coords_jac_0__4 =
                  macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_1__4 =
                  1.0 * (1.0 / micro_edges_per_macro_edge_float);
              const double tmp_coords_jac_2__4 = tmp_coords_jac_1__4 * 0.0;
              const double tmp_coords_jac_3__4 =
                  tmp_coords_jac_0__4 * tmp_coords_jac_2__4;
              const double tmp_coords_jac_4__4 =
                  macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_5__4 =
                  tmp_coords_jac_2__4 * tmp_coords_jac_4__4;
              const double tmp_coords_jac_6__4 =
                  macro_vertex_coord_id_3comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_7__4 =
                  tmp_coords_jac_2__4 * tmp_coords_jac_6__4;
              const double tmp_coords_jac_8__4 = macro_vertex_coord_id_0comp0 +
                                                 tmp_coords_jac_5__4 +
                                                 tmp_coords_jac_7__4;
              const double tmp_coords_jac_9__4 =
                  macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_10__4 =
                  tmp_coords_jac_2__4 * tmp_coords_jac_9__4;
              const double tmp_coords_jac_11__4 =
                  macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_12__4 =
                  tmp_coords_jac_11__4 * tmp_coords_jac_2__4;
              const double tmp_coords_jac_13__4 =
                  macro_vertex_coord_id_3comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_14__4 =
                  tmp_coords_jac_13__4 * tmp_coords_jac_2__4;
              const double tmp_coords_jac_15__4 = macro_vertex_coord_id_0comp1 +
                                                  tmp_coords_jac_12__4 +
                                                  tmp_coords_jac_14__4;
              const double tmp_coords_jac_16__4 =
                  macro_vertex_coord_id_1comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_17__4 =
                  tmp_coords_jac_16__4 * tmp_coords_jac_2__4;
              const double tmp_coords_jac_18__4 =
                  macro_vertex_coord_id_2comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_19__4 =
                  tmp_coords_jac_18__4 * tmp_coords_jac_2__4;
              const double tmp_coords_jac_20__4 =
                  macro_vertex_coord_id_3comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_21__4 =
                  tmp_coords_jac_2__4 * tmp_coords_jac_20__4;
              const double tmp_coords_jac_22__4 = macro_vertex_coord_id_0comp2 +
                                                  tmp_coords_jac_19__4 +
                                                  tmp_coords_jac_21__4;
              const double tmp_coords_jac_23__4 = tmp_coords_jac_1__4 * 1.0;
              const double tmp_coords_jac_24__4 =
                  macro_vertex_coord_id_0comp0 + tmp_coords_jac_3__4;
              const double tmp_coords_jac_25__4 =
                  macro_vertex_coord_id_0comp1 + tmp_coords_jac_10__4;
              const double tmp_coords_jac_26__4 =
                  macro_vertex_coord_id_0comp2 + tmp_coords_jac_17__4;
              const double p_affine_const_0_0__4 =
                  tmp_coords_jac_3__4 + tmp_coords_jac_8__4;
              const double p_affine_const_0_1__4 =
                  tmp_coords_jac_10__4 + tmp_coords_jac_15__4;
              const double p_affine_const_0_2__4 =
                  tmp_coords_jac_17__4 + tmp_coords_jac_22__4;
              const double p_affine_const_1_0__4 =
                  tmp_coords_jac_8__4 +
                  tmp_coords_jac_0__4 * tmp_coords_jac_23__4;
              const double p_affine_const_1_1__4 =
                  tmp_coords_jac_15__4 +
                  tmp_coords_jac_23__4 * tmp_coords_jac_9__4;
              const double p_affine_const_1_2__4 =
                  tmp_coords_jac_22__4 +
                  tmp_coords_jac_16__4 * tmp_coords_jac_23__4;
              const double p_affine_const_2_0__4 =
                  tmp_coords_jac_24__4 + tmp_coords_jac_7__4 +
                  tmp_coords_jac_23__4 * tmp_coords_jac_4__4;
              const double p_affine_const_2_1__4 =
                  tmp_coords_jac_14__4 + tmp_coords_jac_25__4 +
                  tmp_coords_jac_11__4 * tmp_coords_jac_23__4;
              const double p_affine_const_2_2__4 =
                  tmp_coords_jac_21__4 + tmp_coords_jac_26__4 +
                  tmp_coords_jac_18__4 * tmp_coords_jac_23__4;
              const double p_affine_const_3_0__4 =
                  tmp_coords_jac_24__4 + tmp_coords_jac_5__4 +
                  tmp_coords_jac_23__4 * tmp_coords_jac_6__4;
              const double p_affine_const_3_1__4 =
                  tmp_coords_jac_12__4 + tmp_coords_jac_25__4 +
                  tmp_coords_jac_13__4 * tmp_coords_jac_23__4;
              const double p_affine_const_3_2__4 =
                  tmp_coords_jac_19__4 + tmp_coords_jac_26__4 +
                  tmp_coords_jac_20__4 * tmp_coords_jac_23__4;
              const double jac_affine_0_0__4 =
                  p_affine_const_1_0__4 - p_affine_const_0_0__4;
              const double jac_affine_0_1__4 =
                  p_affine_const_2_0__4 - p_affine_const_0_0__4;
              const double jac_affine_0_2__4 =
                  p_affine_const_3_0__4 - p_affine_const_0_0__4;
              const double jac_affine_1_0__4 =
                  p_affine_const_1_1__4 - p_affine_const_0_1__4;
              const double jac_affine_1_1__4 =
                  p_affine_const_2_1__4 - p_affine_const_0_1__4;
              const double tmp_coords_jac_31__3 =
                  jac_affine_0_2__4 * jac_affine_1_1__4;
              const double jac_affine_1_2__4 =
                  p_affine_const_3_1__4 - p_affine_const_0_1__4;
              const double tmp_coords_jac_29__4 =
                  jac_affine_0_1__4 * jac_affine_1_2__4;
              const double jac_affine_2_0__4 =
                  p_affine_const_1_2__4 - p_affine_const_0_2__4;
              const double jac_affine_2_1__4 =
                  p_affine_const_2_2__4 - p_affine_const_0_2__4;
              const double tmp_coords_jac_28__4 =
                  jac_affine_1_2__4 * jac_affine_2_1__4;
              const double jac_affine_2_2__4 =
                  p_affine_const_3_2__4 - p_affine_const_0_2__4;
              const double tmp_coords_jac_27__4 =
                  jac_affine_1_1__4 * jac_affine_2_2__4;
              const double tmp_coords_jac_30__4 =
                  jac_affine_0_1__4 * jac_affine_2_2__4;
              const double tmp_coords_jac_32__3 =
                  jac_affine_0_0__4 * tmp_coords_jac_27__4 +
                  jac_affine_2_0__4 * tmp_coords_jac_29__4 -
                  jac_affine_0_0__4 * tmp_coords_jac_28__4 -
                  jac_affine_1_0__4 * tmp_coords_jac_30__4 -
                  jac_affine_2_0__4 * tmp_coords_jac_31__3 +
                  jac_affine_0_2__4 * jac_affine_1_0__4 * jac_affine_2_1__4;
              const double tmp_coords_jac_33__3 = 1.0 / tmp_coords_jac_32__3;
              const double jac_affine_inv_0_0__4 =
                  tmp_coords_jac_33__3 *
                  (tmp_coords_jac_27__4 - tmp_coords_jac_28__4);
              const double jac_affine_inv_0_1__4 =
                  tmp_coords_jac_33__3 *
                  (-1.0 * tmp_coords_jac_30__4 +
                   jac_affine_0_2__4 * jac_affine_2_1__4);
              const double jac_affine_inv_0_2__4 =
                  tmp_coords_jac_33__3 *
                  (tmp_coords_jac_29__4 - tmp_coords_jac_31__3);
              const double jac_affine_inv_1_0__4 =
                  tmp_coords_jac_33__3 *
                  (jac_affine_1_2__4 * jac_affine_2_0__4 -
                   jac_affine_1_0__4 * jac_affine_2_2__4);
              const double jac_affine_inv_1_1__4 =
                  tmp_coords_jac_33__3 *
                  (jac_affine_0_0__4 * jac_affine_2_2__4 -
                   jac_affine_0_2__4 * jac_affine_2_0__4);
              const double jac_affine_inv_1_2__4 =
                  tmp_coords_jac_33__3 *
                  (jac_affine_0_2__4 * jac_affine_1_0__4 -
                   jac_affine_0_0__4 * jac_affine_1_2__4);
              const double jac_affine_inv_2_0__4 =
                  tmp_coords_jac_33__3 *
                  (jac_affine_1_0__4 * jac_affine_2_1__4 -
                   jac_affine_1_1__4 * jac_affine_2_0__4);
              const double jac_affine_inv_2_1__4 =
                  tmp_coords_jac_33__3 *
                  (jac_affine_0_1__4 * jac_affine_2_0__4 -
                   jac_affine_0_0__4 * jac_affine_2_1__4);
              const double jac_affine_inv_2_2__4 =
                  tmp_coords_jac_33__3 *
                  (jac_affine_0_0__4 * jac_affine_1_1__4 -
                   jac_affine_0_1__4 * jac_affine_1_0__4);
              const double abs_det_jac_affine__4 = abs(tmp_coords_jac_32__3);
              double phi_0_0__4[4] = {0.25, 0.25, 0.25, 0.25};
              double tabulated_and_untitled_0_0__4[10] = {
                  abs_det_jac_affine__4 *
                      ((-1.0 * jac_affine_inv_0_0__4 - jac_affine_inv_1_0__4 -
                        jac_affine_inv_2_0__4) *
                           (-1.0 * jac_affine_inv_0_0__4 -
                            jac_affine_inv_1_0__4 - jac_affine_inv_2_0__4) +
                       (-1.0 * jac_affine_inv_0_1__4 - jac_affine_inv_1_1__4 -
                        jac_affine_inv_2_1__4) *
                           (-1.0 * jac_affine_inv_0_1__4 -
                            jac_affine_inv_1_1__4 - jac_affine_inv_2_1__4) +
                       (-1.0 * jac_affine_inv_0_2__4 - jac_affine_inv_1_2__4 -
                        jac_affine_inv_2_2__4) *
                           (-1.0 * jac_affine_inv_0_2__4 -
                            jac_affine_inv_1_2__4 - jac_affine_inv_2_2__4)),
                  abs_det_jac_affine__4 *
                      (jac_affine_inv_0_0__4 *
                           (-1.0 * jac_affine_inv_0_0__4 -
                            jac_affine_inv_1_0__4 - jac_affine_inv_2_0__4) +
                       jac_affine_inv_0_1__4 *
                           (-1.0 * jac_affine_inv_0_1__4 -
                            jac_affine_inv_1_1__4 - jac_affine_inv_2_1__4) +
                       jac_affine_inv_0_2__4 *
                           (-1.0 * jac_affine_inv_0_2__4 -
                            jac_affine_inv_1_2__4 - jac_affine_inv_2_2__4)),
                  abs_det_jac_affine__4 *
                      (jac_affine_inv_1_0__4 *
                           (-1.0 * jac_affine_inv_0_0__4 -
                            jac_affine_inv_1_0__4 - jac_affine_inv_2_0__4) +
                       jac_affine_inv_1_1__4 *
                           (-1.0 * jac_affine_inv_0_1__4 -
                            jac_affine_inv_1_1__4 - jac_affine_inv_2_1__4) +
                       jac_affine_inv_1_2__4 *
                           (-1.0 * jac_affine_inv_0_2__4 -
                            jac_affine_inv_1_2__4 - jac_affine_inv_2_2__4)),
                  abs_det_jac_affine__4 *
                      (jac_affine_inv_2_0__4 *
                           (-1.0 * jac_affine_inv_0_0__4 -
                            jac_affine_inv_1_0__4 - jac_affine_inv_2_0__4) +
                       jac_affine_inv_2_1__4 *
                           (-1.0 * jac_affine_inv_0_1__4 -
                            jac_affine_inv_1_1__4 - jac_affine_inv_2_1__4) +
                       jac_affine_inv_2_2__4 *
                           (-1.0 * jac_affine_inv_0_2__4 -
                            jac_affine_inv_1_2__4 - jac_affine_inv_2_2__4)),
                  abs_det_jac_affine__4 *
                      (jac_affine_inv_0_0__4 * jac_affine_inv_0_0__4 +
                       jac_affine_inv_0_1__4 * jac_affine_inv_0_1__4 +
                       jac_affine_inv_0_2__4 * jac_affine_inv_0_2__4),
                  abs_det_jac_affine__4 *
                      (jac_affine_inv_0_0__4 * jac_affine_inv_1_0__4 +
                       jac_affine_inv_0_1__4 * jac_affine_inv_1_1__4 +
                       jac_affine_inv_0_2__4 * jac_affine_inv_1_2__4),
                  abs_det_jac_affine__4 *
                      (jac_affine_inv_0_0__4 * jac_affine_inv_2_0__4 +
                       jac_affine_inv_0_1__4 * jac_affine_inv_2_1__4 +
                       jac_affine_inv_0_2__4 * jac_affine_inv_2_2__4),
                  abs_det_jac_affine__4 *
                      (jac_affine_inv_1_0__4 * jac_affine_inv_1_0__4 +
                       jac_affine_inv_1_1__4 * jac_affine_inv_1_1__4 +
                       jac_affine_inv_1_2__4 * jac_affine_inv_1_2__4),
                  abs_det_jac_affine__4 *
                      (jac_affine_inv_1_0__4 * jac_affine_inv_2_0__4 +
                       jac_affine_inv_1_1__4 * jac_affine_inv_2_1__4 +
                       jac_affine_inv_1_2__4 * jac_affine_inv_2_2__4),
                  abs_det_jac_affine__4 *
                      (jac_affine_inv_2_0__4 * jac_affine_inv_2_0__4 +
                       jac_affine_inv_2_1__4 * jac_affine_inv_2_1__4 +
                       jac_affine_inv_2_2__4 * jac_affine_inv_2_2__4)};
              {
                const double p_affine_0_0__4 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_0_1__4 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_0_2__4 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_1_0__4 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_1_1__4 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_1_2__4 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_2_0__4 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_2_1__4 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_2_2__4 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_3_0__4 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_1__4 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_2__4 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double src_dof_0__4 =
                    _data_src[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_1__4 =
                    _data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_2__4 =
                    _data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_3__4 =
                    _data_src[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_0__4 =
                    _data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_1__4 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_2__4 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_3__4 =
                    _data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                double q_acc_0_0__4 = 0.0;
                double q_acc_0_1__4 = 0.0;
                double q_acc_0_2__4 = 0.0;
                double q_acc_0_3__4 = 0.0;
                double q_acc_1_1__4 = 0.0;
                double q_acc_1_2__4 = 0.0;
                double q_acc_1_3__4 = 0.0;
                double q_acc_2_2__4 = 0.0;
                double q_acc_2_3__4 = 0.0;
                double q_acc_3_3__4 = 0.0;
                for (int64_t q__4 = 0LL; q__4 < 1LL; q__4 += 1LL) {
                  const double tmp_qloop_0__4 =
                      (k_dof_0__4 * phi_0_0__4[4LL * q__4] +
                       k_dof_1__4 * phi_0_0__4[1LL + 4LL * q__4] +
                       k_dof_2__4 * phi_0_0__4[2LL + 4LL * q__4] +
                       k_dof_3__4 * phi_0_0__4[3LL + 4LL * q__4]) *
                      q_w[q__4];
                  const double q_tmp_0_0__4 =
                      tmp_qloop_0__4 *
                      tabulated_and_untitled_0_0__4[10LL * q__4];
                  const double q_tmp_0_1__4 =
                      tmp_qloop_0__4 *
                      tabulated_and_untitled_0_0__4[1LL + 10LL * q__4];
                  const double q_tmp_0_2__4 =
                      tmp_qloop_0__4 *
                      tabulated_and_untitled_0_0__4[2LL + 10LL * q__4];
                  const double q_tmp_0_3__4 =
                      tmp_qloop_0__4 *
                      tabulated_and_untitled_0_0__4[3LL + 10LL * q__4];
                  const double q_tmp_1_1__4 =
                      tmp_qloop_0__4 *
                      tabulated_and_untitled_0_0__4[4LL + 10LL * q__4];
                  const double q_tmp_1_2__4 =
                      tmp_qloop_0__4 *
                      tabulated_and_untitled_0_0__4[5LL + 10LL * q__4];
                  const double q_tmp_1_3__4 =
                      tmp_qloop_0__4 *
                      tabulated_and_untitled_0_0__4[6LL + 10LL * q__4];
                  const double q_tmp_2_2__4 =
                      tmp_qloop_0__4 *
                      tabulated_and_untitled_0_0__4[7LL + 10LL * q__4];
                  const double q_tmp_2_3__4 =
                      tmp_qloop_0__4 *
                      tabulated_and_untitled_0_0__4[8LL + 10LL * q__4];
                  const double q_tmp_3_3__4 =
                      tmp_qloop_0__4 *
                      tabulated_and_untitled_0_0__4[9LL + 10LL * q__4];
                  q_acc_0_0__4 = q_acc_0_0__4 + q_tmp_0_0__4;
                  q_acc_0_1__4 = q_acc_0_1__4 + q_tmp_0_1__4;
                  q_acc_0_2__4 = q_acc_0_2__4 + q_tmp_0_2__4;
                  q_acc_0_3__4 = q_acc_0_3__4 + q_tmp_0_3__4;
                  q_acc_1_1__4 = q_acc_1_1__4 + q_tmp_1_1__4;
                  q_acc_1_2__4 = q_acc_1_2__4 + q_tmp_1_2__4;
                  q_acc_1_3__4 = q_acc_1_3__4 + q_tmp_1_3__4;
                  q_acc_2_2__4 = q_acc_2_2__4 + q_tmp_2_2__4;
                  q_acc_2_3__4 = q_acc_2_3__4 + q_tmp_2_3__4;
                  q_acc_3_3__4 = q_acc_3_3__4 + q_tmp_3_3__4;
                }
                const double elMatVec_0__4 =
                    q_acc_0_0__4 * src_dof_0__4 + q_acc_0_1__4 * src_dof_1__4 +
                    q_acc_0_2__4 * src_dof_2__4 + q_acc_0_3__4 * src_dof_3__4;
                const double elMatVec_1__4 =
                    q_acc_0_1__4 * src_dof_0__4 + q_acc_1_1__4 * src_dof_1__4 +
                    q_acc_1_2__4 * src_dof_2__4 + q_acc_1_3__4 * src_dof_3__4;
                const double elMatVec_2__4 =
                    q_acc_0_2__4 * src_dof_0__4 + q_acc_1_2__4 * src_dof_1__4 +
                    q_acc_2_2__4 * src_dof_2__4 + q_acc_2_3__4 * src_dof_3__4;
                const double elMatVec_3__4 =
                    q_acc_0_3__4 * src_dof_0__4 + q_acc_1_3__4 * src_dof_1__4 +
                    q_acc_2_3__4 * src_dof_2__4 + q_acc_3_3__4 * src_dof_3__4;
                _data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_0__4 +
                    _data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_1__4 +
                    _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL + ctr_1) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) +
                          ctr_0__0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_2__4 +
                    _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                          (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_3__4 +
                    _data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
              }
            }
            {
              /* CellType.BLUE_UP */
              const double tmp_coords_jac_0__3 =
                  macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_1__3 =
                  1.0 * (1.0 / micro_edges_per_macro_edge_float);
              const double tmp_coords_jac_2__3 = tmp_coords_jac_1__3 * 0.0;
              const double tmp_coords_jac_3__3 =
                  tmp_coords_jac_0__3 * tmp_coords_jac_2__3;
              const double tmp_coords_jac_4__3 =
                  macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_5__3 = tmp_coords_jac_1__3 * 1.0;
              const double tmp_coords_jac_6__3 =
                  tmp_coords_jac_4__3 * tmp_coords_jac_5__3;
              const double tmp_coords_jac_7__3 =
                  macro_vertex_coord_id_3comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_8__3 =
                  macro_vertex_coord_id_0comp0 +
                  tmp_coords_jac_2__3 * tmp_coords_jac_7__3;
              const double tmp_coords_jac_9__3 =
                  tmp_coords_jac_6__3 + tmp_coords_jac_8__3;
              const double tmp_coords_jac_10__3 =
                  macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_11__3 =
                  tmp_coords_jac_10__3 * tmp_coords_jac_2__3;
              const double tmp_coords_jac_12__3 =
                  macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_13__3 =
                  tmp_coords_jac_12__3 * tmp_coords_jac_5__3;
              const double tmp_coords_jac_14__3 =
                  macro_vertex_coord_id_3comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_15__3 =
                  macro_vertex_coord_id_0comp1 +
                  tmp_coords_jac_14__3 * tmp_coords_jac_2__3;
              const double tmp_coords_jac_16__3 =
                  tmp_coords_jac_13__3 + tmp_coords_jac_15__3;
              const double tmp_coords_jac_17__3 =
                  macro_vertex_coord_id_2comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_18__3 =
                  tmp_coords_jac_17__3 * tmp_coords_jac_2__3;
              const double tmp_coords_jac_19__3 =
                  macro_vertex_coord_id_1comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_20__3 =
                  tmp_coords_jac_19__3 * tmp_coords_jac_5__3;
              const double tmp_coords_jac_21__3 =
                  macro_vertex_coord_id_3comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_22__3 =
                  macro_vertex_coord_id_0comp2 +
                  tmp_coords_jac_2__3 * tmp_coords_jac_21__3;
              const double tmp_coords_jac_23__3 =
                  tmp_coords_jac_20__3 + tmp_coords_jac_22__3;
              const double tmp_coords_jac_24__3 =
                  tmp_coords_jac_0__3 * tmp_coords_jac_5__3;
              const double tmp_coords_jac_25__3 =
                  tmp_coords_jac_10__3 * tmp_coords_jac_5__3;
              const double tmp_coords_jac_26__3 =
                  tmp_coords_jac_17__3 * tmp_coords_jac_5__3;
              const double p_affine_const_0_0__3 =
                  tmp_coords_jac_3__3 + tmp_coords_jac_9__3;
              const double p_affine_const_0_1__3 =
                  tmp_coords_jac_11__3 + tmp_coords_jac_16__3;
              const double p_affine_const_0_2__3 =
                  tmp_coords_jac_18__3 + tmp_coords_jac_23__3;
              const double p_affine_const_1_0__3 =
                  tmp_coords_jac_24__3 + tmp_coords_jac_8__3 +
                  tmp_coords_jac_2__3 * tmp_coords_jac_4__3;
              const double p_affine_const_1_1__3 =
                  tmp_coords_jac_15__3 + tmp_coords_jac_25__3 +
                  tmp_coords_jac_12__3 * tmp_coords_jac_2__3;
              const double p_affine_const_1_2__3 =
                  tmp_coords_jac_22__3 + tmp_coords_jac_26__3 +
                  tmp_coords_jac_19__3 * tmp_coords_jac_2__3;
              const double p_affine_const_2_0__3 =
                  tmp_coords_jac_24__3 + tmp_coords_jac_9__3;
              const double p_affine_const_2_1__3 =
                  tmp_coords_jac_16__3 + tmp_coords_jac_25__3;
              const double p_affine_const_2_2__3 =
                  tmp_coords_jac_23__3 + tmp_coords_jac_26__3;
              const double p_affine_const_3_0__3 =
                  macro_vertex_coord_id_0comp0 + tmp_coords_jac_3__3 +
                  tmp_coords_jac_6__3 +
                  tmp_coords_jac_5__3 * tmp_coords_jac_7__3;
              const double p_affine_const_3_1__3 =
                  macro_vertex_coord_id_0comp1 + tmp_coords_jac_11__3 +
                  tmp_coords_jac_13__3 +
                  tmp_coords_jac_14__3 * tmp_coords_jac_5__3;
              const double p_affine_const_3_2__3 =
                  macro_vertex_coord_id_0comp2 + tmp_coords_jac_18__3 +
                  tmp_coords_jac_20__3 +
                  tmp_coords_jac_21__3 * tmp_coords_jac_5__3;
              const double jac_affine_0_0__3 =
                  p_affine_const_1_0__3 - p_affine_const_0_0__3;
              const double jac_affine_0_1__3 =
                  p_affine_const_2_0__3 - p_affine_const_0_0__3;
              const double jac_affine_0_2__3 =
                  p_affine_const_3_0__3 - p_affine_const_0_0__3;
              const double jac_affine_1_0__3 =
                  p_affine_const_1_1__3 - p_affine_const_0_1__3;
              const double jac_affine_1_1__3 =
                  p_affine_const_2_1__3 - p_affine_const_0_1__3;
              const double tmp_coords_jac_31__2 =
                  jac_affine_0_2__3 * jac_affine_1_1__3;
              const double jac_affine_1_2__3 =
                  p_affine_const_3_1__3 - p_affine_const_0_1__3;
              const double tmp_coords_jac_29__3 =
                  jac_affine_0_1__3 * jac_affine_1_2__3;
              const double jac_affine_2_0__3 =
                  p_affine_const_1_2__3 - p_affine_const_0_2__3;
              const double jac_affine_2_1__3 =
                  p_affine_const_2_2__3 - p_affine_const_0_2__3;
              const double tmp_coords_jac_28__3 =
                  jac_affine_1_2__3 * jac_affine_2_1__3;
              const double jac_affine_2_2__3 =
                  p_affine_const_3_2__3 - p_affine_const_0_2__3;
              const double tmp_coords_jac_27__3 =
                  jac_affine_1_1__3 * jac_affine_2_2__3;
              const double tmp_coords_jac_30__3 =
                  jac_affine_0_1__3 * jac_affine_2_2__3;
              const double tmp_coords_jac_32__2 =
                  jac_affine_0_0__3 * tmp_coords_jac_27__3 +
                  jac_affine_2_0__3 * tmp_coords_jac_29__3 -
                  jac_affine_0_0__3 * tmp_coords_jac_28__3 -
                  jac_affine_1_0__3 * tmp_coords_jac_30__3 -
                  jac_affine_2_0__3 * tmp_coords_jac_31__2 +
                  jac_affine_0_2__3 * jac_affine_1_0__3 * jac_affine_2_1__3;
              const double tmp_coords_jac_33__2 = 1.0 / tmp_coords_jac_32__2;
              const double jac_affine_inv_0_0__3 =
                  tmp_coords_jac_33__2 *
                  (tmp_coords_jac_27__3 - tmp_coords_jac_28__3);
              const double jac_affine_inv_0_1__3 =
                  tmp_coords_jac_33__2 *
                  (-1.0 * tmp_coords_jac_30__3 +
                   jac_affine_0_2__3 * jac_affine_2_1__3);
              const double jac_affine_inv_0_2__3 =
                  tmp_coords_jac_33__2 *
                  (tmp_coords_jac_29__3 - tmp_coords_jac_31__2);
              const double jac_affine_inv_1_0__3 =
                  tmp_coords_jac_33__2 *
                  (jac_affine_1_2__3 * jac_affine_2_0__3 -
                   jac_affine_1_0__3 * jac_affine_2_2__3);
              const double jac_affine_inv_1_1__3 =
                  tmp_coords_jac_33__2 *
                  (jac_affine_0_0__3 * jac_affine_2_2__3 -
                   jac_affine_0_2__3 * jac_affine_2_0__3);
              const double jac_affine_inv_1_2__3 =
                  tmp_coords_jac_33__2 *
                  (jac_affine_0_2__3 * jac_affine_1_0__3 -
                   jac_affine_0_0__3 * jac_affine_1_2__3);
              const double jac_affine_inv_2_0__3 =
                  tmp_coords_jac_33__2 *
                  (jac_affine_1_0__3 * jac_affine_2_1__3 -
                   jac_affine_1_1__3 * jac_affine_2_0__3);
              const double jac_affine_inv_2_1__3 =
                  tmp_coords_jac_33__2 *
                  (jac_affine_0_1__3 * jac_affine_2_0__3 -
                   jac_affine_0_0__3 * jac_affine_2_1__3);
              const double jac_affine_inv_2_2__3 =
                  tmp_coords_jac_33__2 *
                  (jac_affine_0_0__3 * jac_affine_1_1__3 -
                   jac_affine_0_1__3 * jac_affine_1_0__3);
              const double abs_det_jac_affine__3 = abs(tmp_coords_jac_32__2);
              double phi_0_0__3[4] = {0.25, 0.25, 0.25, 0.25};
              double tabulated_and_untitled_0_0__3[10] = {
                  abs_det_jac_affine__3 *
                      ((-1.0 * jac_affine_inv_0_0__3 - jac_affine_inv_1_0__3 -
                        jac_affine_inv_2_0__3) *
                           (-1.0 * jac_affine_inv_0_0__3 -
                            jac_affine_inv_1_0__3 - jac_affine_inv_2_0__3) +
                       (-1.0 * jac_affine_inv_0_1__3 - jac_affine_inv_1_1__3 -
                        jac_affine_inv_2_1__3) *
                           (-1.0 * jac_affine_inv_0_1__3 -
                            jac_affine_inv_1_1__3 - jac_affine_inv_2_1__3) +
                       (-1.0 * jac_affine_inv_0_2__3 - jac_affine_inv_1_2__3 -
                        jac_affine_inv_2_2__3) *
                           (-1.0 * jac_affine_inv_0_2__3 -
                            jac_affine_inv_1_2__3 - jac_affine_inv_2_2__3)),
                  abs_det_jac_affine__3 *
                      (jac_affine_inv_0_0__3 *
                           (-1.0 * jac_affine_inv_0_0__3 -
                            jac_affine_inv_1_0__3 - jac_affine_inv_2_0__3) +
                       jac_affine_inv_0_1__3 *
                           (-1.0 * jac_affine_inv_0_1__3 -
                            jac_affine_inv_1_1__3 - jac_affine_inv_2_1__3) +
                       jac_affine_inv_0_2__3 *
                           (-1.0 * jac_affine_inv_0_2__3 -
                            jac_affine_inv_1_2__3 - jac_affine_inv_2_2__3)),
                  abs_det_jac_affine__3 *
                      (jac_affine_inv_1_0__3 *
                           (-1.0 * jac_affine_inv_0_0__3 -
                            jac_affine_inv_1_0__3 - jac_affine_inv_2_0__3) +
                       jac_affine_inv_1_1__3 *
                           (-1.0 * jac_affine_inv_0_1__3 -
                            jac_affine_inv_1_1__3 - jac_affine_inv_2_1__3) +
                       jac_affine_inv_1_2__3 *
                           (-1.0 * jac_affine_inv_0_2__3 -
                            jac_affine_inv_1_2__3 - jac_affine_inv_2_2__3)),
                  abs_det_jac_affine__3 *
                      (jac_affine_inv_2_0__3 *
                           (-1.0 * jac_affine_inv_0_0__3 -
                            jac_affine_inv_1_0__3 - jac_affine_inv_2_0__3) +
                       jac_affine_inv_2_1__3 *
                           (-1.0 * jac_affine_inv_0_1__3 -
                            jac_affine_inv_1_1__3 - jac_affine_inv_2_1__3) +
                       jac_affine_inv_2_2__3 *
                           (-1.0 * jac_affine_inv_0_2__3 -
                            jac_affine_inv_1_2__3 - jac_affine_inv_2_2__3)),
                  abs_det_jac_affine__3 *
                      (jac_affine_inv_0_0__3 * jac_affine_inv_0_0__3 +
                       jac_affine_inv_0_1__3 * jac_affine_inv_0_1__3 +
                       jac_affine_inv_0_2__3 * jac_affine_inv_0_2__3),
                  abs_det_jac_affine__3 *
                      (jac_affine_inv_0_0__3 * jac_affine_inv_1_0__3 +
                       jac_affine_inv_0_1__3 * jac_affine_inv_1_1__3 +
                       jac_affine_inv_0_2__3 * jac_affine_inv_1_2__3),
                  abs_det_jac_affine__3 *
                      (jac_affine_inv_0_0__3 * jac_affine_inv_2_0__3 +
                       jac_affine_inv_0_1__3 * jac_affine_inv_2_1__3 +
                       jac_affine_inv_0_2__3 * jac_affine_inv_2_2__3),
                  abs_det_jac_affine__3 *
                      (jac_affine_inv_1_0__3 * jac_affine_inv_1_0__3 +
                       jac_affine_inv_1_1__3 * jac_affine_inv_1_1__3 +
                       jac_affine_inv_1_2__3 * jac_affine_inv_1_2__3),
                  abs_det_jac_affine__3 *
                      (jac_affine_inv_1_0__3 * jac_affine_inv_2_0__3 +
                       jac_affine_inv_1_1__3 * jac_affine_inv_2_1__3 +
                       jac_affine_inv_1_2__3 * jac_affine_inv_2_2__3),
                  abs_det_jac_affine__3 *
                      (jac_affine_inv_2_0__3 * jac_affine_inv_2_0__3 +
                       jac_affine_inv_2_1__3 * jac_affine_inv_2_1__3 +
                       jac_affine_inv_2_2__3 * jac_affine_inv_2_2__3)};
              {
                const double p_affine_0_0__3 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_0_1__3 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_0_2__3 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_1_0__3 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_1_1__3 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_1_2__3 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_2_0__3 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_2_1__3 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_2_2__3 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_3_0__3 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_1__3 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_2__3 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double src_dof_0__3 =
                    _data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_1__3 =
                    _data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_2__3 =
                    _data_src[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_3__3 =
                    _data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_0__3 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_1__3 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_2__3 =
                    _data_k[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_3__3 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                double q_acc_0_0__3 = 0.0;
                double q_acc_0_1__3 = 0.0;
                double q_acc_0_2__3 = 0.0;
                double q_acc_0_3__3 = 0.0;
                double q_acc_1_1__3 = 0.0;
                double q_acc_1_2__3 = 0.0;
                double q_acc_1_3__3 = 0.0;
                double q_acc_2_2__3 = 0.0;
                double q_acc_2_3__3 = 0.0;
                double q_acc_3_3__3 = 0.0;
                for (int64_t q__3 = 0LL; q__3 < 1LL; q__3 += 1LL) {
                  const double tmp_qloop_0__3 =
                      (k_dof_0__3 * phi_0_0__3[4LL * q__3] +
                       k_dof_1__3 * phi_0_0__3[1LL + 4LL * q__3] +
                       k_dof_2__3 * phi_0_0__3[2LL + 4LL * q__3] +
                       k_dof_3__3 * phi_0_0__3[3LL + 4LL * q__3]) *
                      q_w[q__3];
                  const double q_tmp_0_0__3 =
                      tmp_qloop_0__3 *
                      tabulated_and_untitled_0_0__3[10LL * q__3];
                  const double q_tmp_0_1__3 =
                      tmp_qloop_0__3 *
                      tabulated_and_untitled_0_0__3[1LL + 10LL * q__3];
                  const double q_tmp_0_2__3 =
                      tmp_qloop_0__3 *
                      tabulated_and_untitled_0_0__3[2LL + 10LL * q__3];
                  const double q_tmp_0_3__3 =
                      tmp_qloop_0__3 *
                      tabulated_and_untitled_0_0__3[3LL + 10LL * q__3];
                  const double q_tmp_1_1__3 =
                      tmp_qloop_0__3 *
                      tabulated_and_untitled_0_0__3[4LL + 10LL * q__3];
                  const double q_tmp_1_2__3 =
                      tmp_qloop_0__3 *
                      tabulated_and_untitled_0_0__3[5LL + 10LL * q__3];
                  const double q_tmp_1_3__3 =
                      tmp_qloop_0__3 *
                      tabulated_and_untitled_0_0__3[6LL + 10LL * q__3];
                  const double q_tmp_2_2__3 =
                      tmp_qloop_0__3 *
                      tabulated_and_untitled_0_0__3[7LL + 10LL * q__3];
                  const double q_tmp_2_3__3 =
                      tmp_qloop_0__3 *
                      tabulated_and_untitled_0_0__3[8LL + 10LL * q__3];
                  const double q_tmp_3_3__3 =
                      tmp_qloop_0__3 *
                      tabulated_and_untitled_0_0__3[9LL + 10LL * q__3];
                  q_acc_0_0__3 = q_acc_0_0__3 + q_tmp_0_0__3;
                  q_acc_0_1__3 = q_acc_0_1__3 + q_tmp_0_1__3;
                  q_acc_0_2__3 = q_acc_0_2__3 + q_tmp_0_2__3;
                  q_acc_0_3__3 = q_acc_0_3__3 + q_tmp_0_3__3;
                  q_acc_1_1__3 = q_acc_1_1__3 + q_tmp_1_1__3;
                  q_acc_1_2__3 = q_acc_1_2__3 + q_tmp_1_2__3;
                  q_acc_1_3__3 = q_acc_1_3__3 + q_tmp_1_3__3;
                  q_acc_2_2__3 = q_acc_2_2__3 + q_tmp_2_2__3;
                  q_acc_2_3__3 = q_acc_2_3__3 + q_tmp_2_3__3;
                  q_acc_3_3__3 = q_acc_3_3__3 + q_tmp_3_3__3;
                }
                const double elMatVec_0__3 =
                    q_acc_0_0__3 * src_dof_0__3 + q_acc_0_1__3 * src_dof_1__3 +
                    q_acc_0_2__3 * src_dof_2__3 + q_acc_0_3__3 * src_dof_3__3;
                const double elMatVec_1__3 =
                    q_acc_0_1__3 * src_dof_0__3 + q_acc_1_1__3 * src_dof_1__3 +
                    q_acc_1_2__3 * src_dof_2__3 + q_acc_1_3__3 * src_dof_3__3;
                const double elMatVec_2__3 =
                    q_acc_0_2__3 * src_dof_0__3 + q_acc_1_2__3 * src_dof_1__3 +
                    q_acc_2_2__3 * src_dof_2__3 + q_acc_2_3__3 * src_dof_3__3;
                const double elMatVec_3__3 =
                    q_acc_0_3__3 * src_dof_0__3 + q_acc_1_3__3 * src_dof_1__3 +
                    q_acc_2_3__3 * src_dof_2__3 + q_acc_3_3__3 * src_dof_3__3;
                _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_0__3 +
                    _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL + ctr_1) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) +
                          ctr_0__0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_1__3 +
                    _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL + ctr_1) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) +
                          ctr_0__0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_2__3 +
                    _data_dst[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                          (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_3__3 +
                    _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
              }
            }
            {
              /* CellType.BLUE_DOWN */
              const double tmp_coords_jac_0__2 =
                  macro_vertex_coord_id_3comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_1__2 =
                  1.0 * (1.0 / micro_edges_per_macro_edge_float);
              const double tmp_coords_jac_2__2 = tmp_coords_jac_1__2 * 0.0;
              const double tmp_coords_jac_3__2 =
                  macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_4__2 = tmp_coords_jac_1__2 * 1.0;
              const double tmp_coords_jac_5__2 =
                  macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_6__2 =
                  macro_vertex_coord_id_0comp0 +
                  tmp_coords_jac_2__2 * tmp_coords_jac_5__2;
              const double tmp_coords_jac_7__2 =
                  tmp_coords_jac_6__2 +
                  tmp_coords_jac_3__2 * tmp_coords_jac_4__2;
              const double tmp_coords_jac_8__2 =
                  macro_vertex_coord_id_3comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_9__2 =
                  macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_10__2 =
                  macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_11__2 =
                  macro_vertex_coord_id_0comp1 +
                  tmp_coords_jac_10__2 * tmp_coords_jac_2__2;
              const double tmp_coords_jac_12__2 =
                  tmp_coords_jac_11__2 +
                  tmp_coords_jac_4__2 * tmp_coords_jac_9__2;
              const double tmp_coords_jac_13__2 =
                  macro_vertex_coord_id_3comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_14__2 =
                  macro_vertex_coord_id_2comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_15__2 =
                  macro_vertex_coord_id_1comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_16__2 =
                  macro_vertex_coord_id_0comp2 +
                  tmp_coords_jac_15__2 * tmp_coords_jac_2__2;
              const double tmp_coords_jac_17__2 =
                  tmp_coords_jac_16__2 +
                  tmp_coords_jac_14__2 * tmp_coords_jac_4__2;
              const double tmp_coords_jac_18__2 =
                  tmp_coords_jac_0__2 * tmp_coords_jac_4__2;
              const double tmp_coords_jac_19__2 =
                  tmp_coords_jac_18__2 +
                  tmp_coords_jac_2__2 * tmp_coords_jac_3__2;
              const double tmp_coords_jac_20__2 =
                  tmp_coords_jac_4__2 * tmp_coords_jac_8__2;
              const double tmp_coords_jac_21__2 =
                  tmp_coords_jac_20__2 +
                  tmp_coords_jac_2__2 * tmp_coords_jac_9__2;
              const double tmp_coords_jac_22__2 =
                  tmp_coords_jac_13__2 * tmp_coords_jac_4__2;
              const double tmp_coords_jac_23__2 =
                  tmp_coords_jac_22__2 +
                  tmp_coords_jac_14__2 * tmp_coords_jac_2__2;
              const double p_affine_const_0_0__2 =
                  tmp_coords_jac_7__2 +
                  tmp_coords_jac_0__2 * tmp_coords_jac_2__2;
              const double p_affine_const_0_1__2 =
                  tmp_coords_jac_12__2 +
                  tmp_coords_jac_2__2 * tmp_coords_jac_8__2;
              const double p_affine_const_0_2__2 =
                  tmp_coords_jac_17__2 +
                  tmp_coords_jac_13__2 * tmp_coords_jac_2__2;
              const double p_affine_const_1_0__2 =
                  tmp_coords_jac_19__2 + tmp_coords_jac_6__2;
              const double p_affine_const_1_1__2 =
                  tmp_coords_jac_11__2 + tmp_coords_jac_21__2;
              const double p_affine_const_1_2__2 =
                  tmp_coords_jac_16__2 + tmp_coords_jac_23__2;
              const double p_affine_const_2_0__2 =
                  macro_vertex_coord_id_0comp0 + tmp_coords_jac_19__2 +
                  tmp_coords_jac_4__2 * tmp_coords_jac_5__2;
              const double p_affine_const_2_1__2 =
                  macro_vertex_coord_id_0comp1 + tmp_coords_jac_21__2 +
                  tmp_coords_jac_10__2 * tmp_coords_jac_4__2;
              const double p_affine_const_2_2__2 =
                  macro_vertex_coord_id_0comp2 + tmp_coords_jac_23__2 +
                  tmp_coords_jac_15__2 * tmp_coords_jac_4__2;
              const double p_affine_const_3_0__2 =
                  tmp_coords_jac_18__2 + tmp_coords_jac_7__2;
              const double p_affine_const_3_1__2 =
                  tmp_coords_jac_12__2 + tmp_coords_jac_20__2;
              const double p_affine_const_3_2__2 =
                  tmp_coords_jac_17__2 + tmp_coords_jac_22__2;
              const double jac_affine_0_0__2 =
                  p_affine_const_1_0__2 - p_affine_const_0_0__2;
              const double jac_affine_0_1__2 =
                  p_affine_const_2_0__2 - p_affine_const_0_0__2;
              const double jac_affine_0_2__2 =
                  p_affine_const_3_0__2 - p_affine_const_0_0__2;
              const double jac_affine_1_0__2 =
                  p_affine_const_1_1__2 - p_affine_const_0_1__2;
              const double jac_affine_1_1__2 =
                  p_affine_const_2_1__2 - p_affine_const_0_1__2;
              const double tmp_coords_jac_28__2 =
                  jac_affine_0_2__2 * jac_affine_1_1__2;
              const double jac_affine_1_2__2 =
                  p_affine_const_3_1__2 - p_affine_const_0_1__2;
              const double tmp_coords_jac_26__2 =
                  jac_affine_0_1__2 * jac_affine_1_2__2;
              const double jac_affine_2_0__2 =
                  p_affine_const_1_2__2 - p_affine_const_0_2__2;
              const double jac_affine_2_1__2 =
                  p_affine_const_2_2__2 - p_affine_const_0_2__2;
              const double tmp_coords_jac_25__2 =
                  jac_affine_1_2__2 * jac_affine_2_1__2;
              const double jac_affine_2_2__2 =
                  p_affine_const_3_2__2 - p_affine_const_0_2__2;
              const double tmp_coords_jac_24__2 =
                  jac_affine_1_1__2 * jac_affine_2_2__2;
              const double tmp_coords_jac_27__2 =
                  jac_affine_0_1__2 * jac_affine_2_2__2;
              const double tmp_coords_jac_29__2 =
                  jac_affine_0_0__2 * tmp_coords_jac_24__2 +
                  jac_affine_2_0__2 * tmp_coords_jac_26__2 -
                  jac_affine_0_0__2 * tmp_coords_jac_25__2 -
                  jac_affine_1_0__2 * tmp_coords_jac_27__2 -
                  jac_affine_2_0__2 * tmp_coords_jac_28__2 +
                  jac_affine_0_2__2 * jac_affine_1_0__2 * jac_affine_2_1__2;
              const double tmp_coords_jac_30__2 = 1.0 / tmp_coords_jac_29__2;
              const double jac_affine_inv_0_0__2 =
                  tmp_coords_jac_30__2 *
                  (tmp_coords_jac_24__2 - tmp_coords_jac_25__2);
              const double jac_affine_inv_0_1__2 =
                  tmp_coords_jac_30__2 *
                  (-1.0 * tmp_coords_jac_27__2 +
                   jac_affine_0_2__2 * jac_affine_2_1__2);
              const double jac_affine_inv_0_2__2 =
                  tmp_coords_jac_30__2 *
                  (tmp_coords_jac_26__2 - tmp_coords_jac_28__2);
              const double jac_affine_inv_1_0__2 =
                  tmp_coords_jac_30__2 *
                  (jac_affine_1_2__2 * jac_affine_2_0__2 -
                   jac_affine_1_0__2 * jac_affine_2_2__2);
              const double jac_affine_inv_1_1__2 =
                  tmp_coords_jac_30__2 *
                  (jac_affine_0_0__2 * jac_affine_2_2__2 -
                   jac_affine_0_2__2 * jac_affine_2_0__2);
              const double jac_affine_inv_1_2__2 =
                  tmp_coords_jac_30__2 *
                  (jac_affine_0_2__2 * jac_affine_1_0__2 -
                   jac_affine_0_0__2 * jac_affine_1_2__2);
              const double jac_affine_inv_2_0__2 =
                  tmp_coords_jac_30__2 *
                  (jac_affine_1_0__2 * jac_affine_2_1__2 -
                   jac_affine_1_1__2 * jac_affine_2_0__2);
              const double jac_affine_inv_2_1__2 =
                  tmp_coords_jac_30__2 *
                  (jac_affine_0_1__2 * jac_affine_2_0__2 -
                   jac_affine_0_0__2 * jac_affine_2_1__2);
              const double jac_affine_inv_2_2__2 =
                  tmp_coords_jac_30__2 *
                  (jac_affine_0_0__2 * jac_affine_1_1__2 -
                   jac_affine_0_1__2 * jac_affine_1_0__2);
              const double abs_det_jac_affine__2 = abs(tmp_coords_jac_29__2);
              double phi_0_0__2[4] = {0.25, 0.25, 0.25, 0.25};
              double tabulated_and_untitled_0_0__2[10] = {
                  abs_det_jac_affine__2 *
                      ((-1.0 * jac_affine_inv_0_0__2 - jac_affine_inv_1_0__2 -
                        jac_affine_inv_2_0__2) *
                           (-1.0 * jac_affine_inv_0_0__2 -
                            jac_affine_inv_1_0__2 - jac_affine_inv_2_0__2) +
                       (-1.0 * jac_affine_inv_0_1__2 - jac_affine_inv_1_1__2 -
                        jac_affine_inv_2_1__2) *
                           (-1.0 * jac_affine_inv_0_1__2 -
                            jac_affine_inv_1_1__2 - jac_affine_inv_2_1__2) +
                       (-1.0 * jac_affine_inv_0_2__2 - jac_affine_inv_1_2__2 -
                        jac_affine_inv_2_2__2) *
                           (-1.0 * jac_affine_inv_0_2__2 -
                            jac_affine_inv_1_2__2 - jac_affine_inv_2_2__2)),
                  abs_det_jac_affine__2 *
                      (jac_affine_inv_0_0__2 *
                           (-1.0 * jac_affine_inv_0_0__2 -
                            jac_affine_inv_1_0__2 - jac_affine_inv_2_0__2) +
                       jac_affine_inv_0_1__2 *
                           (-1.0 * jac_affine_inv_0_1__2 -
                            jac_affine_inv_1_1__2 - jac_affine_inv_2_1__2) +
                       jac_affine_inv_0_2__2 *
                           (-1.0 * jac_affine_inv_0_2__2 -
                            jac_affine_inv_1_2__2 - jac_affine_inv_2_2__2)),
                  abs_det_jac_affine__2 *
                      (jac_affine_inv_1_0__2 *
                           (-1.0 * jac_affine_inv_0_0__2 -
                            jac_affine_inv_1_0__2 - jac_affine_inv_2_0__2) +
                       jac_affine_inv_1_1__2 *
                           (-1.0 * jac_affine_inv_0_1__2 -
                            jac_affine_inv_1_1__2 - jac_affine_inv_2_1__2) +
                       jac_affine_inv_1_2__2 *
                           (-1.0 * jac_affine_inv_0_2__2 -
                            jac_affine_inv_1_2__2 - jac_affine_inv_2_2__2)),
                  abs_det_jac_affine__2 *
                      (jac_affine_inv_2_0__2 *
                           (-1.0 * jac_affine_inv_0_0__2 -
                            jac_affine_inv_1_0__2 - jac_affine_inv_2_0__2) +
                       jac_affine_inv_2_1__2 *
                           (-1.0 * jac_affine_inv_0_1__2 -
                            jac_affine_inv_1_1__2 - jac_affine_inv_2_1__2) +
                       jac_affine_inv_2_2__2 *
                           (-1.0 * jac_affine_inv_0_2__2 -
                            jac_affine_inv_1_2__2 - jac_affine_inv_2_2__2)),
                  abs_det_jac_affine__2 *
                      (jac_affine_inv_0_0__2 * jac_affine_inv_0_0__2 +
                       jac_affine_inv_0_1__2 * jac_affine_inv_0_1__2 +
                       jac_affine_inv_0_2__2 * jac_affine_inv_0_2__2),
                  abs_det_jac_affine__2 *
                      (jac_affine_inv_0_0__2 * jac_affine_inv_1_0__2 +
                       jac_affine_inv_0_1__2 * jac_affine_inv_1_1__2 +
                       jac_affine_inv_0_2__2 * jac_affine_inv_1_2__2),
                  abs_det_jac_affine__2 *
                      (jac_affine_inv_0_0__2 * jac_affine_inv_2_0__2 +
                       jac_affine_inv_0_1__2 * jac_affine_inv_2_1__2 +
                       jac_affine_inv_0_2__2 * jac_affine_inv_2_2__2),
                  abs_det_jac_affine__2 *
                      (jac_affine_inv_1_0__2 * jac_affine_inv_1_0__2 +
                       jac_affine_inv_1_1__2 * jac_affine_inv_1_1__2 +
                       jac_affine_inv_1_2__2 * jac_affine_inv_1_2__2),
                  abs_det_jac_affine__2 *
                      (jac_affine_inv_1_0__2 * jac_affine_inv_2_0__2 +
                       jac_affine_inv_1_1__2 * jac_affine_inv_2_1__2 +
                       jac_affine_inv_1_2__2 * jac_affine_inv_2_2__2),
                  abs_det_jac_affine__2 *
                      (jac_affine_inv_2_0__2 * jac_affine_inv_2_0__2 +
                       jac_affine_inv_2_1__2 * jac_affine_inv_2_1__2 +
                       jac_affine_inv_2_2__2 * jac_affine_inv_2_2__2)};
              {
                const double p_affine_0_0__2 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_0_1__2 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_0_2__2 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_1_0__2 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_1_1__2 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_1_2__2 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_0__2 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_1__2 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_2__2 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_0__2 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_1__2 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_2__2 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double src_dof_0__2 =
                    _data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_1__2 =
                    _data_src[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_2__2 =
                    _data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_3__2 =
                    _data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_0__2 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_1__2 =
                    _data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_2__2 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_3__2 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                double q_acc_0_0__2 = 0.0;
                double q_acc_0_1__2 = 0.0;
                double q_acc_0_2__2 = 0.0;
                double q_acc_0_3__2 = 0.0;
                double q_acc_1_1__2 = 0.0;
                double q_acc_1_2__2 = 0.0;
                double q_acc_1_3__2 = 0.0;
                double q_acc_2_2__2 = 0.0;
                double q_acc_2_3__2 = 0.0;
                double q_acc_3_3__2 = 0.0;
                for (int64_t q__2 = 0LL; q__2 < 1LL; q__2 += 1LL) {
                  const double tmp_qloop_0__2 =
                      (k_dof_0__2 * phi_0_0__2[4LL * q__2] +
                       k_dof_1__2 * phi_0_0__2[1LL + 4LL * q__2] +
                       k_dof_2__2 * phi_0_0__2[2LL + 4LL * q__2] +
                       k_dof_3__2 * phi_0_0__2[3LL + 4LL * q__2]) *
                      q_w[q__2];
                  const double q_tmp_0_0__2 =
                      tmp_qloop_0__2 *
                      tabulated_and_untitled_0_0__2[10LL * q__2];
                  const double q_tmp_0_1__2 =
                      tmp_qloop_0__2 *
                      tabulated_and_untitled_0_0__2[1LL + 10LL * q__2];
                  const double q_tmp_0_2__2 =
                      tmp_qloop_0__2 *
                      tabulated_and_untitled_0_0__2[2LL + 10LL * q__2];
                  const double q_tmp_0_3__2 =
                      tmp_qloop_0__2 *
                      tabulated_and_untitled_0_0__2[3LL + 10LL * q__2];
                  const double q_tmp_1_1__2 =
                      tmp_qloop_0__2 *
                      tabulated_and_untitled_0_0__2[4LL + 10LL * q__2];
                  const double q_tmp_1_2__2 =
                      tmp_qloop_0__2 *
                      tabulated_and_untitled_0_0__2[5LL + 10LL * q__2];
                  const double q_tmp_1_3__2 =
                      tmp_qloop_0__2 *
                      tabulated_and_untitled_0_0__2[6LL + 10LL * q__2];
                  const double q_tmp_2_2__2 =
                      tmp_qloop_0__2 *
                      tabulated_and_untitled_0_0__2[7LL + 10LL * q__2];
                  const double q_tmp_2_3__2 =
                      tmp_qloop_0__2 *
                      tabulated_and_untitled_0_0__2[8LL + 10LL * q__2];
                  const double q_tmp_3_3__2 =
                      tmp_qloop_0__2 *
                      tabulated_and_untitled_0_0__2[9LL + 10LL * q__2];
                  q_acc_0_0__2 = q_acc_0_0__2 + q_tmp_0_0__2;
                  q_acc_0_1__2 = q_acc_0_1__2 + q_tmp_0_1__2;
                  q_acc_0_2__2 = q_acc_0_2__2 + q_tmp_0_2__2;
                  q_acc_0_3__2 = q_acc_0_3__2 + q_tmp_0_3__2;
                  q_acc_1_1__2 = q_acc_1_1__2 + q_tmp_1_1__2;
                  q_acc_1_2__2 = q_acc_1_2__2 + q_tmp_1_2__2;
                  q_acc_1_3__2 = q_acc_1_3__2 + q_tmp_1_3__2;
                  q_acc_2_2__2 = q_acc_2_2__2 + q_tmp_2_2__2;
                  q_acc_2_3__2 = q_acc_2_3__2 + q_tmp_2_3__2;
                  q_acc_3_3__2 = q_acc_3_3__2 + q_tmp_3_3__2;
                }
                const double elMatVec_0__2 =
                    q_acc_0_0__2 * src_dof_0__2 + q_acc_0_1__2 * src_dof_1__2 +
                    q_acc_0_2__2 * src_dof_2__2 + q_acc_0_3__2 * src_dof_3__2;
                const double elMatVec_1__2 =
                    q_acc_0_1__2 * src_dof_0__2 + q_acc_1_1__2 * src_dof_1__2 +
                    q_acc_1_2__2 * src_dof_2__2 + q_acc_1_3__2 * src_dof_3__2;
                const double elMatVec_2__2 =
                    q_acc_0_2__2 * src_dof_0__2 + q_acc_1_2__2 * src_dof_1__2 +
                    q_acc_2_2__2 * src_dof_2__2 + q_acc_2_3__2 * src_dof_3__2;
                const double elMatVec_3__2 =
                    q_acc_0_3__2 * src_dof_0__2 + q_acc_1_3__2 * src_dof_1__2 +
                    q_acc_2_3__2 * src_dof_2__2 + q_acc_3_3__2 * src_dof_3__2;
                _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL + ctr_1) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) +
                          ctr_0__0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_0__2 +
                    _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                          (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_1__2 +
                    _data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                          (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_2__2 +
                    _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                          (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL + ctr_1) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) +
                          ctr_0__0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_3__2 +
                    _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
              }
            }
            {
              /* CellType.GREEN_UP */
              const double tmp_coords_jac_0__1 =
                  macro_vertex_coord_id_3comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_1__1 =
                  1.0 * (1.0 / micro_edges_per_macro_edge_float);
              const double tmp_coords_jac_2__1 = tmp_coords_jac_1__1 * 0.0;
              const double tmp_coords_jac_3__1 =
                  macro_vertex_coord_id_0comp0 +
                  tmp_coords_jac_0__1 * tmp_coords_jac_2__1;
              const double tmp_coords_jac_4__1 =
                  macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_5__1 = tmp_coords_jac_1__1 * 1.0;
              const double tmp_coords_jac_6__1 =
                  macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_7__1 =
                  tmp_coords_jac_2__1 * tmp_coords_jac_6__1;
              const double tmp_coords_jac_8__1 =
                  tmp_coords_jac_7__1 +
                  tmp_coords_jac_4__1 * tmp_coords_jac_5__1;
              const double tmp_coords_jac_9__1 =
                  macro_vertex_coord_id_3comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_10__1 =
                  macro_vertex_coord_id_0comp1 +
                  tmp_coords_jac_2__1 * tmp_coords_jac_9__1;
              const double tmp_coords_jac_11__1 =
                  macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_12__1 =
                  macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_13__1 =
                  tmp_coords_jac_12__1 * tmp_coords_jac_2__1;
              const double tmp_coords_jac_14__1 =
                  tmp_coords_jac_13__1 +
                  tmp_coords_jac_11__1 * tmp_coords_jac_5__1;
              const double tmp_coords_jac_15__1 =
                  macro_vertex_coord_id_3comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_16__1 =
                  macro_vertex_coord_id_0comp2 +
                  tmp_coords_jac_15__1 * tmp_coords_jac_2__1;
              const double tmp_coords_jac_17__1 =
                  macro_vertex_coord_id_1comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_18__1 =
                  macro_vertex_coord_id_2comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_19__1 =
                  tmp_coords_jac_18__1 * tmp_coords_jac_2__1;
              const double tmp_coords_jac_20__1 =
                  tmp_coords_jac_19__1 +
                  tmp_coords_jac_17__1 * tmp_coords_jac_5__1;
              const double tmp_coords_jac_21__1 =
                  tmp_coords_jac_2__1 * tmp_coords_jac_4__1;
              const double tmp_coords_jac_22__1 =
                  tmp_coords_jac_11__1 * tmp_coords_jac_2__1;
              const double tmp_coords_jac_23__1 =
                  tmp_coords_jac_17__1 * tmp_coords_jac_2__1;
              const double tmp_coords_jac_24__1 =
                  macro_vertex_coord_id_0comp0 +
                  tmp_coords_jac_0__1 * tmp_coords_jac_5__1;
              const double tmp_coords_jac_25__1 =
                  macro_vertex_coord_id_0comp1 +
                  tmp_coords_jac_5__1 * tmp_coords_jac_9__1;
              const double tmp_coords_jac_26__1 =
                  macro_vertex_coord_id_0comp2 +
                  tmp_coords_jac_15__1 * tmp_coords_jac_5__1;
              const double p_affine_const_0_0__1 =
                  tmp_coords_jac_3__1 + tmp_coords_jac_8__1;
              const double p_affine_const_0_1__1 =
                  tmp_coords_jac_10__1 + tmp_coords_jac_14__1;
              const double p_affine_const_0_2__1 =
                  tmp_coords_jac_16__1 + tmp_coords_jac_20__1;
              const double p_affine_const_1_0__1 =
                  tmp_coords_jac_21__1 + tmp_coords_jac_3__1 +
                  tmp_coords_jac_5__1 * tmp_coords_jac_6__1;
              const double p_affine_const_1_1__1 =
                  tmp_coords_jac_10__1 + tmp_coords_jac_22__1 +
                  tmp_coords_jac_12__1 * tmp_coords_jac_5__1;
              const double p_affine_const_1_2__1 =
                  tmp_coords_jac_16__1 + tmp_coords_jac_23__1 +
                  tmp_coords_jac_18__1 * tmp_coords_jac_5__1;
              const double p_affine_const_2_0__1 = tmp_coords_jac_21__1 +
                                                   tmp_coords_jac_24__1 +
                                                   tmp_coords_jac_7__1;
              const double p_affine_const_2_1__1 = tmp_coords_jac_13__1 +
                                                   tmp_coords_jac_22__1 +
                                                   tmp_coords_jac_25__1;
              const double p_affine_const_2_2__1 = tmp_coords_jac_19__1 +
                                                   tmp_coords_jac_23__1 +
                                                   tmp_coords_jac_26__1;
              const double p_affine_const_3_0__1 =
                  tmp_coords_jac_24__1 + tmp_coords_jac_8__1;
              const double p_affine_const_3_1__1 =
                  tmp_coords_jac_14__1 + tmp_coords_jac_25__1;
              const double p_affine_const_3_2__1 =
                  tmp_coords_jac_20__1 + tmp_coords_jac_26__1;
              const double jac_affine_0_0__1 =
                  p_affine_const_1_0__1 - p_affine_const_0_0__1;
              const double jac_affine_0_1__1 =
                  p_affine_const_2_0__1 - p_affine_const_0_0__1;
              const double jac_affine_0_2__1 =
                  p_affine_const_3_0__1 - p_affine_const_0_0__1;
              const double jac_affine_1_0__1 =
                  p_affine_const_1_1__1 - p_affine_const_0_1__1;
              const double jac_affine_1_1__1 =
                  p_affine_const_2_1__1 - p_affine_const_0_1__1;
              const double tmp_coords_jac_31__1 =
                  jac_affine_0_2__1 * jac_affine_1_1__1;
              const double jac_affine_1_2__1 =
                  p_affine_const_3_1__1 - p_affine_const_0_1__1;
              const double tmp_coords_jac_29__1 =
                  jac_affine_0_1__1 * jac_affine_1_2__1;
              const double jac_affine_2_0__1 =
                  p_affine_const_1_2__1 - p_affine_const_0_2__1;
              const double jac_affine_2_1__1 =
                  p_affine_const_2_2__1 - p_affine_const_0_2__1;
              const double tmp_coords_jac_28__1 =
                  jac_affine_1_2__1 * jac_affine_2_1__1;
              const double jac_affine_2_2__1 =
                  p_affine_const_3_2__1 - p_affine_const_0_2__1;
              const double tmp_coords_jac_27__1 =
                  jac_affine_1_1__1 * jac_affine_2_2__1;
              const double tmp_coords_jac_30__1 =
                  jac_affine_0_1__1 * jac_affine_2_2__1;
              const double tmp_coords_jac_32__1 =
                  jac_affine_0_0__1 * tmp_coords_jac_27__1 +
                  jac_affine_2_0__1 * tmp_coords_jac_29__1 -
                  jac_affine_0_0__1 * tmp_coords_jac_28__1 -
                  jac_affine_1_0__1 * tmp_coords_jac_30__1 -
                  jac_affine_2_0__1 * tmp_coords_jac_31__1 +
                  jac_affine_0_2__1 * jac_affine_1_0__1 * jac_affine_2_1__1;
              const double tmp_coords_jac_33__1 = 1.0 / tmp_coords_jac_32__1;
              const double jac_affine_inv_0_0__1 =
                  tmp_coords_jac_33__1 *
                  (tmp_coords_jac_27__1 - tmp_coords_jac_28__1);
              const double jac_affine_inv_0_1__1 =
                  tmp_coords_jac_33__1 *
                  (-1.0 * tmp_coords_jac_30__1 +
                   jac_affine_0_2__1 * jac_affine_2_1__1);
              const double jac_affine_inv_0_2__1 =
                  tmp_coords_jac_33__1 *
                  (tmp_coords_jac_29__1 - tmp_coords_jac_31__1);
              const double jac_affine_inv_1_0__1 =
                  tmp_coords_jac_33__1 *
                  (jac_affine_1_2__1 * jac_affine_2_0__1 -
                   jac_affine_1_0__1 * jac_affine_2_2__1);
              const double jac_affine_inv_1_1__1 =
                  tmp_coords_jac_33__1 *
                  (jac_affine_0_0__1 * jac_affine_2_2__1 -
                   jac_affine_0_2__1 * jac_affine_2_0__1);
              const double jac_affine_inv_1_2__1 =
                  tmp_coords_jac_33__1 *
                  (jac_affine_0_2__1 * jac_affine_1_0__1 -
                   jac_affine_0_0__1 * jac_affine_1_2__1);
              const double jac_affine_inv_2_0__1 =
                  tmp_coords_jac_33__1 *
                  (jac_affine_1_0__1 * jac_affine_2_1__1 -
                   jac_affine_1_1__1 * jac_affine_2_0__1);
              const double jac_affine_inv_2_1__1 =
                  tmp_coords_jac_33__1 *
                  (jac_affine_0_1__1 * jac_affine_2_0__1 -
                   jac_affine_0_0__1 * jac_affine_2_1__1);
              const double jac_affine_inv_2_2__1 =
                  tmp_coords_jac_33__1 *
                  (jac_affine_0_0__1 * jac_affine_1_1__1 -
                   jac_affine_0_1__1 * jac_affine_1_0__1);
              const double abs_det_jac_affine__1 = abs(tmp_coords_jac_32__1);
              double phi_0_0__1[4] = {0.25, 0.25, 0.25, 0.25};
              double tabulated_and_untitled_0_0__1[10] = {
                  abs_det_jac_affine__1 *
                      ((-1.0 * jac_affine_inv_0_0__1 - jac_affine_inv_1_0__1 -
                        jac_affine_inv_2_0__1) *
                           (-1.0 * jac_affine_inv_0_0__1 -
                            jac_affine_inv_1_0__1 - jac_affine_inv_2_0__1) +
                       (-1.0 * jac_affine_inv_0_1__1 - jac_affine_inv_1_1__1 -
                        jac_affine_inv_2_1__1) *
                           (-1.0 * jac_affine_inv_0_1__1 -
                            jac_affine_inv_1_1__1 - jac_affine_inv_2_1__1) +
                       (-1.0 * jac_affine_inv_0_2__1 - jac_affine_inv_1_2__1 -
                        jac_affine_inv_2_2__1) *
                           (-1.0 * jac_affine_inv_0_2__1 -
                            jac_affine_inv_1_2__1 - jac_affine_inv_2_2__1)),
                  abs_det_jac_affine__1 *
                      (jac_affine_inv_0_0__1 *
                           (-1.0 * jac_affine_inv_0_0__1 -
                            jac_affine_inv_1_0__1 - jac_affine_inv_2_0__1) +
                       jac_affine_inv_0_1__1 *
                           (-1.0 * jac_affine_inv_0_1__1 -
                            jac_affine_inv_1_1__1 - jac_affine_inv_2_1__1) +
                       jac_affine_inv_0_2__1 *
                           (-1.0 * jac_affine_inv_0_2__1 -
                            jac_affine_inv_1_2__1 - jac_affine_inv_2_2__1)),
                  abs_det_jac_affine__1 *
                      (jac_affine_inv_1_0__1 *
                           (-1.0 * jac_affine_inv_0_0__1 -
                            jac_affine_inv_1_0__1 - jac_affine_inv_2_0__1) +
                       jac_affine_inv_1_1__1 *
                           (-1.0 * jac_affine_inv_0_1__1 -
                            jac_affine_inv_1_1__1 - jac_affine_inv_2_1__1) +
                       jac_affine_inv_1_2__1 *
                           (-1.0 * jac_affine_inv_0_2__1 -
                            jac_affine_inv_1_2__1 - jac_affine_inv_2_2__1)),
                  abs_det_jac_affine__1 *
                      (jac_affine_inv_2_0__1 *
                           (-1.0 * jac_affine_inv_0_0__1 -
                            jac_affine_inv_1_0__1 - jac_affine_inv_2_0__1) +
                       jac_affine_inv_2_1__1 *
                           (-1.0 * jac_affine_inv_0_1__1 -
                            jac_affine_inv_1_1__1 - jac_affine_inv_2_1__1) +
                       jac_affine_inv_2_2__1 *
                           (-1.0 * jac_affine_inv_0_2__1 -
                            jac_affine_inv_1_2__1 - jac_affine_inv_2_2__1)),
                  abs_det_jac_affine__1 *
                      (jac_affine_inv_0_0__1 * jac_affine_inv_0_0__1 +
                       jac_affine_inv_0_1__1 * jac_affine_inv_0_1__1 +
                       jac_affine_inv_0_2__1 * jac_affine_inv_0_2__1),
                  abs_det_jac_affine__1 *
                      (jac_affine_inv_0_0__1 * jac_affine_inv_1_0__1 +
                       jac_affine_inv_0_1__1 * jac_affine_inv_1_1__1 +
                       jac_affine_inv_0_2__1 * jac_affine_inv_1_2__1),
                  abs_det_jac_affine__1 *
                      (jac_affine_inv_0_0__1 * jac_affine_inv_2_0__1 +
                       jac_affine_inv_0_1__1 * jac_affine_inv_2_1__1 +
                       jac_affine_inv_0_2__1 * jac_affine_inv_2_2__1),
                  abs_det_jac_affine__1 *
                      (jac_affine_inv_1_0__1 * jac_affine_inv_1_0__1 +
                       jac_affine_inv_1_1__1 * jac_affine_inv_1_1__1 +
                       jac_affine_inv_1_2__1 * jac_affine_inv_1_2__1),
                  abs_det_jac_affine__1 *
                      (jac_affine_inv_1_0__1 * jac_affine_inv_2_0__1 +
                       jac_affine_inv_1_1__1 * jac_affine_inv_2_1__1 +
                       jac_affine_inv_1_2__1 * jac_affine_inv_2_2__1),
                  abs_det_jac_affine__1 *
                      (jac_affine_inv_2_0__1 * jac_affine_inv_2_0__1 +
                       jac_affine_inv_2_1__1 * jac_affine_inv_2_1__1 +
                       jac_affine_inv_2_2__1 * jac_affine_inv_2_2__1)};
              {
                const double p_affine_0_0__1 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_0_1__1 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_0_2__1 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_1_0__1 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_1_1__1 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_1_2__1 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_2_0__1 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_1__1 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_2__1 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_0__1 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_1__1 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_2__1 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double src_dof_0__1 =
                    _data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_1__1 =
                    _data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_2__1 =
                    _data_src[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_3__1 =
                    _data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_0__1 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_1__1 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_2__1 =
                    _data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_3__1 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                double q_acc_0_0__1 = 0.0;
                double q_acc_0_1__1 = 0.0;
                double q_acc_0_2__1 = 0.0;
                double q_acc_0_3__1 = 0.0;
                double q_acc_1_1__1 = 0.0;
                double q_acc_1_2__1 = 0.0;
                double q_acc_1_3__1 = 0.0;
                double q_acc_2_2__1 = 0.0;
                double q_acc_2_3__1 = 0.0;
                double q_acc_3_3__1 = 0.0;
                for (int64_t q__1 = 0LL; q__1 < 1LL; q__1 += 1LL) {
                  const double tmp_qloop_0__1 =
                      (k_dof_0__1 * phi_0_0__1[4LL * q__1] +
                       k_dof_1__1 * phi_0_0__1[1LL + 4LL * q__1] +
                       k_dof_2__1 * phi_0_0__1[2LL + 4LL * q__1] +
                       k_dof_3__1 * phi_0_0__1[3LL + 4LL * q__1]) *
                      q_w[q__1];
                  const double q_tmp_0_0__1 =
                      tmp_qloop_0__1 *
                      tabulated_and_untitled_0_0__1[10LL * q__1];
                  const double q_tmp_0_1__1 =
                      tmp_qloop_0__1 *
                      tabulated_and_untitled_0_0__1[1LL + 10LL * q__1];
                  const double q_tmp_0_2__1 =
                      tmp_qloop_0__1 *
                      tabulated_and_untitled_0_0__1[2LL + 10LL * q__1];
                  const double q_tmp_0_3__1 =
                      tmp_qloop_0__1 *
                      tabulated_and_untitled_0_0__1[3LL + 10LL * q__1];
                  const double q_tmp_1_1__1 =
                      tmp_qloop_0__1 *
                      tabulated_and_untitled_0_0__1[4LL + 10LL * q__1];
                  const double q_tmp_1_2__1 =
                      tmp_qloop_0__1 *
                      tabulated_and_untitled_0_0__1[5LL + 10LL * q__1];
                  const double q_tmp_1_3__1 =
                      tmp_qloop_0__1 *
                      tabulated_and_untitled_0_0__1[6LL + 10LL * q__1];
                  const double q_tmp_2_2__1 =
                      tmp_qloop_0__1 *
                      tabulated_and_untitled_0_0__1[7LL + 10LL * q__1];
                  const double q_tmp_2_3__1 =
                      tmp_qloop_0__1 *
                      tabulated_and_untitled_0_0__1[8LL + 10LL * q__1];
                  const double q_tmp_3_3__1 =
                      tmp_qloop_0__1 *
                      tabulated_and_untitled_0_0__1[9LL + 10LL * q__1];
                  q_acc_0_0__1 = q_acc_0_0__1 + q_tmp_0_0__1;
                  q_acc_0_1__1 = q_acc_0_1__1 + q_tmp_0_1__1;
                  q_acc_0_2__1 = q_acc_0_2__1 + q_tmp_0_2__1;
                  q_acc_0_3__1 = q_acc_0_3__1 + q_tmp_0_3__1;
                  q_acc_1_1__1 = q_acc_1_1__1 + q_tmp_1_1__1;
                  q_acc_1_2__1 = q_acc_1_2__1 + q_tmp_1_2__1;
                  q_acc_1_3__1 = q_acc_1_3__1 + q_tmp_1_3__1;
                  q_acc_2_2__1 = q_acc_2_2__1 + q_tmp_2_2__1;
                  q_acc_2_3__1 = q_acc_2_3__1 + q_tmp_2_3__1;
                  q_acc_3_3__1 = q_acc_3_3__1 + q_tmp_3_3__1;
                }
                const double elMatVec_0__1 =
                    q_acc_0_0__1 * src_dof_0__1 + q_acc_0_1__1 * src_dof_1__1 +
                    q_acc_0_2__1 * src_dof_2__1 + q_acc_0_3__1 * src_dof_3__1;
                const double elMatVec_1__1 =
                    q_acc_0_1__1 * src_dof_0__1 + q_acc_1_1__1 * src_dof_1__1 +
                    q_acc_1_2__1 * src_dof_2__1 + q_acc_1_3__1 * src_dof_3__1;
                const double elMatVec_2__1 =
                    q_acc_0_2__1 * src_dof_0__1 + q_acc_1_2__1 * src_dof_1__1 +
                    q_acc_2_2__1 * src_dof_2__1 + q_acc_2_3__1 * src_dof_3__1;
                const double elMatVec_3__1 =
                    q_acc_0_3__1 * src_dof_0__1 + q_acc_1_3__1 * src_dof_1__1 +
                    q_acc_2_3__1 * src_dof_2__1 + q_acc_3_3__1 * src_dof_3__1;
                _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_0__1 +
                    _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL + ctr_1) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) +
                          ctr_0__0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_1__1 +
                    _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                          (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_2__1 +
                    _data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                          (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_3__1 +
                    _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
              }
            }
            {
              /* CellType.GREEN_DOWN */
              const double tmp_coords_jac_0__0 =
                  macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_1__0 =
                  1.0 * (1.0 / micro_edges_per_macro_edge_float);
              const double tmp_coords_jac_2__0 = tmp_coords_jac_1__0 * 0.0;
              const double tmp_coords_jac_3__0 =
                  tmp_coords_jac_0__0 * tmp_coords_jac_2__0;
              const double tmp_coords_jac_4__0 =
                  macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_5__0 = tmp_coords_jac_1__0 * 1.0;
              const double tmp_coords_jac_6__0 =
                  tmp_coords_jac_4__0 * tmp_coords_jac_5__0;
              const double tmp_coords_jac_7__0 =
                  macro_vertex_coord_id_3comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_8__0 =
                  macro_vertex_coord_id_0comp0 + tmp_coords_jac_6__0 +
                  tmp_coords_jac_2__0 * tmp_coords_jac_7__0;
              const double tmp_coords_jac_9__0 =
                  macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_10__0 =
                  tmp_coords_jac_2__0 * tmp_coords_jac_9__0;
              const double tmp_coords_jac_11__0 =
                  macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_12__0 =
                  tmp_coords_jac_11__0 * tmp_coords_jac_5__0;
              const double tmp_coords_jac_13__0 =
                  macro_vertex_coord_id_3comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_14__0 =
                  macro_vertex_coord_id_0comp1 + tmp_coords_jac_12__0 +
                  tmp_coords_jac_13__0 * tmp_coords_jac_2__0;
              const double tmp_coords_jac_15__0 =
                  macro_vertex_coord_id_1comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_16__0 =
                  tmp_coords_jac_15__0 * tmp_coords_jac_2__0;
              const double tmp_coords_jac_17__0 =
                  macro_vertex_coord_id_2comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_18__0 =
                  tmp_coords_jac_17__0 * tmp_coords_jac_5__0;
              const double tmp_coords_jac_19__0 =
                  macro_vertex_coord_id_3comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_20__0 =
                  macro_vertex_coord_id_0comp2 + tmp_coords_jac_18__0 +
                  tmp_coords_jac_19__0 * tmp_coords_jac_2__0;
              const double tmp_coords_jac_21__0 =
                  tmp_coords_jac_0__0 * tmp_coords_jac_5__0;
              const double tmp_coords_jac_22__0 =
                  tmp_coords_jac_5__0 * tmp_coords_jac_9__0;
              const double tmp_coords_jac_23__0 =
                  tmp_coords_jac_15__0 * tmp_coords_jac_5__0;
              const double tmp_coords_jac_24__0 =
                  macro_vertex_coord_id_0comp0 +
                  tmp_coords_jac_5__0 * tmp_coords_jac_7__0;
              const double tmp_coords_jac_25__0 =
                  macro_vertex_coord_id_0comp1 +
                  tmp_coords_jac_13__0 * tmp_coords_jac_5__0;
              const double tmp_coords_jac_26__0 =
                  macro_vertex_coord_id_0comp2 +
                  tmp_coords_jac_19__0 * tmp_coords_jac_5__0;
              const double p_affine_const_0_0__0 =
                  tmp_coords_jac_3__0 + tmp_coords_jac_8__0;
              const double p_affine_const_0_1__0 =
                  tmp_coords_jac_10__0 + tmp_coords_jac_14__0;
              const double p_affine_const_0_2__0 =
                  tmp_coords_jac_16__0 + tmp_coords_jac_20__0;
              const double p_affine_const_1_0__0 =
                  tmp_coords_jac_21__0 + tmp_coords_jac_8__0;
              const double p_affine_const_1_1__0 =
                  tmp_coords_jac_14__0 + tmp_coords_jac_22__0;
              const double p_affine_const_1_2__0 =
                  tmp_coords_jac_20__0 + tmp_coords_jac_23__0;
              const double p_affine_const_2_0__0 =
                  tmp_coords_jac_21__0 + tmp_coords_jac_24__0 +
                  tmp_coords_jac_2__0 * tmp_coords_jac_4__0;
              const double p_affine_const_2_1__0 =
                  tmp_coords_jac_22__0 + tmp_coords_jac_25__0 +
                  tmp_coords_jac_11__0 * tmp_coords_jac_2__0;
              const double p_affine_const_2_2__0 =
                  tmp_coords_jac_23__0 + tmp_coords_jac_26__0 +
                  tmp_coords_jac_17__0 * tmp_coords_jac_2__0;
              const double p_affine_const_3_0__0 = tmp_coords_jac_24__0 +
                                                   tmp_coords_jac_3__0 +
                                                   tmp_coords_jac_6__0;
              const double p_affine_const_3_1__0 = tmp_coords_jac_10__0 +
                                                   tmp_coords_jac_12__0 +
                                                   tmp_coords_jac_25__0;
              const double p_affine_const_3_2__0 = tmp_coords_jac_16__0 +
                                                   tmp_coords_jac_18__0 +
                                                   tmp_coords_jac_26__0;
              const double jac_affine_0_0__0 =
                  p_affine_const_1_0__0 - p_affine_const_0_0__0;
              const double jac_affine_0_1__0 =
                  p_affine_const_2_0__0 - p_affine_const_0_0__0;
              const double jac_affine_0_2__0 =
                  p_affine_const_3_0__0 - p_affine_const_0_0__0;
              const double jac_affine_1_0__0 =
                  p_affine_const_1_1__0 - p_affine_const_0_1__0;
              const double jac_affine_1_1__0 =
                  p_affine_const_2_1__0 - p_affine_const_0_1__0;
              const double tmp_coords_jac_31__0 =
                  jac_affine_0_2__0 * jac_affine_1_1__0;
              const double jac_affine_1_2__0 =
                  p_affine_const_3_1__0 - p_affine_const_0_1__0;
              const double tmp_coords_jac_29__0 =
                  jac_affine_0_1__0 * jac_affine_1_2__0;
              const double jac_affine_2_0__0 =
                  p_affine_const_1_2__0 - p_affine_const_0_2__0;
              const double jac_affine_2_1__0 =
                  p_affine_const_2_2__0 - p_affine_const_0_2__0;
              const double tmp_coords_jac_28__0 =
                  jac_affine_1_2__0 * jac_affine_2_1__0;
              const double jac_affine_2_2__0 =
                  p_affine_const_3_2__0 - p_affine_const_0_2__0;
              const double tmp_coords_jac_27__0 =
                  jac_affine_1_1__0 * jac_affine_2_2__0;
              const double tmp_coords_jac_30__0 =
                  jac_affine_0_1__0 * jac_affine_2_2__0;
              const double tmp_coords_jac_32__0 =
                  jac_affine_0_0__0 * tmp_coords_jac_27__0 +
                  jac_affine_2_0__0 * tmp_coords_jac_29__0 -
                  jac_affine_0_0__0 * tmp_coords_jac_28__0 -
                  jac_affine_1_0__0 * tmp_coords_jac_30__0 -
                  jac_affine_2_0__0 * tmp_coords_jac_31__0 +
                  jac_affine_0_2__0 * jac_affine_1_0__0 * jac_affine_2_1__0;
              const double tmp_coords_jac_33__0 = 1.0 / tmp_coords_jac_32__0;
              const double jac_affine_inv_0_0__0 =
                  tmp_coords_jac_33__0 *
                  (tmp_coords_jac_27__0 - tmp_coords_jac_28__0);
              const double jac_affine_inv_0_1__0 =
                  tmp_coords_jac_33__0 *
                  (-1.0 * tmp_coords_jac_30__0 +
                   jac_affine_0_2__0 * jac_affine_2_1__0);
              const double jac_affine_inv_0_2__0 =
                  tmp_coords_jac_33__0 *
                  (tmp_coords_jac_29__0 - tmp_coords_jac_31__0);
              const double jac_affine_inv_1_0__0 =
                  tmp_coords_jac_33__0 *
                  (jac_affine_1_2__0 * jac_affine_2_0__0 -
                   jac_affine_1_0__0 * jac_affine_2_2__0);
              const double jac_affine_inv_1_1__0 =
                  tmp_coords_jac_33__0 *
                  (jac_affine_0_0__0 * jac_affine_2_2__0 -
                   jac_affine_0_2__0 * jac_affine_2_0__0);
              const double jac_affine_inv_1_2__0 =
                  tmp_coords_jac_33__0 *
                  (jac_affine_0_2__0 * jac_affine_1_0__0 -
                   jac_affine_0_0__0 * jac_affine_1_2__0);
              const double jac_affine_inv_2_0__0 =
                  tmp_coords_jac_33__0 *
                  (jac_affine_1_0__0 * jac_affine_2_1__0 -
                   jac_affine_1_1__0 * jac_affine_2_0__0);
              const double jac_affine_inv_2_1__0 =
                  tmp_coords_jac_33__0 *
                  (jac_affine_0_1__0 * jac_affine_2_0__0 -
                   jac_affine_0_0__0 * jac_affine_2_1__0);
              const double jac_affine_inv_2_2__0 =
                  tmp_coords_jac_33__0 *
                  (jac_affine_0_0__0 * jac_affine_1_1__0 -
                   jac_affine_0_1__0 * jac_affine_1_0__0);
              const double abs_det_jac_affine__0 = abs(tmp_coords_jac_32__0);
              double phi_0_0__0[4] = {0.25, 0.25, 0.25, 0.25};
              double tabulated_and_untitled_0_0__0[10] = {
                  abs_det_jac_affine__0 *
                      ((-1.0 * jac_affine_inv_0_0__0 - jac_affine_inv_1_0__0 -
                        jac_affine_inv_2_0__0) *
                           (-1.0 * jac_affine_inv_0_0__0 -
                            jac_affine_inv_1_0__0 - jac_affine_inv_2_0__0) +
                       (-1.0 * jac_affine_inv_0_1__0 - jac_affine_inv_1_1__0 -
                        jac_affine_inv_2_1__0) *
                           (-1.0 * jac_affine_inv_0_1__0 -
                            jac_affine_inv_1_1__0 - jac_affine_inv_2_1__0) +
                       (-1.0 * jac_affine_inv_0_2__0 - jac_affine_inv_1_2__0 -
                        jac_affine_inv_2_2__0) *
                           (-1.0 * jac_affine_inv_0_2__0 -
                            jac_affine_inv_1_2__0 - jac_affine_inv_2_2__0)),
                  abs_det_jac_affine__0 *
                      (jac_affine_inv_0_0__0 *
                           (-1.0 * jac_affine_inv_0_0__0 -
                            jac_affine_inv_1_0__0 - jac_affine_inv_2_0__0) +
                       jac_affine_inv_0_1__0 *
                           (-1.0 * jac_affine_inv_0_1__0 -
                            jac_affine_inv_1_1__0 - jac_affine_inv_2_1__0) +
                       jac_affine_inv_0_2__0 *
                           (-1.0 * jac_affine_inv_0_2__0 -
                            jac_affine_inv_1_2__0 - jac_affine_inv_2_2__0)),
                  abs_det_jac_affine__0 *
                      (jac_affine_inv_1_0__0 *
                           (-1.0 * jac_affine_inv_0_0__0 -
                            jac_affine_inv_1_0__0 - jac_affine_inv_2_0__0) +
                       jac_affine_inv_1_1__0 *
                           (-1.0 * jac_affine_inv_0_1__0 -
                            jac_affine_inv_1_1__0 - jac_affine_inv_2_1__0) +
                       jac_affine_inv_1_2__0 *
                           (-1.0 * jac_affine_inv_0_2__0 -
                            jac_affine_inv_1_2__0 - jac_affine_inv_2_2__0)),
                  abs_det_jac_affine__0 *
                      (jac_affine_inv_2_0__0 *
                           (-1.0 * jac_affine_inv_0_0__0 -
                            jac_affine_inv_1_0__0 - jac_affine_inv_2_0__0) +
                       jac_affine_inv_2_1__0 *
                           (-1.0 * jac_affine_inv_0_1__0 -
                            jac_affine_inv_1_1__0 - jac_affine_inv_2_1__0) +
                       jac_affine_inv_2_2__0 *
                           (-1.0 * jac_affine_inv_0_2__0 -
                            jac_affine_inv_1_2__0 - jac_affine_inv_2_2__0)),
                  abs_det_jac_affine__0 *
                      (jac_affine_inv_0_0__0 * jac_affine_inv_0_0__0 +
                       jac_affine_inv_0_1__0 * jac_affine_inv_0_1__0 +
                       jac_affine_inv_0_2__0 * jac_affine_inv_0_2__0),
                  abs_det_jac_affine__0 *
                      (jac_affine_inv_0_0__0 * jac_affine_inv_1_0__0 +
                       jac_affine_inv_0_1__0 * jac_affine_inv_1_1__0 +
                       jac_affine_inv_0_2__0 * jac_affine_inv_1_2__0),
                  abs_det_jac_affine__0 *
                      (jac_affine_inv_0_0__0 * jac_affine_inv_2_0__0 +
                       jac_affine_inv_0_1__0 * jac_affine_inv_2_1__0 +
                       jac_affine_inv_0_2__0 * jac_affine_inv_2_2__0),
                  abs_det_jac_affine__0 *
                      (jac_affine_inv_1_0__0 * jac_affine_inv_1_0__0 +
                       jac_affine_inv_1_1__0 * jac_affine_inv_1_1__0 +
                       jac_affine_inv_1_2__0 * jac_affine_inv_1_2__0),
                  abs_det_jac_affine__0 *
                      (jac_affine_inv_1_0__0 * jac_affine_inv_2_0__0 +
                       jac_affine_inv_1_1__0 * jac_affine_inv_2_1__0 +
                       jac_affine_inv_1_2__0 * jac_affine_inv_2_2__0),
                  abs_det_jac_affine__0 *
                      (jac_affine_inv_2_0__0 * jac_affine_inv_2_0__0 +
                       jac_affine_inv_2_1__0 * jac_affine_inv_2_1__0 +
                       jac_affine_inv_2_2__0 * jac_affine_inv_2_2__0)};
              {
                const double p_affine_0_0__0 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_0_1__0 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_0_2__0 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_1_0__0 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_1_1__0 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_1_2__0 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_2_0__0 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_1__0 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_2__0 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_0__0 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_1__0 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_2__0 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double src_dof_0__0 =
                    _data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_1__0 =
                    _data_src[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_2__0 =
                    _data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double src_dof_3__0 =
                    _data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_0__0 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_1__0 =
                    _data_k[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_2__0 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_3__0 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                double q_acc_0_0__0 = 0.0;
                double q_acc_0_1__0 = 0.0;
                double q_acc_0_2__0 = 0.0;
                double q_acc_0_3__0 = 0.0;
                double q_acc_1_1__0 = 0.0;
                double q_acc_1_2__0 = 0.0;
                double q_acc_1_3__0 = 0.0;
                double q_acc_2_2__0 = 0.0;
                double q_acc_2_3__0 = 0.0;
                double q_acc_3_3__0 = 0.0;
                for (int64_t q__0 = 0LL; q__0 < 1LL; q__0 += 1LL) {
                  const double tmp_qloop_0__0 =
                      (k_dof_0__0 * phi_0_0__0[4LL * q__0] +
                       k_dof_1__0 * phi_0_0__0[1LL + 4LL * q__0] +
                       k_dof_2__0 * phi_0_0__0[2LL + 4LL * q__0] +
                       k_dof_3__0 * phi_0_0__0[3LL + 4LL * q__0]) *
                      q_w[q__0];
                  const double q_tmp_0_0__0 =
                      tmp_qloop_0__0 *
                      tabulated_and_untitled_0_0__0[10LL * q__0];
                  const double q_tmp_0_1__0 =
                      tmp_qloop_0__0 *
                      tabulated_and_untitled_0_0__0[1LL + 10LL * q__0];
                  const double q_tmp_0_2__0 =
                      tmp_qloop_0__0 *
                      tabulated_and_untitled_0_0__0[2LL + 10LL * q__0];
                  const double q_tmp_0_3__0 =
                      tmp_qloop_0__0 *
                      tabulated_and_untitled_0_0__0[3LL + 10LL * q__0];
                  const double q_tmp_1_1__0 =
                      tmp_qloop_0__0 *
                      tabulated_and_untitled_0_0__0[4LL + 10LL * q__0];
                  const double q_tmp_1_2__0 =
                      tmp_qloop_0__0 *
                      tabulated_and_untitled_0_0__0[5LL + 10LL * q__0];
                  const double q_tmp_1_3__0 =
                      tmp_qloop_0__0 *
                      tabulated_and_untitled_0_0__0[6LL + 10LL * q__0];
                  const double q_tmp_2_2__0 =
                      tmp_qloop_0__0 *
                      tabulated_and_untitled_0_0__0[7LL + 10LL * q__0];
                  const double q_tmp_2_3__0 =
                      tmp_qloop_0__0 *
                      tabulated_and_untitled_0_0__0[8LL + 10LL * q__0];
                  const double q_tmp_3_3__0 =
                      tmp_qloop_0__0 *
                      tabulated_and_untitled_0_0__0[9LL + 10LL * q__0];
                  q_acc_0_0__0 = q_acc_0_0__0 + q_tmp_0_0__0;
                  q_acc_0_1__0 = q_acc_0_1__0 + q_tmp_0_1__0;
                  q_acc_0_2__0 = q_acc_0_2__0 + q_tmp_0_2__0;
                  q_acc_0_3__0 = q_acc_0_3__0 + q_tmp_0_3__0;
                  q_acc_1_1__0 = q_acc_1_1__0 + q_tmp_1_1__0;
                  q_acc_1_2__0 = q_acc_1_2__0 + q_tmp_1_2__0;
                  q_acc_1_3__0 = q_acc_1_3__0 + q_tmp_1_3__0;
                  q_acc_2_2__0 = q_acc_2_2__0 + q_tmp_2_2__0;
                  q_acc_2_3__0 = q_acc_2_3__0 + q_tmp_2_3__0;
                  q_acc_3_3__0 = q_acc_3_3__0 + q_tmp_3_3__0;
                }
                const double elMatVec_0__0 =
                    q_acc_0_0__0 * src_dof_0__0 + q_acc_0_1__0 * src_dof_1__0 +
                    q_acc_0_2__0 * src_dof_2__0 + q_acc_0_3__0 * src_dof_3__0;
                const double elMatVec_1__0 =
                    q_acc_0_1__0 * src_dof_0__0 + q_acc_1_1__0 * src_dof_1__0 +
                    q_acc_1_2__0 * src_dof_2__0 + q_acc_1_3__0 * src_dof_3__0;
                const double elMatVec_2__0 =
                    q_acc_0_2__0 * src_dof_0__0 + q_acc_1_2__0 * src_dof_1__0 +
                    q_acc_2_2__0 * src_dof_2__0 + q_acc_2_3__0 * src_dof_3__0;
                const double elMatVec_3__0 =
                    q_acc_0_3__0 * src_dof_0__0 + q_acc_1_3__0 * src_dof_1__0 +
                    q_acc_2_3__0 * src_dof_2__0 + q_acc_3_3__0 * src_dof_3__0;
                _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL + ctr_1) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) +
                          ctr_0__0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_0__0 +
                    _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL + ctr_1) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) +
                          ctr_0__0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_1__0 +
                    _data_dst[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                          (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_2__0 +
                    _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  ctr_1 +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                          (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL + ctr_1) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) +
                          ctr_0__0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatVec_3__0 +
                    _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                              (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                  (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                  6LL +
                              (1LL + ctr_1) *
                                  (1LL - ctr_2 + micro_edges_per_macro_edge) +
                              ctr_0__0 +
                              (1LL + micro_edges_per_macro_edge) *
                                  (2LL + micro_edges_per_macro_edge) *
                                  (3LL + micro_edges_per_macro_edge) / 6LL];
              }
            }
          }
        }
        {
          const int64_t ctr_0 =
              -1LL - ctr_1 - ctr_2 + micro_edges_per_macro_edge;
          {
            /* CellType.WHITE_UP */
            {
              const double p_affine_0_0 =
                  macro_vertex_coord_id_0comp0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_3comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_2;
              const double p_affine_0_1 =
                  macro_vertex_coord_id_0comp1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_3comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_2;
              const double p_affine_0_2 =
                  macro_vertex_coord_id_0comp2 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp2 -
                       macro_vertex_coord_id_0comp2) *
                      (double)ctr_0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp2 -
                       macro_vertex_coord_id_0comp2) *
                      (double)ctr_1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_3comp2 -
                       macro_vertex_coord_id_0comp2) *
                      (double)ctr_2;
              const double p_affine_1_0 =
                  macro_vertex_coord_id_0comp0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)(1LL + ctr_0) +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_3comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_2;
              const double p_affine_1_1 =
                  macro_vertex_coord_id_0comp1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)(1LL + ctr_0) +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_3comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_2;
              const double p_affine_1_2 =
                  macro_vertex_coord_id_0comp2 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp2 -
                       macro_vertex_coord_id_0comp2) *
                      (double)(1LL + ctr_0) +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp2 -
                       macro_vertex_coord_id_0comp2) *
                      (double)ctr_1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_3comp2 -
                       macro_vertex_coord_id_0comp2) *
                      (double)ctr_2;
              const double p_affine_2_0 =
                  macro_vertex_coord_id_0comp0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)(1LL + ctr_1) +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_3comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_2;
              const double p_affine_2_1 =
                  macro_vertex_coord_id_0comp1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)(1LL + ctr_1) +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_3comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_2;
              const double p_affine_2_2 =
                  macro_vertex_coord_id_0comp2 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp2 -
                       macro_vertex_coord_id_0comp2) *
                      (double)ctr_0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp2 -
                       macro_vertex_coord_id_0comp2) *
                      (double)(1LL + ctr_1) +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_3comp2 -
                       macro_vertex_coord_id_0comp2) *
                      (double)ctr_2;
              const double p_affine_3_0 =
                  macro_vertex_coord_id_0comp0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_3comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)(1LL + ctr_2);
              const double p_affine_3_1 =
                  macro_vertex_coord_id_0comp1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_3comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)(1LL + ctr_2);
              const double p_affine_3_2 =
                  macro_vertex_coord_id_0comp2 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp2 -
                       macro_vertex_coord_id_0comp2) *
                      (double)ctr_0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp2 -
                       macro_vertex_coord_id_0comp2) *
                      (double)ctr_1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_3comp2 -
                       macro_vertex_coord_id_0comp2) *
                      (double)(1LL + ctr_2);
              const double src_dof_0 =
                  _data_src[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
              const double src_dof_1 =
                  _data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
              const double src_dof_2 =
                  _data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
              const double src_dof_3 =
                  _data_src[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
              const double k_dof_0 =
                  _data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL];
              const double k_dof_1 =
                  _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL];
              const double k_dof_2 =
                  _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL + ctr_1) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) +
                          ctr_0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL];
              const double k_dof_3 =
                  _data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                          (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL];
              double q_acc_0_0 = 0.0;
              double q_acc_0_1 = 0.0;
              double q_acc_0_2 = 0.0;
              double q_acc_0_3 = 0.0;
              double q_acc_1_1 = 0.0;
              double q_acc_1_2 = 0.0;
              double q_acc_1_3 = 0.0;
              double q_acc_2_2 = 0.0;
              double q_acc_2_3 = 0.0;
              double q_acc_3_3 = 0.0;
              for (int64_t q = 0LL; q < 1LL; q += 1LL) {
                const double tmp_qloop_0 = (k_dof_0 * phi_0_0[4LL * q] +
                                            k_dof_1 * phi_0_0[1LL + 4LL * q] +
                                            k_dof_2 * phi_0_0[2LL + 4LL * q] +
                                            k_dof_3 * phi_0_0[3LL + 4LL * q]) *
                                           q_w[q];
                const double q_tmp_0_0 =
                    tmp_qloop_0 * tabulated_and_untitled_0_0[10LL * q];
                const double q_tmp_0_1 =
                    tmp_qloop_0 * tabulated_and_untitled_0_0[1LL + 10LL * q];
                const double q_tmp_0_2 =
                    tmp_qloop_0 * tabulated_and_untitled_0_0[2LL + 10LL * q];
                const double q_tmp_0_3 =
                    tmp_qloop_0 * tabulated_and_untitled_0_0[3LL + 10LL * q];
                const double q_tmp_1_1 =
                    tmp_qloop_0 * tabulated_and_untitled_0_0[4LL + 10LL * q];
                const double q_tmp_1_2 =
                    tmp_qloop_0 * tabulated_and_untitled_0_0[5LL + 10LL * q];
                const double q_tmp_1_3 =
                    tmp_qloop_0 * tabulated_and_untitled_0_0[6LL + 10LL * q];
                const double q_tmp_2_2 =
                    tmp_qloop_0 * tabulated_and_untitled_0_0[7LL + 10LL * q];
                const double q_tmp_2_3 =
                    tmp_qloop_0 * tabulated_and_untitled_0_0[8LL + 10LL * q];
                const double q_tmp_3_3 =
                    tmp_qloop_0 * tabulated_and_untitled_0_0[9LL + 10LL * q];
                q_acc_0_0 = q_acc_0_0 + q_tmp_0_0;
                q_acc_0_1 = q_acc_0_1 + q_tmp_0_1;
                q_acc_0_2 = q_acc_0_2 + q_tmp_0_2;
                q_acc_0_3 = q_acc_0_3 + q_tmp_0_3;
                q_acc_1_1 = q_acc_1_1 + q_tmp_1_1;
                q_acc_1_2 = q_acc_1_2 + q_tmp_1_2;
                q_acc_1_3 = q_acc_1_3 + q_tmp_1_3;
                q_acc_2_2 = q_acc_2_2 + q_tmp_2_2;
                q_acc_2_3 = q_acc_2_3 + q_tmp_2_3;
                q_acc_3_3 = q_acc_3_3 + q_tmp_3_3;
              }
              const double elMatVec_0 =
                  q_acc_0_0 * src_dof_0 + q_acc_0_1 * src_dof_1 +
                  q_acc_0_2 * src_dof_2 + q_acc_0_3 * src_dof_3;
              const double elMatVec_1 =
                  q_acc_0_1 * src_dof_0 + q_acc_1_1 * src_dof_1 +
                  q_acc_1_2 * src_dof_2 + q_acc_1_3 * src_dof_3;
              const double elMatVec_2 =
                  q_acc_0_2 * src_dof_0 + q_acc_1_2 * src_dof_1 +
                  q_acc_2_2 * src_dof_2 + q_acc_2_3 * src_dof_3;
              const double elMatVec_3 =
                  q_acc_0_3 * src_dof_0 + q_acc_1_3 * src_dof_1 +
                  q_acc_2_3 * src_dof_2 + q_acc_3_3 * src_dof_3;
              _data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                        (1LL - ctr_2 + micro_edges_per_macro_edge) *
                            (2LL - ctr_2 + micro_edges_per_macro_edge) *
                            (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                        (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                        ctr_0 +
                        (1LL + micro_edges_per_macro_edge) *
                            (2LL + micro_edges_per_macro_edge) *
                            (3LL + micro_edges_per_macro_edge) / 6LL] =
                  elMatVec_0 +
                  _data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
              _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                        (1LL - ctr_2 + micro_edges_per_macro_edge) *
                            (2LL - ctr_2 + micro_edges_per_macro_edge) *
                            (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                        (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                        ctr_0 +
                        (1LL + micro_edges_per_macro_edge) *
                            (2LL + micro_edges_per_macro_edge) *
                            (3LL + micro_edges_per_macro_edge) / 6LL] =
                  elMatVec_1 +
                  _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
              _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                        (1LL - ctr_2 + micro_edges_per_macro_edge) *
                            (2LL - ctr_2 + micro_edges_per_macro_edge) *
                            (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                        (1LL + ctr_1) *
                            (2LL - ctr_2 + micro_edges_per_macro_edge) +
                        ctr_0 +
                        (1LL + micro_edges_per_macro_edge) *
                            (2LL + micro_edges_per_macro_edge) *
                            (3LL + micro_edges_per_macro_edge) / 6LL] =
                  elMatVec_2 +
                  _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
              _data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                        (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                            (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                        (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                        ctr_0 +
                        (1LL + micro_edges_per_macro_edge) *
                            (2LL + micro_edges_per_macro_edge) *
                            (3LL + micro_edges_per_macro_edge) / 6LL] =
                  elMatVec_3 +
                  _data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
            }
          }
        }
      }
    }
  }
}
void P1ElementwiseDivKGrad_cubes_const_vect_fused_quadloops_tab::
    apply_P1ElementwiseDivKGrad_cubes_const_vect_fused_quadloops_tab_macro_2D(
        double *RESTRICT const _data_dst, double *RESTRICT const _data_k,
        double *RESTRICT const _data_src,
        const double macro_vertex_coord_id_0comp0,
        const double macro_vertex_coord_id_0comp1,
        const double macro_vertex_coord_id_1comp0,
        const double macro_vertex_coord_id_1comp1,
        const double macro_vertex_coord_id_2comp0,
        const double macro_vertex_coord_id_2comp1,
        const int64_t micro_edges_per_macro_edge,
        const double micro_edges_per_macro_edge_float) const {
  {
    double q_w[1] = {0.5};
    const double tmp_coords_jac_0__1 =
        macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_1__1 =
        1.0 * (1.0 / micro_edges_per_macro_edge_float);
    const double tmp_coords_jac_2__1 = tmp_coords_jac_1__1 * 0.0;
    const double tmp_coords_jac_3__1 =
        tmp_coords_jac_0__1 * tmp_coords_jac_2__1;
    const double tmp_coords_jac_4__1 =
        macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_5__1 =
        macro_vertex_coord_id_0comp0 +
        tmp_coords_jac_2__1 * tmp_coords_jac_4__1;
    const double tmp_coords_jac_6__1 =
        macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_7__1 =
        tmp_coords_jac_2__1 * tmp_coords_jac_6__1;
    const double tmp_coords_jac_8__1 =
        macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_9__1 =
        macro_vertex_coord_id_0comp1 +
        tmp_coords_jac_2__1 * tmp_coords_jac_8__1;
    const double tmp_coords_jac_10__1 = tmp_coords_jac_1__1 * 1.0;
    const double p_affine_const_0_0__1 =
        tmp_coords_jac_3__1 + tmp_coords_jac_5__1;
    const double p_affine_const_0_1__1 =
        tmp_coords_jac_7__1 + tmp_coords_jac_9__1;
    const double p_affine_const_1_0__1 =
        tmp_coords_jac_5__1 + tmp_coords_jac_0__1 * tmp_coords_jac_10__1;
    const double p_affine_const_1_1__1 =
        tmp_coords_jac_9__1 + tmp_coords_jac_10__1 * tmp_coords_jac_6__1;
    const double p_affine_const_2_0__1 =
        macro_vertex_coord_id_0comp0 + tmp_coords_jac_3__1 +
        tmp_coords_jac_10__1 * tmp_coords_jac_4__1;
    const double p_affine_const_2_1__1 =
        macro_vertex_coord_id_0comp1 + tmp_coords_jac_7__1 +
        tmp_coords_jac_10__1 * tmp_coords_jac_8__1;
    const double jac_affine_0_0__1 =
        p_affine_const_1_0__1 - p_affine_const_0_0__1;
    const double jac_affine_0_1__1 =
        p_affine_const_2_0__1 - p_affine_const_0_0__1;
    const double jac_affine_1_0__1 =
        p_affine_const_1_1__1 - p_affine_const_0_1__1;
    const double jac_affine_1_1__1 =
        p_affine_const_2_1__1 - p_affine_const_0_1__1;
    const double tmp_coords_jac_11__1 = jac_affine_0_0__1 * jac_affine_1_1__1 -
                                        jac_affine_0_1__1 * jac_affine_1_0__1;
    const double tmp_coords_jac_12__1 = 1.0 / tmp_coords_jac_11__1;
    const double jac_affine_inv_0_0__1 =
        jac_affine_1_1__1 * tmp_coords_jac_12__1;
    const double jac_affine_inv_0_1__1 =
        -1.0 * jac_affine_0_1__1 * tmp_coords_jac_12__1;
    const double jac_affine_inv_1_0__1 =
        -1.0 * jac_affine_1_0__1 * tmp_coords_jac_12__1;
    const double jac_affine_inv_1_1__1 =
        jac_affine_0_0__1 * tmp_coords_jac_12__1;
    const double abs_det_jac_affine__1 = abs(tmp_coords_jac_11__1);
    double phi_0_0__1[3] = {0.3333333333333334, 0.3333333333333333,
                            0.3333333333333333};
    double tabulated_and_untitled_0_0__1[6] = {
        abs_det_jac_affine__1 *
            ((-1.0 * jac_affine_inv_0_0__1 - jac_affine_inv_1_0__1) *
                 (-1.0 * jac_affine_inv_0_0__1 - jac_affine_inv_1_0__1) +
             (-1.0 * jac_affine_inv_0_1__1 - jac_affine_inv_1_1__1) *
                 (-1.0 * jac_affine_inv_0_1__1 - jac_affine_inv_1_1__1)),
        abs_det_jac_affine__1 *
            (jac_affine_inv_0_0__1 *
                 (-1.0 * jac_affine_inv_0_0__1 - jac_affine_inv_1_0__1) +
             jac_affine_inv_0_1__1 *
                 (-1.0 * jac_affine_inv_0_1__1 - jac_affine_inv_1_1__1)),
        abs_det_jac_affine__1 *
            (jac_affine_inv_1_0__1 *
                 (-1.0 * jac_affine_inv_0_0__1 - jac_affine_inv_1_0__1) +
             jac_affine_inv_1_1__1 *
                 (-1.0 * jac_affine_inv_0_1__1 - jac_affine_inv_1_1__1)),
        abs_det_jac_affine__1 * (jac_affine_inv_0_0__1 * jac_affine_inv_0_0__1 +
                                 jac_affine_inv_0_1__1 * jac_affine_inv_0_1__1),
        abs_det_jac_affine__1 * (jac_affine_inv_0_0__1 * jac_affine_inv_1_0__1 +
                                 jac_affine_inv_0_1__1 * jac_affine_inv_1_1__1),
        abs_det_jac_affine__1 *
            (jac_affine_inv_1_0__1 * jac_affine_inv_1_0__1 +
             jac_affine_inv_1_1__1 * jac_affine_inv_1_1__1)};
    const double tmp_coords_jac_0__0 =
        macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_1__0 =
        1.0 * (1.0 / micro_edges_per_macro_edge_float);
    const double tmp_coords_jac_2__0 = tmp_coords_jac_1__0 * 0.0;
    const double tmp_coords_jac_3__0 =
        macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_4__0 = tmp_coords_jac_1__0 * 1.0;
    const double tmp_coords_jac_5__0 =
        macro_vertex_coord_id_0comp0 +
        tmp_coords_jac_3__0 * tmp_coords_jac_4__0;
    const double tmp_coords_jac_6__0 =
        macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_7__0 =
        macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_8__0 =
        macro_vertex_coord_id_0comp1 +
        tmp_coords_jac_4__0 * tmp_coords_jac_7__0;
    const double tmp_coords_jac_9__0 =
        tmp_coords_jac_0__0 * tmp_coords_jac_4__0;
    const double tmp_coords_jac_10__0 =
        tmp_coords_jac_4__0 * tmp_coords_jac_6__0;
    const double p_affine_const_0_0__0 =
        tmp_coords_jac_5__0 + tmp_coords_jac_0__0 * tmp_coords_jac_2__0;
    const double p_affine_const_0_1__0 =
        tmp_coords_jac_8__0 + tmp_coords_jac_2__0 * tmp_coords_jac_6__0;
    const double p_affine_const_1_0__0 =
        macro_vertex_coord_id_0comp0 + tmp_coords_jac_9__0 +
        tmp_coords_jac_2__0 * tmp_coords_jac_3__0;
    const double p_affine_const_1_1__0 =
        macro_vertex_coord_id_0comp1 + tmp_coords_jac_10__0 +
        tmp_coords_jac_2__0 * tmp_coords_jac_7__0;
    const double p_affine_const_2_0__0 =
        tmp_coords_jac_5__0 + tmp_coords_jac_9__0;
    const double p_affine_const_2_1__0 =
        tmp_coords_jac_10__0 + tmp_coords_jac_8__0;
    const double jac_affine_0_0__0 =
        p_affine_const_1_0__0 - p_affine_const_0_0__0;
    const double jac_affine_0_1__0 =
        p_affine_const_2_0__0 - p_affine_const_0_0__0;
    const double jac_affine_1_0__0 =
        p_affine_const_1_1__0 - p_affine_const_0_1__0;
    const double jac_affine_1_1__0 =
        p_affine_const_2_1__0 - p_affine_const_0_1__0;
    const double tmp_coords_jac_11__0 = jac_affine_0_0__0 * jac_affine_1_1__0 -
                                        jac_affine_0_1__0 * jac_affine_1_0__0;
    const double tmp_coords_jac_12__0 = 1.0 / tmp_coords_jac_11__0;
    const double jac_affine_inv_0_0__0 =
        jac_affine_1_1__0 * tmp_coords_jac_12__0;
    const double jac_affine_inv_0_1__0 =
        -1.0 * jac_affine_0_1__0 * tmp_coords_jac_12__0;
    const double jac_affine_inv_1_0__0 =
        -1.0 * jac_affine_1_0__0 * tmp_coords_jac_12__0;
    const double jac_affine_inv_1_1__0 =
        jac_affine_0_0__0 * tmp_coords_jac_12__0;
    const double abs_det_jac_affine__0 = abs(tmp_coords_jac_11__0);
    double phi_0_0__0[3] = {0.3333333333333334, 0.3333333333333333,
                            0.3333333333333333};
    double tabulated_and_untitled_0_0__0[6] = {
        abs_det_jac_affine__0 *
            ((-1.0 * jac_affine_inv_0_0__0 - jac_affine_inv_1_0__0) *
                 (-1.0 * jac_affine_inv_0_0__0 - jac_affine_inv_1_0__0) +
             (-1.0 * jac_affine_inv_0_1__0 - jac_affine_inv_1_1__0) *
                 (-1.0 * jac_affine_inv_0_1__0 - jac_affine_inv_1_1__0)),
        abs_det_jac_affine__0 *
            (jac_affine_inv_0_0__0 *
                 (-1.0 * jac_affine_inv_0_0__0 - jac_affine_inv_1_0__0) +
             jac_affine_inv_0_1__0 *
                 (-1.0 * jac_affine_inv_0_1__0 - jac_affine_inv_1_1__0)),
        abs_det_jac_affine__0 *
            (jac_affine_inv_1_0__0 *
                 (-1.0 * jac_affine_inv_0_0__0 - jac_affine_inv_1_0__0) +
             jac_affine_inv_1_1__0 *
                 (-1.0 * jac_affine_inv_0_1__0 - jac_affine_inv_1_1__0)),
        abs_det_jac_affine__0 * (jac_affine_inv_0_0__0 * jac_affine_inv_0_0__0 +
                                 jac_affine_inv_0_1__0 * jac_affine_inv_0_1__0),
        abs_det_jac_affine__0 * (jac_affine_inv_0_0__0 * jac_affine_inv_1_0__0 +
                                 jac_affine_inv_0_1__0 * jac_affine_inv_1_1__0),
        abs_det_jac_affine__0 *
            (jac_affine_inv_1_0__0 * jac_affine_inv_1_0__0 +
             jac_affine_inv_1_1__0 * jac_affine_inv_1_1__0)};
    const double tmp_coords_jac_0 =
        macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_1 =
        1.0 * (1.0 / micro_edges_per_macro_edge_float);
    const double tmp_coords_jac_2 = tmp_coords_jac_1 * 0.0;
    const double tmp_coords_jac_3 = tmp_coords_jac_0 * tmp_coords_jac_2;
    const double tmp_coords_jac_4 =
        macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_5 =
        macro_vertex_coord_id_0comp0 + tmp_coords_jac_2 * tmp_coords_jac_4;
    const double tmp_coords_jac_6 =
        macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_7 = tmp_coords_jac_2 * tmp_coords_jac_6;
    const double tmp_coords_jac_8 =
        macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_9 =
        macro_vertex_coord_id_0comp1 + tmp_coords_jac_2 * tmp_coords_jac_8;
    const double tmp_coords_jac_10 = tmp_coords_jac_1 * 1.0;
    const double p_affine_const_0_0 = tmp_coords_jac_3 + tmp_coords_jac_5;
    const double p_affine_const_0_1 = tmp_coords_jac_7 + tmp_coords_jac_9;
    const double p_affine_const_1_0 =
        tmp_coords_jac_5 + tmp_coords_jac_0 * tmp_coords_jac_10;
    const double p_affine_const_1_1 =
        tmp_coords_jac_9 + tmp_coords_jac_10 * tmp_coords_jac_6;
    const double p_affine_const_2_0 = macro_vertex_coord_id_0comp0 +
                                      tmp_coords_jac_3 +
                                      tmp_coords_jac_10 * tmp_coords_jac_4;
    const double p_affine_const_2_1 = macro_vertex_coord_id_0comp1 +
                                      tmp_coords_jac_7 +
                                      tmp_coords_jac_10 * tmp_coords_jac_8;
    const double jac_affine_0_0 = p_affine_const_1_0 - p_affine_const_0_0;
    const double jac_affine_0_1 = p_affine_const_2_0 - p_affine_const_0_0;
    const double jac_affine_1_0 = p_affine_const_1_1 - p_affine_const_0_1;
    const double jac_affine_1_1 = p_affine_const_2_1 - p_affine_const_0_1;
    const double tmp_coords_jac_11 =
        jac_affine_0_0 * jac_affine_1_1 - jac_affine_0_1 * jac_affine_1_0;
    const double tmp_coords_jac_12 = 1.0 / tmp_coords_jac_11;
    const double jac_affine_inv_0_0 = jac_affine_1_1 * tmp_coords_jac_12;
    const double jac_affine_inv_0_1 = -1.0 * jac_affine_0_1 * tmp_coords_jac_12;
    const double jac_affine_inv_1_0 = -1.0 * jac_affine_1_0 * tmp_coords_jac_12;
    const double jac_affine_inv_1_1 = jac_affine_0_0 * tmp_coords_jac_12;
    const double abs_det_jac_affine = abs(tmp_coords_jac_11);
    double phi_0_0[3] = {0.3333333333333334, 0.3333333333333333,
                         0.3333333333333333};
    double tabulated_and_untitled_0_0[6] = {
        abs_det_jac_affine *
            ((-1.0 * jac_affine_inv_0_0 - jac_affine_inv_1_0) *
                 (-1.0 * jac_affine_inv_0_0 - jac_affine_inv_1_0) +
             (-1.0 * jac_affine_inv_0_1 - jac_affine_inv_1_1) *
                 (-1.0 * jac_affine_inv_0_1 - jac_affine_inv_1_1)),
        abs_det_jac_affine * (jac_affine_inv_0_0 * (-1.0 * jac_affine_inv_0_0 -
                                                    jac_affine_inv_1_0) +
                              jac_affine_inv_0_1 * (-1.0 * jac_affine_inv_0_1 -
                                                    jac_affine_inv_1_1)),
        abs_det_jac_affine * (jac_affine_inv_1_0 * (-1.0 * jac_affine_inv_0_0 -
                                                    jac_affine_inv_1_0) +
                              jac_affine_inv_1_1 * (-1.0 * jac_affine_inv_0_1 -
                                                    jac_affine_inv_1_1)),
        abs_det_jac_affine * (jac_affine_inv_0_0 * jac_affine_inv_0_0 +
                              jac_affine_inv_0_1 * jac_affine_inv_0_1),
        abs_det_jac_affine * (jac_affine_inv_0_0 * jac_affine_inv_1_0 +
                              jac_affine_inv_0_1 * jac_affine_inv_1_1),
        abs_det_jac_affine * (jac_affine_inv_1_0 * jac_affine_inv_1_0 +
                              jac_affine_inv_1_1 * jac_affine_inv_1_1)};
    for (int64_t ctr_1 = 0LL; ctr_1 < micro_edges_per_macro_edge;
         ctr_1 += 1LL) {
      {
        const int64_t __ctr_0__0_simd_stop =
            -1LL - ctr_1 + micro_edges_per_macro_edge - 3LL;
        const int64_t __ctr_0__0_simd_step = 4LL;
        for (int64_t ctr_0__0 = 0LL; ctr_0__0 < __ctr_0__0_simd_stop;
             ctr_0__0 += __ctr_0__0_simd_step) {
          const __m256i ctr_0__3 =
              _mm256_add_epi64(_mm256_set1_epi64x(ctr_0__0),
                               _mm256_set_epi64x(3LL, 2LL, 1LL, 0LL));
          {
            /* FaceType.GRAY */
            {
              const __m256d p_affine_0_0__4 = _mm256_add_pd(
                  _mm256_add_pd(
                      _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_mul_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_div_pd(
                                      _mm256_set1_pd(1.0),
                                      _mm256_set1_pd(
                                          micro_edges_per_macro_edge_float))),
                              _mm256_sub_pd(
                                  _mm256_set1_pd(macro_vertex_coord_id_1comp0),
                                  _mm256_set1_pd(
                                      macro_vertex_coord_id_0comp0))),
                          __builtin_convertvector(
                              ctr_0__3,
                              double __attribute__((__vector_size__(32)))))),
                  _mm256_mul_pd(
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_set1_pd(1.0),
                              _mm256_div_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_set1_pd(
                                      micro_edges_per_macro_edge_float))),
                          _mm256_sub_pd(
                              _mm256_set1_pd(macro_vertex_coord_id_2comp0),
                              _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                      __builtin_convertvector(
                          _mm256_set1_epi64x(ctr_1),
                          double __attribute__((__vector_size__(32))))));
              const __m256d p_affine_0_1__4 = _mm256_add_pd(
                  _mm256_add_pd(
                      _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_mul_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_div_pd(
                                      _mm256_set1_pd(1.0),
                                      _mm256_set1_pd(
                                          micro_edges_per_macro_edge_float))),
                              _mm256_sub_pd(
                                  _mm256_set1_pd(macro_vertex_coord_id_1comp1),
                                  _mm256_set1_pd(
                                      macro_vertex_coord_id_0comp1))),
                          __builtin_convertvector(
                              ctr_0__3,
                              double __attribute__((__vector_size__(32)))))),
                  _mm256_mul_pd(
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_set1_pd(1.0),
                              _mm256_div_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_set1_pd(
                                      micro_edges_per_macro_edge_float))),
                          _mm256_sub_pd(
                              _mm256_set1_pd(macro_vertex_coord_id_2comp1),
                              _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                      __builtin_convertvector(
                          _mm256_set1_epi64x(ctr_1),
                          double __attribute__((__vector_size__(32))))));
              const __m256d p_affine_1_0__4 = _mm256_add_pd(
                  _mm256_add_pd(
                      _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_mul_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_div_pd(
                                      _mm256_set1_pd(1.0),
                                      _mm256_set1_pd(
                                          micro_edges_per_macro_edge_float))),
                              _mm256_sub_pd(
                                  _mm256_set1_pd(macro_vertex_coord_id_1comp0),
                                  _mm256_set1_pd(
                                      macro_vertex_coord_id_0comp0))),
                          __builtin_convertvector(
                              _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                               ctr_0__3),
                              double __attribute__((__vector_size__(32)))))),
                  _mm256_mul_pd(
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_set1_pd(1.0),
                              _mm256_div_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_set1_pd(
                                      micro_edges_per_macro_edge_float))),
                          _mm256_sub_pd(
                              _mm256_set1_pd(macro_vertex_coord_id_2comp0),
                              _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                      __builtin_convertvector(
                          _mm256_set1_epi64x(ctr_1),
                          double __attribute__((__vector_size__(32))))));
              const __m256d p_affine_1_1__4 = _mm256_add_pd(
                  _mm256_add_pd(
                      _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_mul_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_div_pd(
                                      _mm256_set1_pd(1.0),
                                      _mm256_set1_pd(
                                          micro_edges_per_macro_edge_float))),
                              _mm256_sub_pd(
                                  _mm256_set1_pd(macro_vertex_coord_id_1comp1),
                                  _mm256_set1_pd(
                                      macro_vertex_coord_id_0comp1))),
                          __builtin_convertvector(
                              _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                               ctr_0__3),
                              double __attribute__((__vector_size__(32)))))),
                  _mm256_mul_pd(
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_set1_pd(1.0),
                              _mm256_div_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_set1_pd(
                                      micro_edges_per_macro_edge_float))),
                          _mm256_sub_pd(
                              _mm256_set1_pd(macro_vertex_coord_id_2comp1),
                              _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                      __builtin_convertvector(
                          _mm256_set1_epi64x(ctr_1),
                          double __attribute__((__vector_size__(32))))));
              const __m256d p_affine_2_0__4 = _mm256_add_pd(
                  _mm256_add_pd(
                      _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_mul_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_div_pd(
                                      _mm256_set1_pd(1.0),
                                      _mm256_set1_pd(
                                          micro_edges_per_macro_edge_float))),
                              _mm256_sub_pd(
                                  _mm256_set1_pd(macro_vertex_coord_id_1comp0),
                                  _mm256_set1_pd(
                                      macro_vertex_coord_id_0comp0))),
                          __builtin_convertvector(
                              ctr_0__3,
                              double __attribute__((__vector_size__(32)))))),
                  _mm256_mul_pd(
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_set1_pd(1.0),
                              _mm256_div_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_set1_pd(
                                      micro_edges_per_macro_edge_float))),
                          _mm256_sub_pd(
                              _mm256_set1_pd(macro_vertex_coord_id_2comp0),
                              _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                      __builtin_convertvector(
                          _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                           _mm256_set1_epi64x(ctr_1)),
                          double __attribute__((__vector_size__(32))))));
              const __m256d p_affine_2_1__4 = _mm256_add_pd(
                  _mm256_add_pd(
                      _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_mul_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_div_pd(
                                      _mm256_set1_pd(1.0),
                                      _mm256_set1_pd(
                                          micro_edges_per_macro_edge_float))),
                              _mm256_sub_pd(
                                  _mm256_set1_pd(macro_vertex_coord_id_1comp1),
                                  _mm256_set1_pd(
                                      macro_vertex_coord_id_0comp1))),
                          __builtin_convertvector(
                              ctr_0__3,
                              double __attribute__((__vector_size__(32)))))),
                  _mm256_mul_pd(
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_set1_pd(1.0),
                              _mm256_div_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_set1_pd(
                                      micro_edges_per_macro_edge_float))),
                          _mm256_sub_pd(
                              _mm256_set1_pd(macro_vertex_coord_id_2comp1),
                              _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                      __builtin_convertvector(
                          _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                           _mm256_set1_epi64x(ctr_1)),
                          double __attribute__((__vector_size__(32))))));
              const __m256d src_dof_0__4 = _mm256_loadu_pd(
                  &_data_src[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) +
                             (2LL + micro_edges_per_macro_edge) * ctr_1 +
                             ctr_0__0]);
              const __m256d src_dof_1__4 = _mm256_loadu_pd(
                  &_data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                             (2LL + micro_edges_per_macro_edge) * ctr_1 +
                             ctr_0__0]);
              const __m256d src_dof_2__4 = _mm256_loadu_pd(
                  &_data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                             (1LL + ctr_1) *
                                 (2LL + micro_edges_per_macro_edge) +
                             ctr_0__0]);
              const __m256d k_dof_0__4 = _mm256_loadu_pd(
                  &_data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) +
                           (2LL + micro_edges_per_macro_edge) * ctr_1 +
                           ctr_0__0]);
              const __m256d k_dof_1__4 = _mm256_loadu_pd(
                  &_data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                           (2LL + micro_edges_per_macro_edge) * ctr_1 +
                           ctr_0__0]);
              const __m256d k_dof_2__4 = _mm256_loadu_pd(
                  &_data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                           (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                           ctr_0__0]);
              __m256d q_acc_0_0__4 = _mm256_set1_pd(0.0);
              __m256d q_acc_0_1__4 = _mm256_set1_pd(0.0);
              __m256d q_acc_0_2__4 = _mm256_set1_pd(0.0);
              __m256d q_acc_1_1__4 = _mm256_set1_pd(0.0);
              __m256d q_acc_1_2__4 = _mm256_set1_pd(0.0);
              __m256d q_acc_2_2__4 = _mm256_set1_pd(0.0);
              for (int64_t q__3 = 0LL; q__3 < 1LL; q__3 += 1LL) {
                const __m256d tmp_qloop_0__4 = _mm256_mul_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(
                                k_dof_0__4,
                                _mm256_set1_pd(phi_0_0__1[3LL * q__3])),
                            _mm256_mul_pd(
                                k_dof_1__4,
                                _mm256_set1_pd(phi_0_0__1[1LL + 3LL * q__3]))),
                        _mm256_mul_pd(
                            k_dof_2__4,
                            _mm256_set1_pd(phi_0_0__1[2LL + 3LL * q__3]))),
                    _mm256_set1_pd(q_w[q__3]));
                const __m256d q_tmp_0_0__4 = _mm256_mul_pd(
                    tmp_qloop_0__4,
                    _mm256_set1_pd(tabulated_and_untitled_0_0__1[6LL * q__3]));
                const __m256d q_tmp_0_1__4 = _mm256_mul_pd(
                    tmp_qloop_0__4,
                    _mm256_set1_pd(
                        tabulated_and_untitled_0_0__1[1LL + 6LL * q__3]));
                const __m256d q_tmp_0_2__4 = _mm256_mul_pd(
                    tmp_qloop_0__4,
                    _mm256_set1_pd(
                        tabulated_and_untitled_0_0__1[2LL + 6LL * q__3]));
                const __m256d q_tmp_1_1__4 = _mm256_mul_pd(
                    tmp_qloop_0__4,
                    _mm256_set1_pd(
                        tabulated_and_untitled_0_0__1[3LL + 6LL * q__3]));
                const __m256d q_tmp_1_2__4 = _mm256_mul_pd(
                    tmp_qloop_0__4,
                    _mm256_set1_pd(
                        tabulated_and_untitled_0_0__1[4LL + 6LL * q__3]));
                const __m256d q_tmp_2_2__4 = _mm256_mul_pd(
                    tmp_qloop_0__4,
                    _mm256_set1_pd(
                        tabulated_and_untitled_0_0__1[5LL + 6LL * q__3]));
                q_acc_0_0__4 = _mm256_add_pd(q_acc_0_0__4, q_tmp_0_0__4);
                q_acc_0_1__4 = _mm256_add_pd(q_acc_0_1__4, q_tmp_0_1__4);
                q_acc_0_2__4 = _mm256_add_pd(q_acc_0_2__4, q_tmp_0_2__4);
                q_acc_1_1__4 = _mm256_add_pd(q_acc_1_1__4, q_tmp_1_1__4);
                q_acc_1_2__4 = _mm256_add_pd(q_acc_1_2__4, q_tmp_1_2__4);
                q_acc_2_2__4 = _mm256_add_pd(q_acc_2_2__4, q_tmp_2_2__4);
              }
              const __m256d elMatVec_0__4 = _mm256_add_pd(
                  _mm256_add_pd(_mm256_mul_pd(q_acc_0_0__4, src_dof_0__4),
                                _mm256_mul_pd(q_acc_0_1__4, src_dof_1__4)),
                  _mm256_mul_pd(q_acc_0_2__4, src_dof_2__4));
              const __m256d elMatVec_1__4 = _mm256_add_pd(
                  _mm256_add_pd(_mm256_mul_pd(q_acc_0_1__4, src_dof_0__4),
                                _mm256_mul_pd(q_acc_1_1__4, src_dof_1__4)),
                  _mm256_mul_pd(q_acc_1_2__4, src_dof_2__4));
              const __m256d elMatVec_2__4 = _mm256_add_pd(
                  _mm256_add_pd(_mm256_mul_pd(q_acc_0_2__4, src_dof_0__4),
                                _mm256_mul_pd(q_acc_1_2__4, src_dof_1__4)),
                  _mm256_mul_pd(q_acc_2_2__4, src_dof_2__4));
              _mm256_storeu_pd(
                  &_data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) +
                             (2LL + micro_edges_per_macro_edge) * ctr_1 +
                             ctr_0__0],
                  _mm256_add_pd(
                      elMatVec_0__4,
                      _mm256_loadu_pd(
                          &_data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) +
                                     (2LL + micro_edges_per_macro_edge) *
                                         ctr_1 +
                                     ctr_0__0])));
              _mm256_storeu_pd(
                  &_data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                             (2LL + micro_edges_per_macro_edge) * ctr_1 +
                             ctr_0__0],
                  _mm256_add_pd(
                      elMatVec_1__4,
                      _mm256_loadu_pd(
                          &_data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                                     (2LL + micro_edges_per_macro_edge) *
                                         ctr_1 +
                                     ctr_0__0])));
              _mm256_storeu_pd(
                  &_data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                             (1LL + ctr_1) *
                                 (2LL + micro_edges_per_macro_edge) +
                             ctr_0__0],
                  _mm256_add_pd(
                      elMatVec_2__4,
                      _mm256_loadu_pd(
                          &_data_dst[-1LL *
                                         ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                                     (1LL + ctr_1) *
                                         (2LL + micro_edges_per_macro_edge) +
                                     ctr_0__0])));
            }
          }
          {
            /* FaceType.BLUE */
            {
              const __m256d p_affine_0_0__5 = _mm256_add_pd(
                  _mm256_add_pd(
                      _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_mul_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_div_pd(
                                      _mm256_set1_pd(1.0),
                                      _mm256_set1_pd(
                                          micro_edges_per_macro_edge_float))),
                              _mm256_sub_pd(
                                  _mm256_set1_pd(macro_vertex_coord_id_1comp0),
                                  _mm256_set1_pd(
                                      macro_vertex_coord_id_0comp0))),
                          __builtin_convertvector(
                              _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                               ctr_0__3),
                              double __attribute__((__vector_size__(32)))))),
                  _mm256_mul_pd(
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_set1_pd(1.0),
                              _mm256_div_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_set1_pd(
                                      micro_edges_per_macro_edge_float))),
                          _mm256_sub_pd(
                              _mm256_set1_pd(macro_vertex_coord_id_2comp0),
                              _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                      __builtin_convertvector(
                          _mm256_set1_epi64x(ctr_1),
                          double __attribute__((__vector_size__(32))))));
              const __m256d p_affine_0_1__5 = _mm256_add_pd(
                  _mm256_add_pd(
                      _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_mul_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_div_pd(
                                      _mm256_set1_pd(1.0),
                                      _mm256_set1_pd(
                                          micro_edges_per_macro_edge_float))),
                              _mm256_sub_pd(
                                  _mm256_set1_pd(macro_vertex_coord_id_1comp1),
                                  _mm256_set1_pd(
                                      macro_vertex_coord_id_0comp1))),
                          __builtin_convertvector(
                              _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                               ctr_0__3),
                              double __attribute__((__vector_size__(32)))))),
                  _mm256_mul_pd(
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_set1_pd(1.0),
                              _mm256_div_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_set1_pd(
                                      micro_edges_per_macro_edge_float))),
                          _mm256_sub_pd(
                              _mm256_set1_pd(macro_vertex_coord_id_2comp1),
                              _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                      __builtin_convertvector(
                          _mm256_set1_epi64x(ctr_1),
                          double __attribute__((__vector_size__(32))))));
              const __m256d p_affine_1_0__5 = _mm256_add_pd(
                  _mm256_add_pd(
                      _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_mul_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_div_pd(
                                      _mm256_set1_pd(1.0),
                                      _mm256_set1_pd(
                                          micro_edges_per_macro_edge_float))),
                              _mm256_sub_pd(
                                  _mm256_set1_pd(macro_vertex_coord_id_1comp0),
                                  _mm256_set1_pd(
                                      macro_vertex_coord_id_0comp0))),
                          __builtin_convertvector(
                              ctr_0__3,
                              double __attribute__((__vector_size__(32)))))),
                  _mm256_mul_pd(
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_set1_pd(1.0),
                              _mm256_div_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_set1_pd(
                                      micro_edges_per_macro_edge_float))),
                          _mm256_sub_pd(
                              _mm256_set1_pd(macro_vertex_coord_id_2comp0),
                              _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                      __builtin_convertvector(
                          _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                           _mm256_set1_epi64x(ctr_1)),
                          double __attribute__((__vector_size__(32))))));
              const __m256d p_affine_1_1__5 = _mm256_add_pd(
                  _mm256_add_pd(
                      _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_mul_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_div_pd(
                                      _mm256_set1_pd(1.0),
                                      _mm256_set1_pd(
                                          micro_edges_per_macro_edge_float))),
                              _mm256_sub_pd(
                                  _mm256_set1_pd(macro_vertex_coord_id_1comp1),
                                  _mm256_set1_pd(
                                      macro_vertex_coord_id_0comp1))),
                          __builtin_convertvector(
                              ctr_0__3,
                              double __attribute__((__vector_size__(32)))))),
                  _mm256_mul_pd(
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_set1_pd(1.0),
                              _mm256_div_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_set1_pd(
                                      micro_edges_per_macro_edge_float))),
                          _mm256_sub_pd(
                              _mm256_set1_pd(macro_vertex_coord_id_2comp1),
                              _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                      __builtin_convertvector(
                          _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                           _mm256_set1_epi64x(ctr_1)),
                          double __attribute__((__vector_size__(32))))));
              const __m256d p_affine_2_0__5 = _mm256_add_pd(
                  _mm256_add_pd(
                      _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_mul_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_div_pd(
                                      _mm256_set1_pd(1.0),
                                      _mm256_set1_pd(
                                          micro_edges_per_macro_edge_float))),
                              _mm256_sub_pd(
                                  _mm256_set1_pd(macro_vertex_coord_id_1comp0),
                                  _mm256_set1_pd(
                                      macro_vertex_coord_id_0comp0))),
                          __builtin_convertvector(
                              _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                               ctr_0__3),
                              double __attribute__((__vector_size__(32)))))),
                  _mm256_mul_pd(
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_set1_pd(1.0),
                              _mm256_div_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_set1_pd(
                                      micro_edges_per_macro_edge_float))),
                          _mm256_sub_pd(
                              _mm256_set1_pd(macro_vertex_coord_id_2comp0),
                              _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                      __builtin_convertvector(
                          _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                           _mm256_set1_epi64x(ctr_1)),
                          double __attribute__((__vector_size__(32))))));
              const __m256d p_affine_2_1__5 = _mm256_add_pd(
                  _mm256_add_pd(
                      _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_mul_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_div_pd(
                                      _mm256_set1_pd(1.0),
                                      _mm256_set1_pd(
                                          micro_edges_per_macro_edge_float))),
                              _mm256_sub_pd(
                                  _mm256_set1_pd(macro_vertex_coord_id_1comp1),
                                  _mm256_set1_pd(
                                      macro_vertex_coord_id_0comp1))),
                          __builtin_convertvector(
                              _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                               ctr_0__3),
                              double __attribute__((__vector_size__(32)))))),
                  _mm256_mul_pd(
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_set1_pd(1.0),
                              _mm256_div_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_set1_pd(
                                      micro_edges_per_macro_edge_float))),
                          _mm256_sub_pd(
                              _mm256_set1_pd(macro_vertex_coord_id_2comp1),
                              _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                      __builtin_convertvector(
                          _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                           _mm256_set1_epi64x(ctr_1)),
                          double __attribute__((__vector_size__(32))))));
              const __m256d src_dof_0__5 = _mm256_loadu_pd(
                  &_data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                             (2LL + micro_edges_per_macro_edge) * ctr_1 +
                             ctr_0__0]);
              const __m256d src_dof_1__5 = _mm256_loadu_pd(
                  &_data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                             (1LL + ctr_1) *
                                 (2LL + micro_edges_per_macro_edge) +
                             ctr_0__0]);
              const __m256d src_dof_2__5 = _mm256_loadu_pd(
                  &_data_src[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL +
                             (1LL + ctr_1) *
                                 (2LL + micro_edges_per_macro_edge) +
                             ctr_0__0]);
              const __m256d k_dof_0__5 = _mm256_loadu_pd(
                  &_data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                           (2LL + micro_edges_per_macro_edge) * ctr_1 +
                           ctr_0__0]);
              const __m256d k_dof_1__5 = _mm256_loadu_pd(
                  &_data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                           (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                           ctr_0__0]);
              const __m256d k_dof_2__5 = _mm256_loadu_pd(
                  &_data_k[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL +
                           (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                           ctr_0__0]);
              __m256d q_acc_0_0__5 = _mm256_set1_pd(0.0);
              __m256d q_acc_0_1__5 = _mm256_set1_pd(0.0);
              __m256d q_acc_0_2__5 = _mm256_set1_pd(0.0);
              __m256d q_acc_1_1__5 = _mm256_set1_pd(0.0);
              __m256d q_acc_1_2__5 = _mm256_set1_pd(0.0);
              __m256d q_acc_2_2__5 = _mm256_set1_pd(0.0);
              for (int64_t q__2 = 0LL; q__2 < 1LL; q__2 += 1LL) {
                const __m256d tmp_qloop_0__5 = _mm256_mul_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(
                                k_dof_0__5,
                                _mm256_set1_pd(phi_0_0__0[3LL * q__2])),
                            _mm256_mul_pd(
                                k_dof_1__5,
                                _mm256_set1_pd(phi_0_0__0[1LL + 3LL * q__2]))),
                        _mm256_mul_pd(
                            k_dof_2__5,
                            _mm256_set1_pd(phi_0_0__0[2LL + 3LL * q__2]))),
                    _mm256_set1_pd(q_w[q__2]));
                const __m256d q_tmp_0_0__5 = _mm256_mul_pd(
                    tmp_qloop_0__5,
                    _mm256_set1_pd(tabulated_and_untitled_0_0__0[6LL * q__2]));
                const __m256d q_tmp_0_1__5 = _mm256_mul_pd(
                    tmp_qloop_0__5,
                    _mm256_set1_pd(
                        tabulated_and_untitled_0_0__0[1LL + 6LL * q__2]));
                const __m256d q_tmp_0_2__5 = _mm256_mul_pd(
                    tmp_qloop_0__5,
                    _mm256_set1_pd(
                        tabulated_and_untitled_0_0__0[2LL + 6LL * q__2]));
                const __m256d q_tmp_1_1__5 = _mm256_mul_pd(
                    tmp_qloop_0__5,
                    _mm256_set1_pd(
                        tabulated_and_untitled_0_0__0[3LL + 6LL * q__2]));
                const __m256d q_tmp_1_2__5 = _mm256_mul_pd(
                    tmp_qloop_0__5,
                    _mm256_set1_pd(
                        tabulated_and_untitled_0_0__0[4LL + 6LL * q__2]));
                const __m256d q_tmp_2_2__5 = _mm256_mul_pd(
                    tmp_qloop_0__5,
                    _mm256_set1_pd(
                        tabulated_and_untitled_0_0__0[5LL + 6LL * q__2]));
                q_acc_0_0__5 = _mm256_add_pd(q_acc_0_0__5, q_tmp_0_0__5);
                q_acc_0_1__5 = _mm256_add_pd(q_acc_0_1__5, q_tmp_0_1__5);
                q_acc_0_2__5 = _mm256_add_pd(q_acc_0_2__5, q_tmp_0_2__5);
                q_acc_1_1__5 = _mm256_add_pd(q_acc_1_1__5, q_tmp_1_1__5);
                q_acc_1_2__5 = _mm256_add_pd(q_acc_1_2__5, q_tmp_1_2__5);
                q_acc_2_2__5 = _mm256_add_pd(q_acc_2_2__5, q_tmp_2_2__5);
              }
              const __m256d elMatVec_0__5 = _mm256_add_pd(
                  _mm256_add_pd(_mm256_mul_pd(q_acc_0_0__5, src_dof_0__5),
                                _mm256_mul_pd(q_acc_0_1__5, src_dof_1__5)),
                  _mm256_mul_pd(q_acc_0_2__5, src_dof_2__5));
              const __m256d elMatVec_1__5 = _mm256_add_pd(
                  _mm256_add_pd(_mm256_mul_pd(q_acc_0_1__5, src_dof_0__5),
                                _mm256_mul_pd(q_acc_1_1__5, src_dof_1__5)),
                  _mm256_mul_pd(q_acc_1_2__5, src_dof_2__5));
              const __m256d elMatVec_2__5 = _mm256_add_pd(
                  _mm256_add_pd(_mm256_mul_pd(q_acc_0_2__5, src_dof_0__5),
                                _mm256_mul_pd(q_acc_1_2__5, src_dof_1__5)),
                  _mm256_mul_pd(q_acc_2_2__5, src_dof_2__5));
              _mm256_storeu_pd(
                  &_data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                             (2LL + micro_edges_per_macro_edge) * ctr_1 +
                             ctr_0__0],
                  _mm256_add_pd(
                      elMatVec_0__5,
                      _mm256_loadu_pd(
                          &_data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                                     (2LL + micro_edges_per_macro_edge) *
                                         ctr_1 +
                                     ctr_0__0])));
              _mm256_storeu_pd(
                  &_data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                             (1LL + ctr_1) *
                                 (2LL + micro_edges_per_macro_edge) +
                             ctr_0__0],
                  _mm256_add_pd(
                      elMatVec_1__5,
                      _mm256_loadu_pd(
                          &_data_dst[-1LL *
                                         ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                                     (1LL + ctr_1) *
                                         (2LL + micro_edges_per_macro_edge) +
                                     ctr_0__0])));
              _mm256_storeu_pd(
                  &_data_dst[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL +
                             (1LL + ctr_1) *
                                 (2LL + micro_edges_per_macro_edge) +
                             ctr_0__0],
                  _mm256_add_pd(
                      elMatVec_2__5,
                      _mm256_loadu_pd(
                          &_data_dst[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL +
                                     (1LL + ctr_1) *
                                         (2LL + micro_edges_per_macro_edge) +
                                     ctr_0__0])));
            }
          }
        }
        const int64_t __ctr_0__0_trailing_start =
            __ctr_0__0_simd_stop > 0LL
                ? ((__ctr_0__0_simd_stop - 1LL) / __ctr_0__0_simd_step + 1LL) *
                      __ctr_0__0_simd_step
                : 0LL;
        for (int64_t ctr_0__2 = __ctr_0__0_trailing_start;
             ctr_0__2 < -1LL - ctr_1 + micro_edges_per_macro_edge;
             ctr_0__2 += 1LL) {
          {
            /* FaceType.GRAY */
            {
              const double p_affine_0_0__1 =
                  macro_vertex_coord_id_0comp0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_0__2 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_1;
              const double p_affine_0_1__1 =
                  macro_vertex_coord_id_0comp1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_0__2 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_1;
              const double p_affine_1_0__1 =
                  macro_vertex_coord_id_0comp0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)(1LL + ctr_0__2) +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_1;
              const double p_affine_1_1__1 =
                  macro_vertex_coord_id_0comp1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)(1LL + ctr_0__2) +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_1;
              const double p_affine_2_0__1 =
                  macro_vertex_coord_id_0comp0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_0__2 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)(1LL + ctr_1);
              const double p_affine_2_1__1 =
                  macro_vertex_coord_id_0comp1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_0__2 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)(1LL + ctr_1);
              const double src_dof_0__1 =
                  _data_src[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) +
                            (2LL + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__2];
              const double src_dof_1__1 =
                  _data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                            (2LL + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__2];
              const double src_dof_2__1 =
                  _data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                            (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                            ctr_0__2];
              const double k_dof_0__1 =
                  _data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) +
                          (2LL + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__2];
              const double k_dof_1__1 =
                  _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                          (2LL + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__2];
              const double k_dof_2__1 =
                  _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                          (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                          ctr_0__2];
              double q_acc_0_0__1 = 0.0;
              double q_acc_0_1__1 = 0.0;
              double q_acc_0_2__1 = 0.0;
              double q_acc_1_1__1 = 0.0;
              double q_acc_1_2__1 = 0.0;
              double q_acc_2_2__1 = 0.0;
              for (int64_t q__1 = 0LL; q__1 < 1LL; q__1 += 1LL) {
                const double tmp_qloop_0__1 =
                    (k_dof_0__1 * phi_0_0__1[3LL * q__1] +
                     k_dof_1__1 * phi_0_0__1[1LL + 3LL * q__1] +
                     k_dof_2__1 * phi_0_0__1[2LL + 3LL * q__1]) *
                    q_w[q__1];
                const double q_tmp_0_0__1 =
                    tmp_qloop_0__1 * tabulated_and_untitled_0_0__1[6LL * q__1];
                const double q_tmp_0_1__1 =
                    tmp_qloop_0__1 *
                    tabulated_and_untitled_0_0__1[1LL + 6LL * q__1];
                const double q_tmp_0_2__1 =
                    tmp_qloop_0__1 *
                    tabulated_and_untitled_0_0__1[2LL + 6LL * q__1];
                const double q_tmp_1_1__1 =
                    tmp_qloop_0__1 *
                    tabulated_and_untitled_0_0__1[3LL + 6LL * q__1];
                const double q_tmp_1_2__1 =
                    tmp_qloop_0__1 *
                    tabulated_and_untitled_0_0__1[4LL + 6LL * q__1];
                const double q_tmp_2_2__1 =
                    tmp_qloop_0__1 *
                    tabulated_and_untitled_0_0__1[5LL + 6LL * q__1];
                q_acc_0_0__1 = q_acc_0_0__1 + q_tmp_0_0__1;
                q_acc_0_1__1 = q_acc_0_1__1 + q_tmp_0_1__1;
                q_acc_0_2__1 = q_acc_0_2__1 + q_tmp_0_2__1;
                q_acc_1_1__1 = q_acc_1_1__1 + q_tmp_1_1__1;
                q_acc_1_2__1 = q_acc_1_2__1 + q_tmp_1_2__1;
                q_acc_2_2__1 = q_acc_2_2__1 + q_tmp_2_2__1;
              }
              const double elMatVec_0__1 = q_acc_0_0__1 * src_dof_0__1 +
                                           q_acc_0_1__1 * src_dof_1__1 +
                                           q_acc_0_2__1 * src_dof_2__1;
              const double elMatVec_1__1 = q_acc_0_1__1 * src_dof_0__1 +
                                           q_acc_1_1__1 * src_dof_1__1 +
                                           q_acc_1_2__1 * src_dof_2__1;
              const double elMatVec_2__1 = q_acc_0_2__1 * src_dof_0__1 +
                                           q_acc_1_2__1 * src_dof_1__1 +
                                           q_acc_2_2__1 * src_dof_2__1;
              _data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) +
                        (2LL + micro_edges_per_macro_edge) * ctr_1 + ctr_0__2] =
                  elMatVec_0__1 +
                  _data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) +
                            (2LL + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__2];
              _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                        (2LL + micro_edges_per_macro_edge) * ctr_1 + ctr_0__2] =
                  elMatVec_1__1 +
                  _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                            (2LL + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__2];
              _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                        (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                        ctr_0__2] =
                  elMatVec_2__1 +
                  _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                            (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                            ctr_0__2];
            }
          }
          {
            /* FaceType.BLUE */
            {
              const double p_affine_0_0__0 =
                  macro_vertex_coord_id_0comp0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)(1LL + ctr_0__2) +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_1;
              const double p_affine_0_1__0 =
                  macro_vertex_coord_id_0comp1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)(1LL + ctr_0__2) +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_1;
              const double p_affine_1_0__0 =
                  macro_vertex_coord_id_0comp0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_0__2 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)(1LL + ctr_1);
              const double p_affine_1_1__0 =
                  macro_vertex_coord_id_0comp1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_0__2 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)(1LL + ctr_1);
              const double p_affine_2_0__0 =
                  macro_vertex_coord_id_0comp0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)(1LL + ctr_0__2) +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)(1LL + ctr_1);
              const double p_affine_2_1__0 =
                  macro_vertex_coord_id_0comp1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)(1LL + ctr_0__2) +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)(1LL + ctr_1);
              const double src_dof_0__0 =
                  _data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                            (2LL + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__2];
              const double src_dof_1__0 =
                  _data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                            (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                            ctr_0__2];
              const double src_dof_2__0 =
                  _data_src[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL +
                            (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                            ctr_0__2];
              const double k_dof_0__0 =
                  _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                          (2LL + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__2];
              const double k_dof_1__0 =
                  _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                          (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                          ctr_0__2];
              const double k_dof_2__0 =
                  _data_k[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL +
                          (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                          ctr_0__2];
              double q_acc_0_0__0 = 0.0;
              double q_acc_0_1__0 = 0.0;
              double q_acc_0_2__0 = 0.0;
              double q_acc_1_1__0 = 0.0;
              double q_acc_1_2__0 = 0.0;
              double q_acc_2_2__0 = 0.0;
              for (int64_t q__0 = 0LL; q__0 < 1LL; q__0 += 1LL) {
                const double tmp_qloop_0__0 =
                    (k_dof_0__0 * phi_0_0__0[3LL * q__0] +
                     k_dof_1__0 * phi_0_0__0[1LL + 3LL * q__0] +
                     k_dof_2__0 * phi_0_0__0[2LL + 3LL * q__0]) *
                    q_w[q__0];
                const double q_tmp_0_0__0 =
                    tmp_qloop_0__0 * tabulated_and_untitled_0_0__0[6LL * q__0];
                const double q_tmp_0_1__0 =
                    tmp_qloop_0__0 *
                    tabulated_and_untitled_0_0__0[1LL + 6LL * q__0];
                const double q_tmp_0_2__0 =
                    tmp_qloop_0__0 *
                    tabulated_and_untitled_0_0__0[2LL + 6LL * q__0];
                const double q_tmp_1_1__0 =
                    tmp_qloop_0__0 *
                    tabulated_and_untitled_0_0__0[3LL + 6LL * q__0];
                const double q_tmp_1_2__0 =
                    tmp_qloop_0__0 *
                    tabulated_and_untitled_0_0__0[4LL + 6LL * q__0];
                const double q_tmp_2_2__0 =
                    tmp_qloop_0__0 *
                    tabulated_and_untitled_0_0__0[5LL + 6LL * q__0];
                q_acc_0_0__0 = q_acc_0_0__0 + q_tmp_0_0__0;
                q_acc_0_1__0 = q_acc_0_1__0 + q_tmp_0_1__0;
                q_acc_0_2__0 = q_acc_0_2__0 + q_tmp_0_2__0;
                q_acc_1_1__0 = q_acc_1_1__0 + q_tmp_1_1__0;
                q_acc_1_2__0 = q_acc_1_2__0 + q_tmp_1_2__0;
                q_acc_2_2__0 = q_acc_2_2__0 + q_tmp_2_2__0;
              }
              const double elMatVec_0__0 = q_acc_0_0__0 * src_dof_0__0 +
                                           q_acc_0_1__0 * src_dof_1__0 +
                                           q_acc_0_2__0 * src_dof_2__0;
              const double elMatVec_1__0 = q_acc_0_1__0 * src_dof_0__0 +
                                           q_acc_1_1__0 * src_dof_1__0 +
                                           q_acc_1_2__0 * src_dof_2__0;
              const double elMatVec_2__0 = q_acc_0_2__0 * src_dof_0__0 +
                                           q_acc_1_2__0 * src_dof_1__0 +
                                           q_acc_2_2__0 * src_dof_2__0;
              _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                        (2LL + micro_edges_per_macro_edge) * ctr_1 + ctr_0__2] =
                  elMatVec_0__0 +
                  _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                            (2LL + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__2];
              _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                        (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                        ctr_0__2] =
                  elMatVec_1__0 +
                  _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                            (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                            ctr_0__2];
              _data_dst[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL +
                        (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                        ctr_0__2] =
                  elMatVec_2__0 +
                  _data_dst[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL +
                            (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                            ctr_0__2];
            }
          }
        }
      }
      {
        const int64_t ctr_0 = -1LL - ctr_1 + micro_edges_per_macro_edge;
        {
          /* FaceType.GRAY */
          {
            const double p_affine_0_0 =
                macro_vertex_coord_id_0comp0 +
                1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                    (macro_vertex_coord_id_1comp0 -
                     macro_vertex_coord_id_0comp0) *
                    (double)ctr_0 +
                1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                    (macro_vertex_coord_id_2comp0 -
                     macro_vertex_coord_id_0comp0) *
                    (double)ctr_1;
            const double p_affine_0_1 =
                macro_vertex_coord_id_0comp1 +
                1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                    (macro_vertex_coord_id_1comp1 -
                     macro_vertex_coord_id_0comp1) *
                    (double)ctr_0 +
                1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                    (macro_vertex_coord_id_2comp1 -
                     macro_vertex_coord_id_0comp1) *
                    (double)ctr_1;
            const double p_affine_1_0 =
                macro_vertex_coord_id_0comp0 +
                1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                    (macro_vertex_coord_id_1comp0 -
                     macro_vertex_coord_id_0comp0) *
                    (double)(1LL + ctr_0) +
                1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                    (macro_vertex_coord_id_2comp0 -
                     macro_vertex_coord_id_0comp0) *
                    (double)ctr_1;
            const double p_affine_1_1 =
                macro_vertex_coord_id_0comp1 +
                1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                    (macro_vertex_coord_id_1comp1 -
                     macro_vertex_coord_id_0comp1) *
                    (double)(1LL + ctr_0) +
                1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                    (macro_vertex_coord_id_2comp1 -
                     macro_vertex_coord_id_0comp1) *
                    (double)ctr_1;
            const double p_affine_2_0 =
                macro_vertex_coord_id_0comp0 +
                1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                    (macro_vertex_coord_id_1comp0 -
                     macro_vertex_coord_id_0comp0) *
                    (double)ctr_0 +
                1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                    (macro_vertex_coord_id_2comp0 -
                     macro_vertex_coord_id_0comp0) *
                    (double)(1LL + ctr_1);
            const double p_affine_2_1 =
                macro_vertex_coord_id_0comp1 +
                1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                    (macro_vertex_coord_id_1comp1 -
                     macro_vertex_coord_id_0comp1) *
                    (double)ctr_0 +
                1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                    (macro_vertex_coord_id_2comp1 -
                     macro_vertex_coord_id_0comp1) *
                    (double)(1LL + ctr_1);
            const double src_dof_0 =
                _data_src[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) +
                          (2LL + micro_edges_per_macro_edge) * ctr_1 + ctr_0];
            const double src_dof_1 =
                _data_src[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                          (2LL + micro_edges_per_macro_edge) * ctr_1 + ctr_0];
            const double src_dof_2 =
                _data_src[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                          (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                          ctr_0];
            const double k_dof_0 =
                _data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) +
                        (2LL + micro_edges_per_macro_edge) * ctr_1 + ctr_0];
            const double k_dof_1 =
                _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                        (2LL + micro_edges_per_macro_edge) * ctr_1 + ctr_0];
            const double k_dof_2 =
                _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                        (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                        ctr_0];
            double q_acc_0_0 = 0.0;
            double q_acc_0_1 = 0.0;
            double q_acc_0_2 = 0.0;
            double q_acc_1_1 = 0.0;
            double q_acc_1_2 = 0.0;
            double q_acc_2_2 = 0.0;
            for (int64_t q = 0LL; q < 1LL; q += 1LL) {
              const double tmp_qloop_0 = (k_dof_0 * phi_0_0[3LL * q] +
                                          k_dof_1 * phi_0_0[1LL + 3LL * q] +
                                          k_dof_2 * phi_0_0[2LL + 3LL * q]) *
                                         q_w[q];
              const double q_tmp_0_0 =
                  tmp_qloop_0 * tabulated_and_untitled_0_0[6LL * q];
              const double q_tmp_0_1 =
                  tmp_qloop_0 * tabulated_and_untitled_0_0[1LL + 6LL * q];
              const double q_tmp_0_2 =
                  tmp_qloop_0 * tabulated_and_untitled_0_0[2LL + 6LL * q];
              const double q_tmp_1_1 =
                  tmp_qloop_0 * tabulated_and_untitled_0_0[3LL + 6LL * q];
              const double q_tmp_1_2 =
                  tmp_qloop_0 * tabulated_and_untitled_0_0[4LL + 6LL * q];
              const double q_tmp_2_2 =
                  tmp_qloop_0 * tabulated_and_untitled_0_0[5LL + 6LL * q];
              q_acc_0_0 = q_acc_0_0 + q_tmp_0_0;
              q_acc_0_1 = q_acc_0_1 + q_tmp_0_1;
              q_acc_0_2 = q_acc_0_2 + q_tmp_0_2;
              q_acc_1_1 = q_acc_1_1 + q_tmp_1_1;
              q_acc_1_2 = q_acc_1_2 + q_tmp_1_2;
              q_acc_2_2 = q_acc_2_2 + q_tmp_2_2;
            }
            const double elMatVec_0 = q_acc_0_0 * src_dof_0 +
                                      q_acc_0_1 * src_dof_1 +
                                      q_acc_0_2 * src_dof_2;
            const double elMatVec_1 = q_acc_0_1 * src_dof_0 +
                                      q_acc_1_1 * src_dof_1 +
                                      q_acc_1_2 * src_dof_2;
            const double elMatVec_2 = q_acc_0_2 * src_dof_0 +
                                      q_acc_1_2 * src_dof_1 +
                                      q_acc_2_2 * src_dof_2;
            _data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) +
                      (2LL + micro_edges_per_macro_edge) * ctr_1 + ctr_0] =
                elMatVec_0 +
                _data_dst[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) +
                          (2LL + micro_edges_per_macro_edge) * ctr_1 + ctr_0];
            _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                      (2LL + micro_edges_per_macro_edge) * ctr_1 + ctr_0] =
                elMatVec_1 +
                _data_dst[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                          (2LL + micro_edges_per_macro_edge) * ctr_1 + ctr_0];
            _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                      (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                      ctr_0] =
                elMatVec_2 +
                _data_dst[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                          (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                          ctr_0];
          }
        }
      }
    }
  }
}
void P1ElementwiseDivKGrad_cubes_const_vect_fused_quadloops_tab::
    computeInverseDiagonalOperatorValues_P1ElementwiseDivKGrad_cubes_const_vect_fused_quadloops_tab_macro_3D(
        double *RESTRICT const _data_invDiag_, double *RESTRICT const _data_k,
        const double macro_vertex_coord_id_0comp0,
        const double macro_vertex_coord_id_0comp1,
        const double macro_vertex_coord_id_0comp2,
        const double macro_vertex_coord_id_1comp0,
        const double macro_vertex_coord_id_1comp1,
        const double macro_vertex_coord_id_1comp2,
        const double macro_vertex_coord_id_2comp0,
        const double macro_vertex_coord_id_2comp1,
        const double macro_vertex_coord_id_2comp2,
        const double macro_vertex_coord_id_3comp0,
        const double macro_vertex_coord_id_3comp1,
        const double macro_vertex_coord_id_3comp2,
        const int64_t micro_edges_per_macro_edge,
        const double micro_edges_per_macro_edge_float) const {
  {
    double q_w[1] = {0.16666666666666663};
    const double tmp_coords_jac_0__10 =
        macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_1__10 =
        1.0 * (1.0 / micro_edges_per_macro_edge_float);
    const double tmp_coords_jac_2__10 = tmp_coords_jac_1__10 * 0.0;
    const double tmp_coords_jac_3__10 =
        tmp_coords_jac_0__10 * tmp_coords_jac_2__10;
    const double tmp_coords_jac_4__10 =
        macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_5__10 =
        tmp_coords_jac_2__10 * tmp_coords_jac_4__10;
    const double tmp_coords_jac_6__10 =
        macro_vertex_coord_id_3comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_7__10 =
        tmp_coords_jac_2__10 * tmp_coords_jac_6__10;
    const double tmp_coords_jac_8__10 = macro_vertex_coord_id_0comp0 +
                                        tmp_coords_jac_5__10 +
                                        tmp_coords_jac_7__10;
    const double tmp_coords_jac_9__10 =
        macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_10__10 =
        tmp_coords_jac_2__10 * tmp_coords_jac_9__10;
    const double tmp_coords_jac_11__10 =
        macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_12__10 =
        tmp_coords_jac_11__10 * tmp_coords_jac_2__10;
    const double tmp_coords_jac_13__10 =
        macro_vertex_coord_id_3comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_14__10 =
        tmp_coords_jac_13__10 * tmp_coords_jac_2__10;
    const double tmp_coords_jac_15__10 = macro_vertex_coord_id_0comp1 +
                                         tmp_coords_jac_12__10 +
                                         tmp_coords_jac_14__10;
    const double tmp_coords_jac_16__10 =
        macro_vertex_coord_id_1comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_17__10 =
        tmp_coords_jac_16__10 * tmp_coords_jac_2__10;
    const double tmp_coords_jac_18__10 =
        macro_vertex_coord_id_2comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_19__10 =
        tmp_coords_jac_18__10 * tmp_coords_jac_2__10;
    const double tmp_coords_jac_20__10 =
        macro_vertex_coord_id_3comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_21__10 =
        tmp_coords_jac_2__10 * tmp_coords_jac_20__10;
    const double tmp_coords_jac_22__10 = macro_vertex_coord_id_0comp2 +
                                         tmp_coords_jac_19__10 +
                                         tmp_coords_jac_21__10;
    const double tmp_coords_jac_23__10 = tmp_coords_jac_1__10 * 1.0;
    const double tmp_coords_jac_24__10 =
        macro_vertex_coord_id_0comp0 + tmp_coords_jac_3__10;
    const double tmp_coords_jac_25__10 =
        macro_vertex_coord_id_0comp1 + tmp_coords_jac_10__10;
    const double tmp_coords_jac_26__10 =
        macro_vertex_coord_id_0comp2 + tmp_coords_jac_17__10;
    const double p_affine_const_0_0__10 =
        tmp_coords_jac_3__10 + tmp_coords_jac_8__10;
    const double p_affine_const_0_1__10 =
        tmp_coords_jac_10__10 + tmp_coords_jac_15__10;
    const double p_affine_const_0_2__10 =
        tmp_coords_jac_17__10 + tmp_coords_jac_22__10;
    const double p_affine_const_1_0__10 =
        tmp_coords_jac_8__10 + tmp_coords_jac_0__10 * tmp_coords_jac_23__10;
    const double p_affine_const_1_1__10 =
        tmp_coords_jac_15__10 + tmp_coords_jac_23__10 * tmp_coords_jac_9__10;
    const double p_affine_const_1_2__10 =
        tmp_coords_jac_22__10 + tmp_coords_jac_16__10 * tmp_coords_jac_23__10;
    const double p_affine_const_2_0__10 =
        tmp_coords_jac_24__10 + tmp_coords_jac_7__10 +
        tmp_coords_jac_23__10 * tmp_coords_jac_4__10;
    const double p_affine_const_2_1__10 =
        tmp_coords_jac_14__10 + tmp_coords_jac_25__10 +
        tmp_coords_jac_11__10 * tmp_coords_jac_23__10;
    const double p_affine_const_2_2__10 =
        tmp_coords_jac_21__10 + tmp_coords_jac_26__10 +
        tmp_coords_jac_18__10 * tmp_coords_jac_23__10;
    const double p_affine_const_3_0__10 =
        tmp_coords_jac_24__10 + tmp_coords_jac_5__10 +
        tmp_coords_jac_23__10 * tmp_coords_jac_6__10;
    const double p_affine_const_3_1__10 =
        tmp_coords_jac_12__10 + tmp_coords_jac_25__10 +
        tmp_coords_jac_13__10 * tmp_coords_jac_23__10;
    const double p_affine_const_3_2__10 =
        tmp_coords_jac_19__10 + tmp_coords_jac_26__10 +
        tmp_coords_jac_20__10 * tmp_coords_jac_23__10;
    const double jac_affine_0_0__10 =
        p_affine_const_1_0__10 - p_affine_const_0_0__10;
    const double jac_affine_0_1__10 =
        p_affine_const_2_0__10 - p_affine_const_0_0__10;
    const double jac_affine_0_2__10 =
        p_affine_const_3_0__10 - p_affine_const_0_0__10;
    const double jac_affine_1_0__10 =
        p_affine_const_1_1__10 - p_affine_const_0_1__10;
    const double jac_affine_1_1__10 =
        p_affine_const_2_1__10 - p_affine_const_0_1__10;
    const double tmp_coords_jac_31__7 = jac_affine_0_2__10 * jac_affine_1_1__10;
    const double jac_affine_1_2__10 =
        p_affine_const_3_1__10 - p_affine_const_0_1__10;
    const double tmp_coords_jac_29__10 =
        jac_affine_0_1__10 * jac_affine_1_2__10;
    const double jac_affine_2_0__10 =
        p_affine_const_1_2__10 - p_affine_const_0_2__10;
    const double jac_affine_2_1__10 =
        p_affine_const_2_2__10 - p_affine_const_0_2__10;
    const double tmp_coords_jac_28__10 =
        jac_affine_1_2__10 * jac_affine_2_1__10;
    const double jac_affine_2_2__10 =
        p_affine_const_3_2__10 - p_affine_const_0_2__10;
    const double tmp_coords_jac_27__10 =
        jac_affine_1_1__10 * jac_affine_2_2__10;
    const double tmp_coords_jac_30__10 =
        jac_affine_0_1__10 * jac_affine_2_2__10;
    const double tmp_coords_jac_32__7 =
        jac_affine_0_0__10 * tmp_coords_jac_27__10 +
        jac_affine_2_0__10 * tmp_coords_jac_29__10 -
        jac_affine_0_0__10 * tmp_coords_jac_28__10 -
        jac_affine_1_0__10 * tmp_coords_jac_30__10 -
        jac_affine_2_0__10 * tmp_coords_jac_31__7 +
        jac_affine_0_2__10 * jac_affine_1_0__10 * jac_affine_2_1__10;
    const double tmp_coords_jac_33__7 = 1.0 / tmp_coords_jac_32__7;
    const double jac_affine_inv_0_0__10 =
        tmp_coords_jac_33__7 * (tmp_coords_jac_27__10 - tmp_coords_jac_28__10);
    const double jac_affine_inv_0_1__10 =
        tmp_coords_jac_33__7 * (-1.0 * tmp_coords_jac_30__10 +
                                jac_affine_0_2__10 * jac_affine_2_1__10);
    const double jac_affine_inv_0_2__10 =
        tmp_coords_jac_33__7 * (tmp_coords_jac_29__10 - tmp_coords_jac_31__7);
    const double jac_affine_inv_1_0__10 =
        tmp_coords_jac_33__7 * (jac_affine_1_2__10 * jac_affine_2_0__10 -
                                jac_affine_1_0__10 * jac_affine_2_2__10);
    const double jac_affine_inv_1_1__10 =
        tmp_coords_jac_33__7 * (jac_affine_0_0__10 * jac_affine_2_2__10 -
                                jac_affine_0_2__10 * jac_affine_2_0__10);
    const double jac_affine_inv_1_2__10 =
        tmp_coords_jac_33__7 * (jac_affine_0_2__10 * jac_affine_1_0__10 -
                                jac_affine_0_0__10 * jac_affine_1_2__10);
    const double jac_affine_inv_2_0__10 =
        tmp_coords_jac_33__7 * (jac_affine_1_0__10 * jac_affine_2_1__10 -
                                jac_affine_1_1__10 * jac_affine_2_0__10);
    const double jac_affine_inv_2_1__10 =
        tmp_coords_jac_33__7 * (jac_affine_0_1__10 * jac_affine_2_0__10 -
                                jac_affine_0_0__10 * jac_affine_2_1__10);
    const double jac_affine_inv_2_2__10 =
        tmp_coords_jac_33__7 * (jac_affine_0_0__10 * jac_affine_1_1__10 -
                                jac_affine_0_1__10 * jac_affine_1_0__10);
    const double abs_det_jac_affine__10 = abs(tmp_coords_jac_32__7);
    double phi_0_0__10[4] = {0.25, 0.25, 0.25, 0.25};
    double tabulated_and_untitled_0_0__10[10] = {
        abs_det_jac_affine__10 *
            ((-1.0 * jac_affine_inv_0_0__10 - jac_affine_inv_1_0__10 -
              jac_affine_inv_2_0__10) *
                 (-1.0 * jac_affine_inv_0_0__10 - jac_affine_inv_1_0__10 -
                  jac_affine_inv_2_0__10) +
             (-1.0 * jac_affine_inv_0_1__10 - jac_affine_inv_1_1__10 -
              jac_affine_inv_2_1__10) *
                 (-1.0 * jac_affine_inv_0_1__10 - jac_affine_inv_1_1__10 -
                  jac_affine_inv_2_1__10) +
             (-1.0 * jac_affine_inv_0_2__10 - jac_affine_inv_1_2__10 -
              jac_affine_inv_2_2__10) *
                 (-1.0 * jac_affine_inv_0_2__10 - jac_affine_inv_1_2__10 -
                  jac_affine_inv_2_2__10)),
        abs_det_jac_affine__10 *
            (jac_affine_inv_0_0__10 *
                 (-1.0 * jac_affine_inv_0_0__10 - jac_affine_inv_1_0__10 -
                  jac_affine_inv_2_0__10) +
             jac_affine_inv_0_1__10 *
                 (-1.0 * jac_affine_inv_0_1__10 - jac_affine_inv_1_1__10 -
                  jac_affine_inv_2_1__10) +
             jac_affine_inv_0_2__10 *
                 (-1.0 * jac_affine_inv_0_2__10 - jac_affine_inv_1_2__10 -
                  jac_affine_inv_2_2__10)),
        abs_det_jac_affine__10 *
            (jac_affine_inv_1_0__10 *
                 (-1.0 * jac_affine_inv_0_0__10 - jac_affine_inv_1_0__10 -
                  jac_affine_inv_2_0__10) +
             jac_affine_inv_1_1__10 *
                 (-1.0 * jac_affine_inv_0_1__10 - jac_affine_inv_1_1__10 -
                  jac_affine_inv_2_1__10) +
             jac_affine_inv_1_2__10 *
                 (-1.0 * jac_affine_inv_0_2__10 - jac_affine_inv_1_2__10 -
                  jac_affine_inv_2_2__10)),
        abs_det_jac_affine__10 *
            (jac_affine_inv_2_0__10 *
                 (-1.0 * jac_affine_inv_0_0__10 - jac_affine_inv_1_0__10 -
                  jac_affine_inv_2_0__10) +
             jac_affine_inv_2_1__10 *
                 (-1.0 * jac_affine_inv_0_1__10 - jac_affine_inv_1_1__10 -
                  jac_affine_inv_2_1__10) +
             jac_affine_inv_2_2__10 *
                 (-1.0 * jac_affine_inv_0_2__10 - jac_affine_inv_1_2__10 -
                  jac_affine_inv_2_2__10)),
        abs_det_jac_affine__10 *
            (jac_affine_inv_0_0__10 * jac_affine_inv_0_0__10 +
             jac_affine_inv_0_1__10 * jac_affine_inv_0_1__10 +
             jac_affine_inv_0_2__10 * jac_affine_inv_0_2__10),
        abs_det_jac_affine__10 *
            (jac_affine_inv_0_0__10 * jac_affine_inv_1_0__10 +
             jac_affine_inv_0_1__10 * jac_affine_inv_1_1__10 +
             jac_affine_inv_0_2__10 * jac_affine_inv_1_2__10),
        abs_det_jac_affine__10 *
            (jac_affine_inv_0_0__10 * jac_affine_inv_2_0__10 +
             jac_affine_inv_0_1__10 * jac_affine_inv_2_1__10 +
             jac_affine_inv_0_2__10 * jac_affine_inv_2_2__10),
        abs_det_jac_affine__10 *
            (jac_affine_inv_1_0__10 * jac_affine_inv_1_0__10 +
             jac_affine_inv_1_1__10 * jac_affine_inv_1_1__10 +
             jac_affine_inv_1_2__10 * jac_affine_inv_1_2__10),
        abs_det_jac_affine__10 *
            (jac_affine_inv_1_0__10 * jac_affine_inv_2_0__10 +
             jac_affine_inv_1_1__10 * jac_affine_inv_2_1__10 +
             jac_affine_inv_1_2__10 * jac_affine_inv_2_2__10),
        abs_det_jac_affine__10 *
            (jac_affine_inv_2_0__10 * jac_affine_inv_2_0__10 +
             jac_affine_inv_2_1__10 * jac_affine_inv_2_1__10 +
             jac_affine_inv_2_2__10 * jac_affine_inv_2_2__10)};
    const double tmp_coords_jac_0__9 =
        macro_vertex_coord_id_3comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_1__9 =
        1.0 * (1.0 / micro_edges_per_macro_edge_float);
    const double tmp_coords_jac_2__9 = tmp_coords_jac_1__9 * 0.0;
    const double tmp_coords_jac_3__9 =
        macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_4__9 = tmp_coords_jac_1__9 * 1.0;
    const double tmp_coords_jac_5__9 =
        tmp_coords_jac_3__9 * tmp_coords_jac_4__9;
    const double tmp_coords_jac_6__9 =
        macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_7__9 =
        macro_vertex_coord_id_0comp0 +
        tmp_coords_jac_4__9 * tmp_coords_jac_6__9;
    const double tmp_coords_jac_8__9 =
        tmp_coords_jac_5__9 + tmp_coords_jac_7__9;
    const double tmp_coords_jac_9__9 =
        macro_vertex_coord_id_3comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_10__9 =
        macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_11__9 =
        tmp_coords_jac_10__9 * tmp_coords_jac_4__9;
    const double tmp_coords_jac_12__9 =
        macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_13__9 =
        macro_vertex_coord_id_0comp1 +
        tmp_coords_jac_12__9 * tmp_coords_jac_4__9;
    const double tmp_coords_jac_14__9 =
        tmp_coords_jac_11__9 + tmp_coords_jac_13__9;
    const double tmp_coords_jac_15__9 =
        macro_vertex_coord_id_3comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_16__9 =
        macro_vertex_coord_id_2comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_17__9 =
        tmp_coords_jac_16__9 * tmp_coords_jac_4__9;
    const double tmp_coords_jac_18__9 =
        macro_vertex_coord_id_1comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_19__9 =
        macro_vertex_coord_id_0comp2 +
        tmp_coords_jac_18__9 * tmp_coords_jac_4__9;
    const double tmp_coords_jac_20__9 =
        tmp_coords_jac_17__9 + tmp_coords_jac_19__9;
    const double tmp_coords_jac_21__9 =
        tmp_coords_jac_0__9 * tmp_coords_jac_4__9;
    const double tmp_coords_jac_22__9 =
        tmp_coords_jac_4__9 * tmp_coords_jac_9__9;
    const double tmp_coords_jac_23__9 =
        tmp_coords_jac_15__9 * tmp_coords_jac_4__9;
    const double p_affine_const_0_0__9 =
        tmp_coords_jac_8__9 + tmp_coords_jac_0__9 * tmp_coords_jac_2__9;
    const double p_affine_const_0_1__9 =
        tmp_coords_jac_14__9 + tmp_coords_jac_2__9 * tmp_coords_jac_9__9;
    const double p_affine_const_0_2__9 =
        tmp_coords_jac_20__9 + tmp_coords_jac_15__9 * tmp_coords_jac_2__9;
    const double p_affine_const_1_0__9 =
        tmp_coords_jac_21__9 + tmp_coords_jac_7__9 +
        tmp_coords_jac_2__9 * tmp_coords_jac_3__9;
    const double p_affine_const_1_1__9 =
        tmp_coords_jac_13__9 + tmp_coords_jac_22__9 +
        tmp_coords_jac_10__9 * tmp_coords_jac_2__9;
    const double p_affine_const_1_2__9 =
        tmp_coords_jac_19__9 + tmp_coords_jac_23__9 +
        tmp_coords_jac_16__9 * tmp_coords_jac_2__9;
    const double p_affine_const_2_0__9 =
        macro_vertex_coord_id_0comp0 + tmp_coords_jac_21__9 +
        tmp_coords_jac_5__9 + tmp_coords_jac_2__9 * tmp_coords_jac_6__9;
    const double p_affine_const_2_1__9 =
        macro_vertex_coord_id_0comp1 + tmp_coords_jac_11__9 +
        tmp_coords_jac_22__9 + tmp_coords_jac_12__9 * tmp_coords_jac_2__9;
    const double p_affine_const_2_2__9 =
        macro_vertex_coord_id_0comp2 + tmp_coords_jac_17__9 +
        tmp_coords_jac_23__9 + tmp_coords_jac_18__9 * tmp_coords_jac_2__9;
    const double p_affine_const_3_0__9 =
        tmp_coords_jac_21__9 + tmp_coords_jac_8__9;
    const double p_affine_const_3_1__9 =
        tmp_coords_jac_14__9 + tmp_coords_jac_22__9;
    const double p_affine_const_3_2__9 =
        tmp_coords_jac_20__9 + tmp_coords_jac_23__9;
    const double jac_affine_0_0__9 =
        p_affine_const_1_0__9 - p_affine_const_0_0__9;
    const double jac_affine_0_1__9 =
        p_affine_const_2_0__9 - p_affine_const_0_0__9;
    const double jac_affine_0_2__9 =
        p_affine_const_3_0__9 - p_affine_const_0_0__9;
    const double jac_affine_1_0__9 =
        p_affine_const_1_1__9 - p_affine_const_0_1__9;
    const double jac_affine_1_1__9 =
        p_affine_const_2_1__9 - p_affine_const_0_1__9;
    const double tmp_coords_jac_28__9 = jac_affine_0_2__9 * jac_affine_1_1__9;
    const double jac_affine_1_2__9 =
        p_affine_const_3_1__9 - p_affine_const_0_1__9;
    const double tmp_coords_jac_26__9 = jac_affine_0_1__9 * jac_affine_1_2__9;
    const double jac_affine_2_0__9 =
        p_affine_const_1_2__9 - p_affine_const_0_2__9;
    const double jac_affine_2_1__9 =
        p_affine_const_2_2__9 - p_affine_const_0_2__9;
    const double tmp_coords_jac_25__9 = jac_affine_1_2__9 * jac_affine_2_1__9;
    const double jac_affine_2_2__9 =
        p_affine_const_3_2__9 - p_affine_const_0_2__9;
    const double tmp_coords_jac_24__9 = jac_affine_1_1__9 * jac_affine_2_2__9;
    const double tmp_coords_jac_27__9 = jac_affine_0_1__9 * jac_affine_2_2__9;
    const double tmp_coords_jac_29__9 =
        jac_affine_0_0__9 * tmp_coords_jac_24__9 +
        jac_affine_2_0__9 * tmp_coords_jac_26__9 -
        jac_affine_0_0__9 * tmp_coords_jac_25__9 -
        jac_affine_1_0__9 * tmp_coords_jac_27__9 -
        jac_affine_2_0__9 * tmp_coords_jac_28__9 +
        jac_affine_0_2__9 * jac_affine_1_0__9 * jac_affine_2_1__9;
    const double tmp_coords_jac_30__9 = 1.0 / tmp_coords_jac_29__9;
    const double jac_affine_inv_0_0__9 =
        tmp_coords_jac_30__9 * (tmp_coords_jac_24__9 - tmp_coords_jac_25__9);
    const double jac_affine_inv_0_1__9 =
        tmp_coords_jac_30__9 *
        (-1.0 * tmp_coords_jac_27__9 + jac_affine_0_2__9 * jac_affine_2_1__9);
    const double jac_affine_inv_0_2__9 =
        tmp_coords_jac_30__9 * (tmp_coords_jac_26__9 - tmp_coords_jac_28__9);
    const double jac_affine_inv_1_0__9 =
        tmp_coords_jac_30__9 * (jac_affine_1_2__9 * jac_affine_2_0__9 -
                                jac_affine_1_0__9 * jac_affine_2_2__9);
    const double jac_affine_inv_1_1__9 =
        tmp_coords_jac_30__9 * (jac_affine_0_0__9 * jac_affine_2_2__9 -
                                jac_affine_0_2__9 * jac_affine_2_0__9);
    const double jac_affine_inv_1_2__9 =
        tmp_coords_jac_30__9 * (jac_affine_0_2__9 * jac_affine_1_0__9 -
                                jac_affine_0_0__9 * jac_affine_1_2__9);
    const double jac_affine_inv_2_0__9 =
        tmp_coords_jac_30__9 * (jac_affine_1_0__9 * jac_affine_2_1__9 -
                                jac_affine_1_1__9 * jac_affine_2_0__9);
    const double jac_affine_inv_2_1__9 =
        tmp_coords_jac_30__9 * (jac_affine_0_1__9 * jac_affine_2_0__9 -
                                jac_affine_0_0__9 * jac_affine_2_1__9);
    const double jac_affine_inv_2_2__9 =
        tmp_coords_jac_30__9 * (jac_affine_0_0__9 * jac_affine_1_1__9 -
                                jac_affine_0_1__9 * jac_affine_1_0__9);
    const double abs_det_jac_affine__9 = abs(tmp_coords_jac_29__9);
    double phi_0_0__9[4] = {0.25, 0.25, 0.25, 0.25};
    double tabulated_and_untitled_0_0__9[10] = {
        abs_det_jac_affine__9 *
            ((-1.0 * jac_affine_inv_0_0__9 - jac_affine_inv_1_0__9 -
              jac_affine_inv_2_0__9) *
                 (-1.0 * jac_affine_inv_0_0__9 - jac_affine_inv_1_0__9 -
                  jac_affine_inv_2_0__9) +
             (-1.0 * jac_affine_inv_0_1__9 - jac_affine_inv_1_1__9 -
              jac_affine_inv_2_1__9) *
                 (-1.0 * jac_affine_inv_0_1__9 - jac_affine_inv_1_1__9 -
                  jac_affine_inv_2_1__9) +
             (-1.0 * jac_affine_inv_0_2__9 - jac_affine_inv_1_2__9 -
              jac_affine_inv_2_2__9) *
                 (-1.0 * jac_affine_inv_0_2__9 - jac_affine_inv_1_2__9 -
                  jac_affine_inv_2_2__9)),
        abs_det_jac_affine__9 *
            (jac_affine_inv_0_0__9 *
                 (-1.0 * jac_affine_inv_0_0__9 - jac_affine_inv_1_0__9 -
                  jac_affine_inv_2_0__9) +
             jac_affine_inv_0_1__9 *
                 (-1.0 * jac_affine_inv_0_1__9 - jac_affine_inv_1_1__9 -
                  jac_affine_inv_2_1__9) +
             jac_affine_inv_0_2__9 *
                 (-1.0 * jac_affine_inv_0_2__9 - jac_affine_inv_1_2__9 -
                  jac_affine_inv_2_2__9)),
        abs_det_jac_affine__9 *
            (jac_affine_inv_1_0__9 *
                 (-1.0 * jac_affine_inv_0_0__9 - jac_affine_inv_1_0__9 -
                  jac_affine_inv_2_0__9) +
             jac_affine_inv_1_1__9 *
                 (-1.0 * jac_affine_inv_0_1__9 - jac_affine_inv_1_1__9 -
                  jac_affine_inv_2_1__9) +
             jac_affine_inv_1_2__9 *
                 (-1.0 * jac_affine_inv_0_2__9 - jac_affine_inv_1_2__9 -
                  jac_affine_inv_2_2__9)),
        abs_det_jac_affine__9 *
            (jac_affine_inv_2_0__9 *
                 (-1.0 * jac_affine_inv_0_0__9 - jac_affine_inv_1_0__9 -
                  jac_affine_inv_2_0__9) +
             jac_affine_inv_2_1__9 *
                 (-1.0 * jac_affine_inv_0_1__9 - jac_affine_inv_1_1__9 -
                  jac_affine_inv_2_1__9) +
             jac_affine_inv_2_2__9 *
                 (-1.0 * jac_affine_inv_0_2__9 - jac_affine_inv_1_2__9 -
                  jac_affine_inv_2_2__9)),
        abs_det_jac_affine__9 * (jac_affine_inv_0_0__9 * jac_affine_inv_0_0__9 +
                                 jac_affine_inv_0_1__9 * jac_affine_inv_0_1__9 +
                                 jac_affine_inv_0_2__9 * jac_affine_inv_0_2__9),
        abs_det_jac_affine__9 * (jac_affine_inv_0_0__9 * jac_affine_inv_1_0__9 +
                                 jac_affine_inv_0_1__9 * jac_affine_inv_1_1__9 +
                                 jac_affine_inv_0_2__9 * jac_affine_inv_1_2__9),
        abs_det_jac_affine__9 * (jac_affine_inv_0_0__9 * jac_affine_inv_2_0__9 +
                                 jac_affine_inv_0_1__9 * jac_affine_inv_2_1__9 +
                                 jac_affine_inv_0_2__9 * jac_affine_inv_2_2__9),
        abs_det_jac_affine__9 * (jac_affine_inv_1_0__9 * jac_affine_inv_1_0__9 +
                                 jac_affine_inv_1_1__9 * jac_affine_inv_1_1__9 +
                                 jac_affine_inv_1_2__9 * jac_affine_inv_1_2__9),
        abs_det_jac_affine__9 * (jac_affine_inv_1_0__9 * jac_affine_inv_2_0__9 +
                                 jac_affine_inv_1_1__9 * jac_affine_inv_2_1__9 +
                                 jac_affine_inv_1_2__9 * jac_affine_inv_2_2__9),
        abs_det_jac_affine__9 *
            (jac_affine_inv_2_0__9 * jac_affine_inv_2_0__9 +
             jac_affine_inv_2_1__9 * jac_affine_inv_2_1__9 +
             jac_affine_inv_2_2__9 * jac_affine_inv_2_2__9)};
    const double tmp_coords_jac_0__8 =
        macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_1__8 =
        1.0 * (1.0 / micro_edges_per_macro_edge_float);
    const double tmp_coords_jac_2__8 = tmp_coords_jac_1__8 * 0.0;
    const double tmp_coords_jac_3__8 =
        tmp_coords_jac_0__8 * tmp_coords_jac_2__8;
    const double tmp_coords_jac_4__8 =
        macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_5__8 = tmp_coords_jac_1__8 * 1.0;
    const double tmp_coords_jac_6__8 =
        tmp_coords_jac_4__8 * tmp_coords_jac_5__8;
    const double tmp_coords_jac_7__8 =
        macro_vertex_coord_id_3comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_8__8 =
        macro_vertex_coord_id_0comp0 +
        tmp_coords_jac_2__8 * tmp_coords_jac_7__8;
    const double tmp_coords_jac_9__8 =
        tmp_coords_jac_6__8 + tmp_coords_jac_8__8;
    const double tmp_coords_jac_10__8 =
        macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_11__8 =
        tmp_coords_jac_10__8 * tmp_coords_jac_2__8;
    const double tmp_coords_jac_12__8 =
        macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_13__8 =
        tmp_coords_jac_12__8 * tmp_coords_jac_5__8;
    const double tmp_coords_jac_14__8 =
        macro_vertex_coord_id_3comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_15__8 =
        macro_vertex_coord_id_0comp1 +
        tmp_coords_jac_14__8 * tmp_coords_jac_2__8;
    const double tmp_coords_jac_16__8 =
        tmp_coords_jac_13__8 + tmp_coords_jac_15__8;
    const double tmp_coords_jac_17__8 =
        macro_vertex_coord_id_2comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_18__8 =
        tmp_coords_jac_17__8 * tmp_coords_jac_2__8;
    const double tmp_coords_jac_19__8 =
        macro_vertex_coord_id_1comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_20__8 =
        tmp_coords_jac_19__8 * tmp_coords_jac_5__8;
    const double tmp_coords_jac_21__8 =
        macro_vertex_coord_id_3comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_22__8 =
        macro_vertex_coord_id_0comp2 +
        tmp_coords_jac_2__8 * tmp_coords_jac_21__8;
    const double tmp_coords_jac_23__8 =
        tmp_coords_jac_20__8 + tmp_coords_jac_22__8;
    const double tmp_coords_jac_24__8 =
        tmp_coords_jac_0__8 * tmp_coords_jac_5__8;
    const double tmp_coords_jac_25__8 =
        tmp_coords_jac_10__8 * tmp_coords_jac_5__8;
    const double tmp_coords_jac_26__8 =
        tmp_coords_jac_17__8 * tmp_coords_jac_5__8;
    const double p_affine_const_0_0__8 =
        tmp_coords_jac_3__8 + tmp_coords_jac_9__8;
    const double p_affine_const_0_1__8 =
        tmp_coords_jac_11__8 + tmp_coords_jac_16__8;
    const double p_affine_const_0_2__8 =
        tmp_coords_jac_18__8 + tmp_coords_jac_23__8;
    const double p_affine_const_1_0__8 =
        tmp_coords_jac_24__8 + tmp_coords_jac_8__8 +
        tmp_coords_jac_2__8 * tmp_coords_jac_4__8;
    const double p_affine_const_1_1__8 =
        tmp_coords_jac_15__8 + tmp_coords_jac_25__8 +
        tmp_coords_jac_12__8 * tmp_coords_jac_2__8;
    const double p_affine_const_1_2__8 =
        tmp_coords_jac_22__8 + tmp_coords_jac_26__8 +
        tmp_coords_jac_19__8 * tmp_coords_jac_2__8;
    const double p_affine_const_2_0__8 =
        tmp_coords_jac_24__8 + tmp_coords_jac_9__8;
    const double p_affine_const_2_1__8 =
        tmp_coords_jac_16__8 + tmp_coords_jac_25__8;
    const double p_affine_const_2_2__8 =
        tmp_coords_jac_23__8 + tmp_coords_jac_26__8;
    const double p_affine_const_3_0__8 =
        macro_vertex_coord_id_0comp0 + tmp_coords_jac_3__8 +
        tmp_coords_jac_6__8 + tmp_coords_jac_5__8 * tmp_coords_jac_7__8;
    const double p_affine_const_3_1__8 =
        macro_vertex_coord_id_0comp1 + tmp_coords_jac_11__8 +
        tmp_coords_jac_13__8 + tmp_coords_jac_14__8 * tmp_coords_jac_5__8;
    const double p_affine_const_3_2__8 =
        macro_vertex_coord_id_0comp2 + tmp_coords_jac_18__8 +
        tmp_coords_jac_20__8 + tmp_coords_jac_21__8 * tmp_coords_jac_5__8;
    const double jac_affine_0_0__8 =
        p_affine_const_1_0__8 - p_affine_const_0_0__8;
    const double jac_affine_0_1__8 =
        p_affine_const_2_0__8 - p_affine_const_0_0__8;
    const double jac_affine_0_2__8 =
        p_affine_const_3_0__8 - p_affine_const_0_0__8;
    const double jac_affine_1_0__8 =
        p_affine_const_1_1__8 - p_affine_const_0_1__8;
    const double jac_affine_1_1__8 =
        p_affine_const_2_1__8 - p_affine_const_0_1__8;
    const double tmp_coords_jac_31__6 = jac_affine_0_2__8 * jac_affine_1_1__8;
    const double jac_affine_1_2__8 =
        p_affine_const_3_1__8 - p_affine_const_0_1__8;
    const double tmp_coords_jac_29__8 = jac_affine_0_1__8 * jac_affine_1_2__8;
    const double jac_affine_2_0__8 =
        p_affine_const_1_2__8 - p_affine_const_0_2__8;
    const double jac_affine_2_1__8 =
        p_affine_const_2_2__8 - p_affine_const_0_2__8;
    const double tmp_coords_jac_28__8 = jac_affine_1_2__8 * jac_affine_2_1__8;
    const double jac_affine_2_2__8 =
        p_affine_const_3_2__8 - p_affine_const_0_2__8;
    const double tmp_coords_jac_27__8 = jac_affine_1_1__8 * jac_affine_2_2__8;
    const double tmp_coords_jac_30__8 = jac_affine_0_1__8 * jac_affine_2_2__8;
    const double tmp_coords_jac_32__6 =
        jac_affine_0_0__8 * tmp_coords_jac_27__8 +
        jac_affine_2_0__8 * tmp_coords_jac_29__8 -
        jac_affine_0_0__8 * tmp_coords_jac_28__8 -
        jac_affine_1_0__8 * tmp_coords_jac_30__8 -
        jac_affine_2_0__8 * tmp_coords_jac_31__6 +
        jac_affine_0_2__8 * jac_affine_1_0__8 * jac_affine_2_1__8;
    const double tmp_coords_jac_33__6 = 1.0 / tmp_coords_jac_32__6;
    const double jac_affine_inv_0_0__8 =
        tmp_coords_jac_33__6 * (tmp_coords_jac_27__8 - tmp_coords_jac_28__8);
    const double jac_affine_inv_0_1__8 =
        tmp_coords_jac_33__6 *
        (-1.0 * tmp_coords_jac_30__8 + jac_affine_0_2__8 * jac_affine_2_1__8);
    const double jac_affine_inv_0_2__8 =
        tmp_coords_jac_33__6 * (tmp_coords_jac_29__8 - tmp_coords_jac_31__6);
    const double jac_affine_inv_1_0__8 =
        tmp_coords_jac_33__6 * (jac_affine_1_2__8 * jac_affine_2_0__8 -
                                jac_affine_1_0__8 * jac_affine_2_2__8);
    const double jac_affine_inv_1_1__8 =
        tmp_coords_jac_33__6 * (jac_affine_0_0__8 * jac_affine_2_2__8 -
                                jac_affine_0_2__8 * jac_affine_2_0__8);
    const double jac_affine_inv_1_2__8 =
        tmp_coords_jac_33__6 * (jac_affine_0_2__8 * jac_affine_1_0__8 -
                                jac_affine_0_0__8 * jac_affine_1_2__8);
    const double jac_affine_inv_2_0__8 =
        tmp_coords_jac_33__6 * (jac_affine_1_0__8 * jac_affine_2_1__8 -
                                jac_affine_1_1__8 * jac_affine_2_0__8);
    const double jac_affine_inv_2_1__8 =
        tmp_coords_jac_33__6 * (jac_affine_0_1__8 * jac_affine_2_0__8 -
                                jac_affine_0_0__8 * jac_affine_2_1__8);
    const double jac_affine_inv_2_2__8 =
        tmp_coords_jac_33__6 * (jac_affine_0_0__8 * jac_affine_1_1__8 -
                                jac_affine_0_1__8 * jac_affine_1_0__8);
    const double abs_det_jac_affine__8 = abs(tmp_coords_jac_32__6);
    double phi_0_0__8[4] = {0.25, 0.25, 0.25, 0.25};
    double tabulated_and_untitled_0_0__8[10] = {
        abs_det_jac_affine__8 *
            ((-1.0 * jac_affine_inv_0_0__8 - jac_affine_inv_1_0__8 -
              jac_affine_inv_2_0__8) *
                 (-1.0 * jac_affine_inv_0_0__8 - jac_affine_inv_1_0__8 -
                  jac_affine_inv_2_0__8) +
             (-1.0 * jac_affine_inv_0_1__8 - jac_affine_inv_1_1__8 -
              jac_affine_inv_2_1__8) *
                 (-1.0 * jac_affine_inv_0_1__8 - jac_affine_inv_1_1__8 -
                  jac_affine_inv_2_1__8) +
             (-1.0 * jac_affine_inv_0_2__8 - jac_affine_inv_1_2__8 -
              jac_affine_inv_2_2__8) *
                 (-1.0 * jac_affine_inv_0_2__8 - jac_affine_inv_1_2__8 -
                  jac_affine_inv_2_2__8)),
        abs_det_jac_affine__8 *
            (jac_affine_inv_0_0__8 *
                 (-1.0 * jac_affine_inv_0_0__8 - jac_affine_inv_1_0__8 -
                  jac_affine_inv_2_0__8) +
             jac_affine_inv_0_1__8 *
                 (-1.0 * jac_affine_inv_0_1__8 - jac_affine_inv_1_1__8 -
                  jac_affine_inv_2_1__8) +
             jac_affine_inv_0_2__8 *
                 (-1.0 * jac_affine_inv_0_2__8 - jac_affine_inv_1_2__8 -
                  jac_affine_inv_2_2__8)),
        abs_det_jac_affine__8 *
            (jac_affine_inv_1_0__8 *
                 (-1.0 * jac_affine_inv_0_0__8 - jac_affine_inv_1_0__8 -
                  jac_affine_inv_2_0__8) +
             jac_affine_inv_1_1__8 *
                 (-1.0 * jac_affine_inv_0_1__8 - jac_affine_inv_1_1__8 -
                  jac_affine_inv_2_1__8) +
             jac_affine_inv_1_2__8 *
                 (-1.0 * jac_affine_inv_0_2__8 - jac_affine_inv_1_2__8 -
                  jac_affine_inv_2_2__8)),
        abs_det_jac_affine__8 *
            (jac_affine_inv_2_0__8 *
                 (-1.0 * jac_affine_inv_0_0__8 - jac_affine_inv_1_0__8 -
                  jac_affine_inv_2_0__8) +
             jac_affine_inv_2_1__8 *
                 (-1.0 * jac_affine_inv_0_1__8 - jac_affine_inv_1_1__8 -
                  jac_affine_inv_2_1__8) +
             jac_affine_inv_2_2__8 *
                 (-1.0 * jac_affine_inv_0_2__8 - jac_affine_inv_1_2__8 -
                  jac_affine_inv_2_2__8)),
        abs_det_jac_affine__8 * (jac_affine_inv_0_0__8 * jac_affine_inv_0_0__8 +
                                 jac_affine_inv_0_1__8 * jac_affine_inv_0_1__8 +
                                 jac_affine_inv_0_2__8 * jac_affine_inv_0_2__8),
        abs_det_jac_affine__8 * (jac_affine_inv_0_0__8 * jac_affine_inv_1_0__8 +
                                 jac_affine_inv_0_1__8 * jac_affine_inv_1_1__8 +
                                 jac_affine_inv_0_2__8 * jac_affine_inv_1_2__8),
        abs_det_jac_affine__8 * (jac_affine_inv_0_0__8 * jac_affine_inv_2_0__8 +
                                 jac_affine_inv_0_1__8 * jac_affine_inv_2_1__8 +
                                 jac_affine_inv_0_2__8 * jac_affine_inv_2_2__8),
        abs_det_jac_affine__8 * (jac_affine_inv_1_0__8 * jac_affine_inv_1_0__8 +
                                 jac_affine_inv_1_1__8 * jac_affine_inv_1_1__8 +
                                 jac_affine_inv_1_2__8 * jac_affine_inv_1_2__8),
        abs_det_jac_affine__8 * (jac_affine_inv_1_0__8 * jac_affine_inv_2_0__8 +
                                 jac_affine_inv_1_1__8 * jac_affine_inv_2_1__8 +
                                 jac_affine_inv_1_2__8 * jac_affine_inv_2_2__8),
        abs_det_jac_affine__8 *
            (jac_affine_inv_2_0__8 * jac_affine_inv_2_0__8 +
             jac_affine_inv_2_1__8 * jac_affine_inv_2_1__8 +
             jac_affine_inv_2_2__8 * jac_affine_inv_2_2__8)};
    const double tmp_coords_jac_0__7 =
        macro_vertex_coord_id_3comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_1__7 =
        1.0 * (1.0 / micro_edges_per_macro_edge_float);
    const double tmp_coords_jac_2__7 = tmp_coords_jac_1__7 * 0.0;
    const double tmp_coords_jac_3__7 =
        macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_4__7 = tmp_coords_jac_1__7 * 1.0;
    const double tmp_coords_jac_5__7 =
        macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_6__7 =
        macro_vertex_coord_id_0comp0 +
        tmp_coords_jac_2__7 * tmp_coords_jac_5__7;
    const double tmp_coords_jac_7__7 =
        tmp_coords_jac_6__7 + tmp_coords_jac_3__7 * tmp_coords_jac_4__7;
    const double tmp_coords_jac_8__7 =
        macro_vertex_coord_id_3comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_9__7 =
        macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_10__7 =
        macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_11__7 =
        macro_vertex_coord_id_0comp1 +
        tmp_coords_jac_10__7 * tmp_coords_jac_2__7;
    const double tmp_coords_jac_12__7 =
        tmp_coords_jac_11__7 + tmp_coords_jac_4__7 * tmp_coords_jac_9__7;
    const double tmp_coords_jac_13__7 =
        macro_vertex_coord_id_3comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_14__7 =
        macro_vertex_coord_id_2comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_15__7 =
        macro_vertex_coord_id_1comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_16__7 =
        macro_vertex_coord_id_0comp2 +
        tmp_coords_jac_15__7 * tmp_coords_jac_2__7;
    const double tmp_coords_jac_17__7 =
        tmp_coords_jac_16__7 + tmp_coords_jac_14__7 * tmp_coords_jac_4__7;
    const double tmp_coords_jac_18__7 =
        tmp_coords_jac_0__7 * tmp_coords_jac_4__7;
    const double tmp_coords_jac_19__7 =
        tmp_coords_jac_18__7 + tmp_coords_jac_2__7 * tmp_coords_jac_3__7;
    const double tmp_coords_jac_20__7 =
        tmp_coords_jac_4__7 * tmp_coords_jac_8__7;
    const double tmp_coords_jac_21__7 =
        tmp_coords_jac_20__7 + tmp_coords_jac_2__7 * tmp_coords_jac_9__7;
    const double tmp_coords_jac_22__7 =
        tmp_coords_jac_13__7 * tmp_coords_jac_4__7;
    const double tmp_coords_jac_23__7 =
        tmp_coords_jac_22__7 + tmp_coords_jac_14__7 * tmp_coords_jac_2__7;
    const double p_affine_const_0_0__7 =
        tmp_coords_jac_7__7 + tmp_coords_jac_0__7 * tmp_coords_jac_2__7;
    const double p_affine_const_0_1__7 =
        tmp_coords_jac_12__7 + tmp_coords_jac_2__7 * tmp_coords_jac_8__7;
    const double p_affine_const_0_2__7 =
        tmp_coords_jac_17__7 + tmp_coords_jac_13__7 * tmp_coords_jac_2__7;
    const double p_affine_const_1_0__7 =
        tmp_coords_jac_19__7 + tmp_coords_jac_6__7;
    const double p_affine_const_1_1__7 =
        tmp_coords_jac_11__7 + tmp_coords_jac_21__7;
    const double p_affine_const_1_2__7 =
        tmp_coords_jac_16__7 + tmp_coords_jac_23__7;
    const double p_affine_const_2_0__7 =
        macro_vertex_coord_id_0comp0 + tmp_coords_jac_19__7 +
        tmp_coords_jac_4__7 * tmp_coords_jac_5__7;
    const double p_affine_const_2_1__7 =
        macro_vertex_coord_id_0comp1 + tmp_coords_jac_21__7 +
        tmp_coords_jac_10__7 * tmp_coords_jac_4__7;
    const double p_affine_const_2_2__7 =
        macro_vertex_coord_id_0comp2 + tmp_coords_jac_23__7 +
        tmp_coords_jac_15__7 * tmp_coords_jac_4__7;
    const double p_affine_const_3_0__7 =
        tmp_coords_jac_18__7 + tmp_coords_jac_7__7;
    const double p_affine_const_3_1__7 =
        tmp_coords_jac_12__7 + tmp_coords_jac_20__7;
    const double p_affine_const_3_2__7 =
        tmp_coords_jac_17__7 + tmp_coords_jac_22__7;
    const double jac_affine_0_0__7 =
        p_affine_const_1_0__7 - p_affine_const_0_0__7;
    const double jac_affine_0_1__7 =
        p_affine_const_2_0__7 - p_affine_const_0_0__7;
    const double jac_affine_0_2__7 =
        p_affine_const_3_0__7 - p_affine_const_0_0__7;
    const double jac_affine_1_0__7 =
        p_affine_const_1_1__7 - p_affine_const_0_1__7;
    const double jac_affine_1_1__7 =
        p_affine_const_2_1__7 - p_affine_const_0_1__7;
    const double tmp_coords_jac_28__7 = jac_affine_0_2__7 * jac_affine_1_1__7;
    const double jac_affine_1_2__7 =
        p_affine_const_3_1__7 - p_affine_const_0_1__7;
    const double tmp_coords_jac_26__7 = jac_affine_0_1__7 * jac_affine_1_2__7;
    const double jac_affine_2_0__7 =
        p_affine_const_1_2__7 - p_affine_const_0_2__7;
    const double jac_affine_2_1__7 =
        p_affine_const_2_2__7 - p_affine_const_0_2__7;
    const double tmp_coords_jac_25__7 = jac_affine_1_2__7 * jac_affine_2_1__7;
    const double jac_affine_2_2__7 =
        p_affine_const_3_2__7 - p_affine_const_0_2__7;
    const double tmp_coords_jac_24__7 = jac_affine_1_1__7 * jac_affine_2_2__7;
    const double tmp_coords_jac_27__7 = jac_affine_0_1__7 * jac_affine_2_2__7;
    const double tmp_coords_jac_29__7 =
        jac_affine_0_0__7 * tmp_coords_jac_24__7 +
        jac_affine_2_0__7 * tmp_coords_jac_26__7 -
        jac_affine_0_0__7 * tmp_coords_jac_25__7 -
        jac_affine_1_0__7 * tmp_coords_jac_27__7 -
        jac_affine_2_0__7 * tmp_coords_jac_28__7 +
        jac_affine_0_2__7 * jac_affine_1_0__7 * jac_affine_2_1__7;
    const double tmp_coords_jac_30__7 = 1.0 / tmp_coords_jac_29__7;
    const double jac_affine_inv_0_0__7 =
        tmp_coords_jac_30__7 * (tmp_coords_jac_24__7 - tmp_coords_jac_25__7);
    const double jac_affine_inv_0_1__7 =
        tmp_coords_jac_30__7 *
        (-1.0 * tmp_coords_jac_27__7 + jac_affine_0_2__7 * jac_affine_2_1__7);
    const double jac_affine_inv_0_2__7 =
        tmp_coords_jac_30__7 * (tmp_coords_jac_26__7 - tmp_coords_jac_28__7);
    const double jac_affine_inv_1_0__7 =
        tmp_coords_jac_30__7 * (jac_affine_1_2__7 * jac_affine_2_0__7 -
                                jac_affine_1_0__7 * jac_affine_2_2__7);
    const double jac_affine_inv_1_1__7 =
        tmp_coords_jac_30__7 * (jac_affine_0_0__7 * jac_affine_2_2__7 -
                                jac_affine_0_2__7 * jac_affine_2_0__7);
    const double jac_affine_inv_1_2__7 =
        tmp_coords_jac_30__7 * (jac_affine_0_2__7 * jac_affine_1_0__7 -
                                jac_affine_0_0__7 * jac_affine_1_2__7);
    const double jac_affine_inv_2_0__7 =
        tmp_coords_jac_30__7 * (jac_affine_1_0__7 * jac_affine_2_1__7 -
                                jac_affine_1_1__7 * jac_affine_2_0__7);
    const double jac_affine_inv_2_1__7 =
        tmp_coords_jac_30__7 * (jac_affine_0_1__7 * jac_affine_2_0__7 -
                                jac_affine_0_0__7 * jac_affine_2_1__7);
    const double jac_affine_inv_2_2__7 =
        tmp_coords_jac_30__7 * (jac_affine_0_0__7 * jac_affine_1_1__7 -
                                jac_affine_0_1__7 * jac_affine_1_0__7);
    const double abs_det_jac_affine__7 = abs(tmp_coords_jac_29__7);
    double phi_0_0__7[4] = {0.25, 0.25, 0.25, 0.25};
    double tabulated_and_untitled_0_0__7[10] = {
        abs_det_jac_affine__7 *
            ((-1.0 * jac_affine_inv_0_0__7 - jac_affine_inv_1_0__7 -
              jac_affine_inv_2_0__7) *
                 (-1.0 * jac_affine_inv_0_0__7 - jac_affine_inv_1_0__7 -
                  jac_affine_inv_2_0__7) +
             (-1.0 * jac_affine_inv_0_1__7 - jac_affine_inv_1_1__7 -
              jac_affine_inv_2_1__7) *
                 (-1.0 * jac_affine_inv_0_1__7 - jac_affine_inv_1_1__7 -
                  jac_affine_inv_2_1__7) +
             (-1.0 * jac_affine_inv_0_2__7 - jac_affine_inv_1_2__7 -
              jac_affine_inv_2_2__7) *
                 (-1.0 * jac_affine_inv_0_2__7 - jac_affine_inv_1_2__7 -
                  jac_affine_inv_2_2__7)),
        abs_det_jac_affine__7 *
            (jac_affine_inv_0_0__7 *
                 (-1.0 * jac_affine_inv_0_0__7 - jac_affine_inv_1_0__7 -
                  jac_affine_inv_2_0__7) +
             jac_affine_inv_0_1__7 *
                 (-1.0 * jac_affine_inv_0_1__7 - jac_affine_inv_1_1__7 -
                  jac_affine_inv_2_1__7) +
             jac_affine_inv_0_2__7 *
                 (-1.0 * jac_affine_inv_0_2__7 - jac_affine_inv_1_2__7 -
                  jac_affine_inv_2_2__7)),
        abs_det_jac_affine__7 *
            (jac_affine_inv_1_0__7 *
                 (-1.0 * jac_affine_inv_0_0__7 - jac_affine_inv_1_0__7 -
                  jac_affine_inv_2_0__7) +
             jac_affine_inv_1_1__7 *
                 (-1.0 * jac_affine_inv_0_1__7 - jac_affine_inv_1_1__7 -
                  jac_affine_inv_2_1__7) +
             jac_affine_inv_1_2__7 *
                 (-1.0 * jac_affine_inv_0_2__7 - jac_affine_inv_1_2__7 -
                  jac_affine_inv_2_2__7)),
        abs_det_jac_affine__7 *
            (jac_affine_inv_2_0__7 *
                 (-1.0 * jac_affine_inv_0_0__7 - jac_affine_inv_1_0__7 -
                  jac_affine_inv_2_0__7) +
             jac_affine_inv_2_1__7 *
                 (-1.0 * jac_affine_inv_0_1__7 - jac_affine_inv_1_1__7 -
                  jac_affine_inv_2_1__7) +
             jac_affine_inv_2_2__7 *
                 (-1.0 * jac_affine_inv_0_2__7 - jac_affine_inv_1_2__7 -
                  jac_affine_inv_2_2__7)),
        abs_det_jac_affine__7 * (jac_affine_inv_0_0__7 * jac_affine_inv_0_0__7 +
                                 jac_affine_inv_0_1__7 * jac_affine_inv_0_1__7 +
                                 jac_affine_inv_0_2__7 * jac_affine_inv_0_2__7),
        abs_det_jac_affine__7 * (jac_affine_inv_0_0__7 * jac_affine_inv_1_0__7 +
                                 jac_affine_inv_0_1__7 * jac_affine_inv_1_1__7 +
                                 jac_affine_inv_0_2__7 * jac_affine_inv_1_2__7),
        abs_det_jac_affine__7 * (jac_affine_inv_0_0__7 * jac_affine_inv_2_0__7 +
                                 jac_affine_inv_0_1__7 * jac_affine_inv_2_1__7 +
                                 jac_affine_inv_0_2__7 * jac_affine_inv_2_2__7),
        abs_det_jac_affine__7 * (jac_affine_inv_1_0__7 * jac_affine_inv_1_0__7 +
                                 jac_affine_inv_1_1__7 * jac_affine_inv_1_1__7 +
                                 jac_affine_inv_1_2__7 * jac_affine_inv_1_2__7),
        abs_det_jac_affine__7 * (jac_affine_inv_1_0__7 * jac_affine_inv_2_0__7 +
                                 jac_affine_inv_1_1__7 * jac_affine_inv_2_1__7 +
                                 jac_affine_inv_1_2__7 * jac_affine_inv_2_2__7),
        abs_det_jac_affine__7 *
            (jac_affine_inv_2_0__7 * jac_affine_inv_2_0__7 +
             jac_affine_inv_2_1__7 * jac_affine_inv_2_1__7 +
             jac_affine_inv_2_2__7 * jac_affine_inv_2_2__7)};
    const double tmp_coords_jac_0__6 =
        macro_vertex_coord_id_3comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_1__6 =
        1.0 * (1.0 / micro_edges_per_macro_edge_float);
    const double tmp_coords_jac_2__6 = tmp_coords_jac_1__6 * 0.0;
    const double tmp_coords_jac_3__6 =
        macro_vertex_coord_id_0comp0 +
        tmp_coords_jac_0__6 * tmp_coords_jac_2__6;
    const double tmp_coords_jac_4__6 =
        macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_5__6 = tmp_coords_jac_1__6 * 1.0;
    const double tmp_coords_jac_6__6 =
        macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_7__6 =
        tmp_coords_jac_2__6 * tmp_coords_jac_6__6;
    const double tmp_coords_jac_8__6 =
        tmp_coords_jac_7__6 + tmp_coords_jac_4__6 * tmp_coords_jac_5__6;
    const double tmp_coords_jac_9__6 =
        macro_vertex_coord_id_3comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_10__6 =
        macro_vertex_coord_id_0comp1 +
        tmp_coords_jac_2__6 * tmp_coords_jac_9__6;
    const double tmp_coords_jac_11__6 =
        macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_12__6 =
        macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_13__6 =
        tmp_coords_jac_12__6 * tmp_coords_jac_2__6;
    const double tmp_coords_jac_14__6 =
        tmp_coords_jac_13__6 + tmp_coords_jac_11__6 * tmp_coords_jac_5__6;
    const double tmp_coords_jac_15__6 =
        macro_vertex_coord_id_3comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_16__6 =
        macro_vertex_coord_id_0comp2 +
        tmp_coords_jac_15__6 * tmp_coords_jac_2__6;
    const double tmp_coords_jac_17__6 =
        macro_vertex_coord_id_1comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_18__6 =
        macro_vertex_coord_id_2comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_19__6 =
        tmp_coords_jac_18__6 * tmp_coords_jac_2__6;
    const double tmp_coords_jac_20__6 =
        tmp_coords_jac_19__6 + tmp_coords_jac_17__6 * tmp_coords_jac_5__6;
    const double tmp_coords_jac_21__6 =
        tmp_coords_jac_2__6 * tmp_coords_jac_4__6;
    const double tmp_coords_jac_22__6 =
        tmp_coords_jac_11__6 * tmp_coords_jac_2__6;
    const double tmp_coords_jac_23__6 =
        tmp_coords_jac_17__6 * tmp_coords_jac_2__6;
    const double tmp_coords_jac_24__6 =
        macro_vertex_coord_id_0comp0 +
        tmp_coords_jac_0__6 * tmp_coords_jac_5__6;
    const double tmp_coords_jac_25__6 =
        macro_vertex_coord_id_0comp1 +
        tmp_coords_jac_5__6 * tmp_coords_jac_9__6;
    const double tmp_coords_jac_26__6 =
        macro_vertex_coord_id_0comp2 +
        tmp_coords_jac_15__6 * tmp_coords_jac_5__6;
    const double p_affine_const_0_0__6 =
        tmp_coords_jac_3__6 + tmp_coords_jac_8__6;
    const double p_affine_const_0_1__6 =
        tmp_coords_jac_10__6 + tmp_coords_jac_14__6;
    const double p_affine_const_0_2__6 =
        tmp_coords_jac_16__6 + tmp_coords_jac_20__6;
    const double p_affine_const_1_0__6 =
        tmp_coords_jac_21__6 + tmp_coords_jac_3__6 +
        tmp_coords_jac_5__6 * tmp_coords_jac_6__6;
    const double p_affine_const_1_1__6 =
        tmp_coords_jac_10__6 + tmp_coords_jac_22__6 +
        tmp_coords_jac_12__6 * tmp_coords_jac_5__6;
    const double p_affine_const_1_2__6 =
        tmp_coords_jac_16__6 + tmp_coords_jac_23__6 +
        tmp_coords_jac_18__6 * tmp_coords_jac_5__6;
    const double p_affine_const_2_0__6 =
        tmp_coords_jac_21__6 + tmp_coords_jac_24__6 + tmp_coords_jac_7__6;
    const double p_affine_const_2_1__6 =
        tmp_coords_jac_13__6 + tmp_coords_jac_22__6 + tmp_coords_jac_25__6;
    const double p_affine_const_2_2__6 =
        tmp_coords_jac_19__6 + tmp_coords_jac_23__6 + tmp_coords_jac_26__6;
    const double p_affine_const_3_0__6 =
        tmp_coords_jac_24__6 + tmp_coords_jac_8__6;
    const double p_affine_const_3_1__6 =
        tmp_coords_jac_14__6 + tmp_coords_jac_25__6;
    const double p_affine_const_3_2__6 =
        tmp_coords_jac_20__6 + tmp_coords_jac_26__6;
    const double jac_affine_0_0__6 =
        p_affine_const_1_0__6 - p_affine_const_0_0__6;
    const double jac_affine_0_1__6 =
        p_affine_const_2_0__6 - p_affine_const_0_0__6;
    const double jac_affine_0_2__6 =
        p_affine_const_3_0__6 - p_affine_const_0_0__6;
    const double jac_affine_1_0__6 =
        p_affine_const_1_1__6 - p_affine_const_0_1__6;
    const double jac_affine_1_1__6 =
        p_affine_const_2_1__6 - p_affine_const_0_1__6;
    const double tmp_coords_jac_31__5 = jac_affine_0_2__6 * jac_affine_1_1__6;
    const double jac_affine_1_2__6 =
        p_affine_const_3_1__6 - p_affine_const_0_1__6;
    const double tmp_coords_jac_29__6 = jac_affine_0_1__6 * jac_affine_1_2__6;
    const double jac_affine_2_0__6 =
        p_affine_const_1_2__6 - p_affine_const_0_2__6;
    const double jac_affine_2_1__6 =
        p_affine_const_2_2__6 - p_affine_const_0_2__6;
    const double tmp_coords_jac_28__6 = jac_affine_1_2__6 * jac_affine_2_1__6;
    const double jac_affine_2_2__6 =
        p_affine_const_3_2__6 - p_affine_const_0_2__6;
    const double tmp_coords_jac_27__6 = jac_affine_1_1__6 * jac_affine_2_2__6;
    const double tmp_coords_jac_30__6 = jac_affine_0_1__6 * jac_affine_2_2__6;
    const double tmp_coords_jac_32__5 =
        jac_affine_0_0__6 * tmp_coords_jac_27__6 +
        jac_affine_2_0__6 * tmp_coords_jac_29__6 -
        jac_affine_0_0__6 * tmp_coords_jac_28__6 -
        jac_affine_1_0__6 * tmp_coords_jac_30__6 -
        jac_affine_2_0__6 * tmp_coords_jac_31__5 +
        jac_affine_0_2__6 * jac_affine_1_0__6 * jac_affine_2_1__6;
    const double tmp_coords_jac_33__5 = 1.0 / tmp_coords_jac_32__5;
    const double jac_affine_inv_0_0__6 =
        tmp_coords_jac_33__5 * (tmp_coords_jac_27__6 - tmp_coords_jac_28__6);
    const double jac_affine_inv_0_1__6 =
        tmp_coords_jac_33__5 *
        (-1.0 * tmp_coords_jac_30__6 + jac_affine_0_2__6 * jac_affine_2_1__6);
    const double jac_affine_inv_0_2__6 =
        tmp_coords_jac_33__5 * (tmp_coords_jac_29__6 - tmp_coords_jac_31__5);
    const double jac_affine_inv_1_0__6 =
        tmp_coords_jac_33__5 * (jac_affine_1_2__6 * jac_affine_2_0__6 -
                                jac_affine_1_0__6 * jac_affine_2_2__6);
    const double jac_affine_inv_1_1__6 =
        tmp_coords_jac_33__5 * (jac_affine_0_0__6 * jac_affine_2_2__6 -
                                jac_affine_0_2__6 * jac_affine_2_0__6);
    const double jac_affine_inv_1_2__6 =
        tmp_coords_jac_33__5 * (jac_affine_0_2__6 * jac_affine_1_0__6 -
                                jac_affine_0_0__6 * jac_affine_1_2__6);
    const double jac_affine_inv_2_0__6 =
        tmp_coords_jac_33__5 * (jac_affine_1_0__6 * jac_affine_2_1__6 -
                                jac_affine_1_1__6 * jac_affine_2_0__6);
    const double jac_affine_inv_2_1__6 =
        tmp_coords_jac_33__5 * (jac_affine_0_1__6 * jac_affine_2_0__6 -
                                jac_affine_0_0__6 * jac_affine_2_1__6);
    const double jac_affine_inv_2_2__6 =
        tmp_coords_jac_33__5 * (jac_affine_0_0__6 * jac_affine_1_1__6 -
                                jac_affine_0_1__6 * jac_affine_1_0__6);
    const double abs_det_jac_affine__6 = abs(tmp_coords_jac_32__5);
    double phi_0_0__6[4] = {0.25, 0.25, 0.25, 0.25};
    double tabulated_and_untitled_0_0__6[10] = {
        abs_det_jac_affine__6 *
            ((-1.0 * jac_affine_inv_0_0__6 - jac_affine_inv_1_0__6 -
              jac_affine_inv_2_0__6) *
                 (-1.0 * jac_affine_inv_0_0__6 - jac_affine_inv_1_0__6 -
                  jac_affine_inv_2_0__6) +
             (-1.0 * jac_affine_inv_0_1__6 - jac_affine_inv_1_1__6 -
              jac_affine_inv_2_1__6) *
                 (-1.0 * jac_affine_inv_0_1__6 - jac_affine_inv_1_1__6 -
                  jac_affine_inv_2_1__6) +
             (-1.0 * jac_affine_inv_0_2__6 - jac_affine_inv_1_2__6 -
              jac_affine_inv_2_2__6) *
                 (-1.0 * jac_affine_inv_0_2__6 - jac_affine_inv_1_2__6 -
                  jac_affine_inv_2_2__6)),
        abs_det_jac_affine__6 *
            (jac_affine_inv_0_0__6 *
                 (-1.0 * jac_affine_inv_0_0__6 - jac_affine_inv_1_0__6 -
                  jac_affine_inv_2_0__6) +
             jac_affine_inv_0_1__6 *
                 (-1.0 * jac_affine_inv_0_1__6 - jac_affine_inv_1_1__6 -
                  jac_affine_inv_2_1__6) +
             jac_affine_inv_0_2__6 *
                 (-1.0 * jac_affine_inv_0_2__6 - jac_affine_inv_1_2__6 -
                  jac_affine_inv_2_2__6)),
        abs_det_jac_affine__6 *
            (jac_affine_inv_1_0__6 *
                 (-1.0 * jac_affine_inv_0_0__6 - jac_affine_inv_1_0__6 -
                  jac_affine_inv_2_0__6) +
             jac_affine_inv_1_1__6 *
                 (-1.0 * jac_affine_inv_0_1__6 - jac_affine_inv_1_1__6 -
                  jac_affine_inv_2_1__6) +
             jac_affine_inv_1_2__6 *
                 (-1.0 * jac_affine_inv_0_2__6 - jac_affine_inv_1_2__6 -
                  jac_affine_inv_2_2__6)),
        abs_det_jac_affine__6 *
            (jac_affine_inv_2_0__6 *
                 (-1.0 * jac_affine_inv_0_0__6 - jac_affine_inv_1_0__6 -
                  jac_affine_inv_2_0__6) +
             jac_affine_inv_2_1__6 *
                 (-1.0 * jac_affine_inv_0_1__6 - jac_affine_inv_1_1__6 -
                  jac_affine_inv_2_1__6) +
             jac_affine_inv_2_2__6 *
                 (-1.0 * jac_affine_inv_0_2__6 - jac_affine_inv_1_2__6 -
                  jac_affine_inv_2_2__6)),
        abs_det_jac_affine__6 * (jac_affine_inv_0_0__6 * jac_affine_inv_0_0__6 +
                                 jac_affine_inv_0_1__6 * jac_affine_inv_0_1__6 +
                                 jac_affine_inv_0_2__6 * jac_affine_inv_0_2__6),
        abs_det_jac_affine__6 * (jac_affine_inv_0_0__6 * jac_affine_inv_1_0__6 +
                                 jac_affine_inv_0_1__6 * jac_affine_inv_1_1__6 +
                                 jac_affine_inv_0_2__6 * jac_affine_inv_1_2__6),
        abs_det_jac_affine__6 * (jac_affine_inv_0_0__6 * jac_affine_inv_2_0__6 +
                                 jac_affine_inv_0_1__6 * jac_affine_inv_2_1__6 +
                                 jac_affine_inv_0_2__6 * jac_affine_inv_2_2__6),
        abs_det_jac_affine__6 * (jac_affine_inv_1_0__6 * jac_affine_inv_1_0__6 +
                                 jac_affine_inv_1_1__6 * jac_affine_inv_1_1__6 +
                                 jac_affine_inv_1_2__6 * jac_affine_inv_1_2__6),
        abs_det_jac_affine__6 * (jac_affine_inv_1_0__6 * jac_affine_inv_2_0__6 +
                                 jac_affine_inv_1_1__6 * jac_affine_inv_2_1__6 +
                                 jac_affine_inv_1_2__6 * jac_affine_inv_2_2__6),
        abs_det_jac_affine__6 *
            (jac_affine_inv_2_0__6 * jac_affine_inv_2_0__6 +
             jac_affine_inv_2_1__6 * jac_affine_inv_2_1__6 +
             jac_affine_inv_2_2__6 * jac_affine_inv_2_2__6)};
    const double tmp_coords_jac_0__5 =
        macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_1__5 =
        1.0 * (1.0 / micro_edges_per_macro_edge_float);
    const double tmp_coords_jac_2__5 = tmp_coords_jac_1__5 * 0.0;
    const double tmp_coords_jac_3__5 =
        tmp_coords_jac_0__5 * tmp_coords_jac_2__5;
    const double tmp_coords_jac_4__5 =
        macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_5__5 = tmp_coords_jac_1__5 * 1.0;
    const double tmp_coords_jac_6__5 =
        tmp_coords_jac_4__5 * tmp_coords_jac_5__5;
    const double tmp_coords_jac_7__5 =
        macro_vertex_coord_id_3comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_8__5 =
        macro_vertex_coord_id_0comp0 + tmp_coords_jac_6__5 +
        tmp_coords_jac_2__5 * tmp_coords_jac_7__5;
    const double tmp_coords_jac_9__5 =
        macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_10__5 =
        tmp_coords_jac_2__5 * tmp_coords_jac_9__5;
    const double tmp_coords_jac_11__5 =
        macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_12__5 =
        tmp_coords_jac_11__5 * tmp_coords_jac_5__5;
    const double tmp_coords_jac_13__5 =
        macro_vertex_coord_id_3comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_14__5 =
        macro_vertex_coord_id_0comp1 + tmp_coords_jac_12__5 +
        tmp_coords_jac_13__5 * tmp_coords_jac_2__5;
    const double tmp_coords_jac_15__5 =
        macro_vertex_coord_id_1comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_16__5 =
        tmp_coords_jac_15__5 * tmp_coords_jac_2__5;
    const double tmp_coords_jac_17__5 =
        macro_vertex_coord_id_2comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_18__5 =
        tmp_coords_jac_17__5 * tmp_coords_jac_5__5;
    const double tmp_coords_jac_19__5 =
        macro_vertex_coord_id_3comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_20__5 =
        macro_vertex_coord_id_0comp2 + tmp_coords_jac_18__5 +
        tmp_coords_jac_19__5 * tmp_coords_jac_2__5;
    const double tmp_coords_jac_21__5 =
        tmp_coords_jac_0__5 * tmp_coords_jac_5__5;
    const double tmp_coords_jac_22__5 =
        tmp_coords_jac_5__5 * tmp_coords_jac_9__5;
    const double tmp_coords_jac_23__5 =
        tmp_coords_jac_15__5 * tmp_coords_jac_5__5;
    const double tmp_coords_jac_24__5 =
        macro_vertex_coord_id_0comp0 +
        tmp_coords_jac_5__5 * tmp_coords_jac_7__5;
    const double tmp_coords_jac_25__5 =
        macro_vertex_coord_id_0comp1 +
        tmp_coords_jac_13__5 * tmp_coords_jac_5__5;
    const double tmp_coords_jac_26__5 =
        macro_vertex_coord_id_0comp2 +
        tmp_coords_jac_19__5 * tmp_coords_jac_5__5;
    const double p_affine_const_0_0__5 =
        tmp_coords_jac_3__5 + tmp_coords_jac_8__5;
    const double p_affine_const_0_1__5 =
        tmp_coords_jac_10__5 + tmp_coords_jac_14__5;
    const double p_affine_const_0_2__5 =
        tmp_coords_jac_16__5 + tmp_coords_jac_20__5;
    const double p_affine_const_1_0__5 =
        tmp_coords_jac_21__5 + tmp_coords_jac_8__5;
    const double p_affine_const_1_1__5 =
        tmp_coords_jac_14__5 + tmp_coords_jac_22__5;
    const double p_affine_const_1_2__5 =
        tmp_coords_jac_20__5 + tmp_coords_jac_23__5;
    const double p_affine_const_2_0__5 =
        tmp_coords_jac_21__5 + tmp_coords_jac_24__5 +
        tmp_coords_jac_2__5 * tmp_coords_jac_4__5;
    const double p_affine_const_2_1__5 =
        tmp_coords_jac_22__5 + tmp_coords_jac_25__5 +
        tmp_coords_jac_11__5 * tmp_coords_jac_2__5;
    const double p_affine_const_2_2__5 =
        tmp_coords_jac_23__5 + tmp_coords_jac_26__5 +
        tmp_coords_jac_17__5 * tmp_coords_jac_2__5;
    const double p_affine_const_3_0__5 =
        tmp_coords_jac_24__5 + tmp_coords_jac_3__5 + tmp_coords_jac_6__5;
    const double p_affine_const_3_1__5 =
        tmp_coords_jac_10__5 + tmp_coords_jac_12__5 + tmp_coords_jac_25__5;
    const double p_affine_const_3_2__5 =
        tmp_coords_jac_16__5 + tmp_coords_jac_18__5 + tmp_coords_jac_26__5;
    const double jac_affine_0_0__5 =
        p_affine_const_1_0__5 - p_affine_const_0_0__5;
    const double jac_affine_0_1__5 =
        p_affine_const_2_0__5 - p_affine_const_0_0__5;
    const double jac_affine_0_2__5 =
        p_affine_const_3_0__5 - p_affine_const_0_0__5;
    const double jac_affine_1_0__5 =
        p_affine_const_1_1__5 - p_affine_const_0_1__5;
    const double jac_affine_1_1__5 =
        p_affine_const_2_1__5 - p_affine_const_0_1__5;
    const double tmp_coords_jac_31__4 = jac_affine_0_2__5 * jac_affine_1_1__5;
    const double jac_affine_1_2__5 =
        p_affine_const_3_1__5 - p_affine_const_0_1__5;
    const double tmp_coords_jac_29__5 = jac_affine_0_1__5 * jac_affine_1_2__5;
    const double jac_affine_2_0__5 =
        p_affine_const_1_2__5 - p_affine_const_0_2__5;
    const double jac_affine_2_1__5 =
        p_affine_const_2_2__5 - p_affine_const_0_2__5;
    const double tmp_coords_jac_28__5 = jac_affine_1_2__5 * jac_affine_2_1__5;
    const double jac_affine_2_2__5 =
        p_affine_const_3_2__5 - p_affine_const_0_2__5;
    const double tmp_coords_jac_27__5 = jac_affine_1_1__5 * jac_affine_2_2__5;
    const double tmp_coords_jac_30__5 = jac_affine_0_1__5 * jac_affine_2_2__5;
    const double tmp_coords_jac_32__4 =
        jac_affine_0_0__5 * tmp_coords_jac_27__5 +
        jac_affine_2_0__5 * tmp_coords_jac_29__5 -
        jac_affine_0_0__5 * tmp_coords_jac_28__5 -
        jac_affine_1_0__5 * tmp_coords_jac_30__5 -
        jac_affine_2_0__5 * tmp_coords_jac_31__4 +
        jac_affine_0_2__5 * jac_affine_1_0__5 * jac_affine_2_1__5;
    const double tmp_coords_jac_33__4 = 1.0 / tmp_coords_jac_32__4;
    const double jac_affine_inv_0_0__5 =
        tmp_coords_jac_33__4 * (tmp_coords_jac_27__5 - tmp_coords_jac_28__5);
    const double jac_affine_inv_0_1__5 =
        tmp_coords_jac_33__4 *
        (-1.0 * tmp_coords_jac_30__5 + jac_affine_0_2__5 * jac_affine_2_1__5);
    const double jac_affine_inv_0_2__5 =
        tmp_coords_jac_33__4 * (tmp_coords_jac_29__5 - tmp_coords_jac_31__4);
    const double jac_affine_inv_1_0__5 =
        tmp_coords_jac_33__4 * (jac_affine_1_2__5 * jac_affine_2_0__5 -
                                jac_affine_1_0__5 * jac_affine_2_2__5);
    const double jac_affine_inv_1_1__5 =
        tmp_coords_jac_33__4 * (jac_affine_0_0__5 * jac_affine_2_2__5 -
                                jac_affine_0_2__5 * jac_affine_2_0__5);
    const double jac_affine_inv_1_2__5 =
        tmp_coords_jac_33__4 * (jac_affine_0_2__5 * jac_affine_1_0__5 -
                                jac_affine_0_0__5 * jac_affine_1_2__5);
    const double jac_affine_inv_2_0__5 =
        tmp_coords_jac_33__4 * (jac_affine_1_0__5 * jac_affine_2_1__5 -
                                jac_affine_1_1__5 * jac_affine_2_0__5);
    const double jac_affine_inv_2_1__5 =
        tmp_coords_jac_33__4 * (jac_affine_0_1__5 * jac_affine_2_0__5 -
                                jac_affine_0_0__5 * jac_affine_2_1__5);
    const double jac_affine_inv_2_2__5 =
        tmp_coords_jac_33__4 * (jac_affine_0_0__5 * jac_affine_1_1__5 -
                                jac_affine_0_1__5 * jac_affine_1_0__5);
    const double abs_det_jac_affine__5 = abs(tmp_coords_jac_32__4);
    double phi_0_0__5[4] = {0.25, 0.25, 0.25, 0.25};
    double tabulated_and_untitled_0_0__5[10] = {
        abs_det_jac_affine__5 *
            ((-1.0 * jac_affine_inv_0_0__5 - jac_affine_inv_1_0__5 -
              jac_affine_inv_2_0__5) *
                 (-1.0 * jac_affine_inv_0_0__5 - jac_affine_inv_1_0__5 -
                  jac_affine_inv_2_0__5) +
             (-1.0 * jac_affine_inv_0_1__5 - jac_affine_inv_1_1__5 -
              jac_affine_inv_2_1__5) *
                 (-1.0 * jac_affine_inv_0_1__5 - jac_affine_inv_1_1__5 -
                  jac_affine_inv_2_1__5) +
             (-1.0 * jac_affine_inv_0_2__5 - jac_affine_inv_1_2__5 -
              jac_affine_inv_2_2__5) *
                 (-1.0 * jac_affine_inv_0_2__5 - jac_affine_inv_1_2__5 -
                  jac_affine_inv_2_2__5)),
        abs_det_jac_affine__5 *
            (jac_affine_inv_0_0__5 *
                 (-1.0 * jac_affine_inv_0_0__5 - jac_affine_inv_1_0__5 -
                  jac_affine_inv_2_0__5) +
             jac_affine_inv_0_1__5 *
                 (-1.0 * jac_affine_inv_0_1__5 - jac_affine_inv_1_1__5 -
                  jac_affine_inv_2_1__5) +
             jac_affine_inv_0_2__5 *
                 (-1.0 * jac_affine_inv_0_2__5 - jac_affine_inv_1_2__5 -
                  jac_affine_inv_2_2__5)),
        abs_det_jac_affine__5 *
            (jac_affine_inv_1_0__5 *
                 (-1.0 * jac_affine_inv_0_0__5 - jac_affine_inv_1_0__5 -
                  jac_affine_inv_2_0__5) +
             jac_affine_inv_1_1__5 *
                 (-1.0 * jac_affine_inv_0_1__5 - jac_affine_inv_1_1__5 -
                  jac_affine_inv_2_1__5) +
             jac_affine_inv_1_2__5 *
                 (-1.0 * jac_affine_inv_0_2__5 - jac_affine_inv_1_2__5 -
                  jac_affine_inv_2_2__5)),
        abs_det_jac_affine__5 *
            (jac_affine_inv_2_0__5 *
                 (-1.0 * jac_affine_inv_0_0__5 - jac_affine_inv_1_0__5 -
                  jac_affine_inv_2_0__5) +
             jac_affine_inv_2_1__5 *
                 (-1.0 * jac_affine_inv_0_1__5 - jac_affine_inv_1_1__5 -
                  jac_affine_inv_2_1__5) +
             jac_affine_inv_2_2__5 *
                 (-1.0 * jac_affine_inv_0_2__5 - jac_affine_inv_1_2__5 -
                  jac_affine_inv_2_2__5)),
        abs_det_jac_affine__5 * (jac_affine_inv_0_0__5 * jac_affine_inv_0_0__5 +
                                 jac_affine_inv_0_1__5 * jac_affine_inv_0_1__5 +
                                 jac_affine_inv_0_2__5 * jac_affine_inv_0_2__5),
        abs_det_jac_affine__5 * (jac_affine_inv_0_0__5 * jac_affine_inv_1_0__5 +
                                 jac_affine_inv_0_1__5 * jac_affine_inv_1_1__5 +
                                 jac_affine_inv_0_2__5 * jac_affine_inv_1_2__5),
        abs_det_jac_affine__5 * (jac_affine_inv_0_0__5 * jac_affine_inv_2_0__5 +
                                 jac_affine_inv_0_1__5 * jac_affine_inv_2_1__5 +
                                 jac_affine_inv_0_2__5 * jac_affine_inv_2_2__5),
        abs_det_jac_affine__5 * (jac_affine_inv_1_0__5 * jac_affine_inv_1_0__5 +
                                 jac_affine_inv_1_1__5 * jac_affine_inv_1_1__5 +
                                 jac_affine_inv_1_2__5 * jac_affine_inv_1_2__5),
        abs_det_jac_affine__5 * (jac_affine_inv_1_0__5 * jac_affine_inv_2_0__5 +
                                 jac_affine_inv_1_1__5 * jac_affine_inv_2_1__5 +
                                 jac_affine_inv_1_2__5 * jac_affine_inv_2_2__5),
        abs_det_jac_affine__5 *
            (jac_affine_inv_2_0__5 * jac_affine_inv_2_0__5 +
             jac_affine_inv_2_1__5 * jac_affine_inv_2_1__5 +
             jac_affine_inv_2_2__5 * jac_affine_inv_2_2__5)};
    const double tmp_coords_jac_0 =
        macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_1 =
        1.0 * (1.0 / micro_edges_per_macro_edge_float);
    const double tmp_coords_jac_2 = tmp_coords_jac_1 * 0.0;
    const double tmp_coords_jac_3 = tmp_coords_jac_0 * tmp_coords_jac_2;
    const double tmp_coords_jac_4 =
        macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_5 = tmp_coords_jac_2 * tmp_coords_jac_4;
    const double tmp_coords_jac_6 =
        macro_vertex_coord_id_3comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_7 = tmp_coords_jac_2 * tmp_coords_jac_6;
    const double tmp_coords_jac_8 =
        macro_vertex_coord_id_0comp0 + tmp_coords_jac_5 + tmp_coords_jac_7;
    const double tmp_coords_jac_9 =
        macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_10 = tmp_coords_jac_2 * tmp_coords_jac_9;
    const double tmp_coords_jac_11 =
        macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_12 = tmp_coords_jac_11 * tmp_coords_jac_2;
    const double tmp_coords_jac_13 =
        macro_vertex_coord_id_3comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_14 = tmp_coords_jac_13 * tmp_coords_jac_2;
    const double tmp_coords_jac_15 =
        macro_vertex_coord_id_0comp1 + tmp_coords_jac_12 + tmp_coords_jac_14;
    const double tmp_coords_jac_16 =
        macro_vertex_coord_id_1comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_17 = tmp_coords_jac_16 * tmp_coords_jac_2;
    const double tmp_coords_jac_18 =
        macro_vertex_coord_id_2comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_19 = tmp_coords_jac_18 * tmp_coords_jac_2;
    const double tmp_coords_jac_20 =
        macro_vertex_coord_id_3comp2 - macro_vertex_coord_id_0comp2;
    const double tmp_coords_jac_21 = tmp_coords_jac_2 * tmp_coords_jac_20;
    const double tmp_coords_jac_22 =
        macro_vertex_coord_id_0comp2 + tmp_coords_jac_19 + tmp_coords_jac_21;
    const double tmp_coords_jac_23 = tmp_coords_jac_1 * 1.0;
    const double tmp_coords_jac_24 =
        macro_vertex_coord_id_0comp0 + tmp_coords_jac_3;
    const double tmp_coords_jac_25 =
        macro_vertex_coord_id_0comp1 + tmp_coords_jac_10;
    const double tmp_coords_jac_26 =
        macro_vertex_coord_id_0comp2 + tmp_coords_jac_17;
    const double p_affine_const_0_0 = tmp_coords_jac_3 + tmp_coords_jac_8;
    const double p_affine_const_0_1 = tmp_coords_jac_10 + tmp_coords_jac_15;
    const double p_affine_const_0_2 = tmp_coords_jac_17 + tmp_coords_jac_22;
    const double p_affine_const_1_0 =
        tmp_coords_jac_8 + tmp_coords_jac_0 * tmp_coords_jac_23;
    const double p_affine_const_1_1 =
        tmp_coords_jac_15 + tmp_coords_jac_23 * tmp_coords_jac_9;
    const double p_affine_const_1_2 =
        tmp_coords_jac_22 + tmp_coords_jac_16 * tmp_coords_jac_23;
    const double p_affine_const_2_0 = tmp_coords_jac_24 + tmp_coords_jac_7 +
                                      tmp_coords_jac_23 * tmp_coords_jac_4;
    const double p_affine_const_2_1 = tmp_coords_jac_14 + tmp_coords_jac_25 +
                                      tmp_coords_jac_11 * tmp_coords_jac_23;
    const double p_affine_const_2_2 = tmp_coords_jac_21 + tmp_coords_jac_26 +
                                      tmp_coords_jac_18 * tmp_coords_jac_23;
    const double p_affine_const_3_0 = tmp_coords_jac_24 + tmp_coords_jac_5 +
                                      tmp_coords_jac_23 * tmp_coords_jac_6;
    const double p_affine_const_3_1 = tmp_coords_jac_12 + tmp_coords_jac_25 +
                                      tmp_coords_jac_13 * tmp_coords_jac_23;
    const double p_affine_const_3_2 = tmp_coords_jac_19 + tmp_coords_jac_26 +
                                      tmp_coords_jac_20 * tmp_coords_jac_23;
    const double jac_affine_0_0 = p_affine_const_1_0 - p_affine_const_0_0;
    const double jac_affine_0_1 = p_affine_const_2_0 - p_affine_const_0_0;
    const double jac_affine_0_2 = p_affine_const_3_0 - p_affine_const_0_0;
    const double jac_affine_1_0 = p_affine_const_1_1 - p_affine_const_0_1;
    const double jac_affine_1_1 = p_affine_const_2_1 - p_affine_const_0_1;
    const double tmp_coords_jac_31 = jac_affine_0_2 * jac_affine_1_1;
    const double jac_affine_1_2 = p_affine_const_3_1 - p_affine_const_0_1;
    const double tmp_coords_jac_29 = jac_affine_0_1 * jac_affine_1_2;
    const double jac_affine_2_0 = p_affine_const_1_2 - p_affine_const_0_2;
    const double jac_affine_2_1 = p_affine_const_2_2 - p_affine_const_0_2;
    const double tmp_coords_jac_28 = jac_affine_1_2 * jac_affine_2_1;
    const double jac_affine_2_2 = p_affine_const_3_2 - p_affine_const_0_2;
    const double tmp_coords_jac_27 = jac_affine_1_1 * jac_affine_2_2;
    const double tmp_coords_jac_30 = jac_affine_0_1 * jac_affine_2_2;
    const double tmp_coords_jac_32 =
        jac_affine_0_0 * tmp_coords_jac_27 +
        jac_affine_2_0 * tmp_coords_jac_29 -
        jac_affine_0_0 * tmp_coords_jac_28 -
        jac_affine_1_0 * tmp_coords_jac_30 -
        jac_affine_2_0 * tmp_coords_jac_31 +
        jac_affine_0_2 * jac_affine_1_0 * jac_affine_2_1;
    const double tmp_coords_jac_33 = 1.0 / tmp_coords_jac_32;
    const double jac_affine_inv_0_0 =
        tmp_coords_jac_33 * (tmp_coords_jac_27 - tmp_coords_jac_28);
    const double jac_affine_inv_0_1 =
        tmp_coords_jac_33 *
        (-1.0 * tmp_coords_jac_30 + jac_affine_0_2 * jac_affine_2_1);
    const double jac_affine_inv_0_2 =
        tmp_coords_jac_33 * (tmp_coords_jac_29 - tmp_coords_jac_31);
    const double jac_affine_inv_1_0 =
        tmp_coords_jac_33 *
        (jac_affine_1_2 * jac_affine_2_0 - jac_affine_1_0 * jac_affine_2_2);
    const double jac_affine_inv_1_1 =
        tmp_coords_jac_33 *
        (jac_affine_0_0 * jac_affine_2_2 - jac_affine_0_2 * jac_affine_2_0);
    const double jac_affine_inv_1_2 =
        tmp_coords_jac_33 *
        (jac_affine_0_2 * jac_affine_1_0 - jac_affine_0_0 * jac_affine_1_2);
    const double jac_affine_inv_2_0 =
        tmp_coords_jac_33 *
        (jac_affine_1_0 * jac_affine_2_1 - jac_affine_1_1 * jac_affine_2_0);
    const double jac_affine_inv_2_1 =
        tmp_coords_jac_33 *
        (jac_affine_0_1 * jac_affine_2_0 - jac_affine_0_0 * jac_affine_2_1);
    const double jac_affine_inv_2_2 =
        tmp_coords_jac_33 *
        (jac_affine_0_0 * jac_affine_1_1 - jac_affine_0_1 * jac_affine_1_0);
    const double abs_det_jac_affine = abs(tmp_coords_jac_32);
    double phi_0_0[4] = {0.25, 0.25, 0.25, 0.25};
    double tabulated_and_untitled_0_0[10] = {
        abs_det_jac_affine * ((-1.0 * jac_affine_inv_0_0 - jac_affine_inv_1_0 -
                               jac_affine_inv_2_0) *
                                  (-1.0 * jac_affine_inv_0_0 -
                                   jac_affine_inv_1_0 - jac_affine_inv_2_0) +
                              (-1.0 * jac_affine_inv_0_1 - jac_affine_inv_1_1 -
                               jac_affine_inv_2_1) *
                                  (-1.0 * jac_affine_inv_0_1 -
                                   jac_affine_inv_1_1 - jac_affine_inv_2_1) +
                              (-1.0 * jac_affine_inv_0_2 - jac_affine_inv_1_2 -
                               jac_affine_inv_2_2) *
                                  (-1.0 * jac_affine_inv_0_2 -
                                   jac_affine_inv_1_2 - jac_affine_inv_2_2)),
        abs_det_jac_affine *
            (jac_affine_inv_0_0 * (-1.0 * jac_affine_inv_0_0 -
                                   jac_affine_inv_1_0 - jac_affine_inv_2_0) +
             jac_affine_inv_0_1 * (-1.0 * jac_affine_inv_0_1 -
                                   jac_affine_inv_1_1 - jac_affine_inv_2_1) +
             jac_affine_inv_0_2 * (-1.0 * jac_affine_inv_0_2 -
                                   jac_affine_inv_1_2 - jac_affine_inv_2_2)),
        abs_det_jac_affine *
            (jac_affine_inv_1_0 * (-1.0 * jac_affine_inv_0_0 -
                                   jac_affine_inv_1_0 - jac_affine_inv_2_0) +
             jac_affine_inv_1_1 * (-1.0 * jac_affine_inv_0_1 -
                                   jac_affine_inv_1_1 - jac_affine_inv_2_1) +
             jac_affine_inv_1_2 * (-1.0 * jac_affine_inv_0_2 -
                                   jac_affine_inv_1_2 - jac_affine_inv_2_2)),
        abs_det_jac_affine *
            (jac_affine_inv_2_0 * (-1.0 * jac_affine_inv_0_0 -
                                   jac_affine_inv_1_0 - jac_affine_inv_2_0) +
             jac_affine_inv_2_1 * (-1.0 * jac_affine_inv_0_1 -
                                   jac_affine_inv_1_1 - jac_affine_inv_2_1) +
             jac_affine_inv_2_2 * (-1.0 * jac_affine_inv_0_2 -
                                   jac_affine_inv_1_2 - jac_affine_inv_2_2)),
        abs_det_jac_affine * (jac_affine_inv_0_0 * jac_affine_inv_0_0 +
                              jac_affine_inv_0_1 * jac_affine_inv_0_1 +
                              jac_affine_inv_0_2 * jac_affine_inv_0_2),
        abs_det_jac_affine * (jac_affine_inv_0_0 * jac_affine_inv_1_0 +
                              jac_affine_inv_0_1 * jac_affine_inv_1_1 +
                              jac_affine_inv_0_2 * jac_affine_inv_1_2),
        abs_det_jac_affine * (jac_affine_inv_0_0 * jac_affine_inv_2_0 +
                              jac_affine_inv_0_1 * jac_affine_inv_2_1 +
                              jac_affine_inv_0_2 * jac_affine_inv_2_2),
        abs_det_jac_affine * (jac_affine_inv_1_0 * jac_affine_inv_1_0 +
                              jac_affine_inv_1_1 * jac_affine_inv_1_1 +
                              jac_affine_inv_1_2 * jac_affine_inv_1_2),
        abs_det_jac_affine * (jac_affine_inv_1_0 * jac_affine_inv_2_0 +
                              jac_affine_inv_1_1 * jac_affine_inv_2_1 +
                              jac_affine_inv_1_2 * jac_affine_inv_2_2),
        abs_det_jac_affine * (jac_affine_inv_2_0 * jac_affine_inv_2_0 +
                              jac_affine_inv_2_1 * jac_affine_inv_2_1 +
                              jac_affine_inv_2_2 * jac_affine_inv_2_2)};
    for (int64_t ctr_2 = 0LL; ctr_2 < micro_edges_per_macro_edge;
         ctr_2 += 1LL) {
      for (int64_t ctr_1 = 0LL;
           ctr_1 < -1LL * ctr_2 + micro_edges_per_macro_edge; ctr_1 += 1LL) {
        {
          const int64_t __ctr_0__1_simd_stop =
              -2LL - ctr_1 - ctr_2 + micro_edges_per_macro_edge - 3LL;
          const int64_t __ctr_0__1_simd_step = 4LL;
          for (int64_t ctr_0__1 = 0LL; ctr_0__1 < __ctr_0__1_simd_stop;
               ctr_0__1 += __ctr_0__1_simd_step) {
            const __m256i ctr_0__4 =
                _mm256_add_epi64(_mm256_set1_epi64x(ctr_0__1),
                                 _mm256_set_epi64x(3LL, 2LL, 1LL, 0LL));
            {
              /* CellType.WHITE_UP */
              {
                const __m256d p_affine_0_0__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_0_1__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_0_2__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_0__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_1__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_2__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_0__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_1__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_2__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_0__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_1__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_2__17 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d k_dof_0__17 = _mm256_loadu_pd(
                    &_data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_1__17 = _mm256_loadu_pd(
                    &_data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_2__17 = _mm256_loadu_pd(
                    &_data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL + ctr_1) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_3__17 = _mm256_loadu_pd(
                    &_data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                             (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                __m256d q_acc_0_0__17 = _mm256_set1_pd(0.0);
                __m256d q_acc_1_1__17 = _mm256_set1_pd(0.0);
                __m256d q_acc_2_2__17 = _mm256_set1_pd(0.0);
                __m256d q_acc_3_3__17 = _mm256_set1_pd(0.0);
                for (int64_t q__16 = 0LL; q__16 < 1LL; q__16 += 1LL) {
                  const __m256d tmp_qloop_0__17 = _mm256_mul_pd(
                      _mm256_add_pd(
                          _mm256_add_pd(
                              _mm256_add_pd(
                                  _mm256_mul_pd(
                                      k_dof_0__17,
                                      _mm256_set1_pd(phi_0_0__10[4LL * q__16])),
                                  _mm256_mul_pd(
                                      k_dof_1__17,
                                      _mm256_set1_pd(
                                          phi_0_0__10[1LL + 4LL * q__16]))),
                              _mm256_mul_pd(
                                  k_dof_2__17,
                                  _mm256_set1_pd(
                                      phi_0_0__10[2LL + 4LL * q__16]))),
                          _mm256_mul_pd(
                              k_dof_3__17,
                              _mm256_set1_pd(phi_0_0__10[3LL + 4LL * q__16]))),
                      _mm256_set1_pd(q_w[q__16]));
                  const __m256d q_tmp_0_0__17 = _mm256_mul_pd(
                      tmp_qloop_0__17,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__10[10LL * q__16]));
                  const __m256d q_tmp_1_1__17 = _mm256_mul_pd(
                      tmp_qloop_0__17,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__10[4LL + 10LL * q__16]));
                  const __m256d q_tmp_2_2__17 = _mm256_mul_pd(
                      tmp_qloop_0__17,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__10[7LL + 10LL * q__16]));
                  const __m256d q_tmp_3_3__17 = _mm256_mul_pd(
                      tmp_qloop_0__17,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__10[9LL + 10LL * q__16]));
                  q_acc_0_0__17 = _mm256_add_pd(q_acc_0_0__17, q_tmp_0_0__17);
                  q_acc_1_1__17 = _mm256_add_pd(q_acc_1_1__17, q_tmp_1_1__17);
                  q_acc_2_2__17 = _mm256_add_pd(q_acc_2_2__17, q_tmp_2_2__17);
                  q_acc_3_3__17 = _mm256_add_pd(q_acc_3_3__17, q_tmp_3_3__17);
                }
                const __m256d elMatDiag_0__17 = q_acc_0_0__17;
                const __m256d elMatDiag_1__17 = q_acc_1_1__17;
                const __m256d elMatDiag_2__17 = q_acc_2_2__17;
                const __m256d elMatDiag_3__17 = q_acc_3_3__17;
                _mm256_storeu_pd(
                    &_data_invDiag_
                        [-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__1 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatDiag_0__17,
                        _mm256_loadu_pd(
                            &_data_invDiag_
                                [-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (3LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                     ctr_1 +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_invDiag_
                        [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__1 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatDiag_1__17,
                        _mm256_loadu_pd(
                            &_data_invDiag_
                                [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (3LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                     ctr_1 +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_invDiag_
                        [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__1 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatDiag_2__17,
                        _mm256_loadu_pd(
                            &_data_invDiag_
                                [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (3LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL + ctr_1) * (2LL - ctr_2 +
                                                  micro_edges_per_macro_edge) +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_invDiag_
                        [-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__1 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatDiag_3__17,
                        _mm256_loadu_pd(
                            &_data_invDiag_
                                [-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                                 (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                     (1LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     ctr_1 +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
              }
            }
            {
              /* CellType.WHITE_DOWN */
              {
                const __m256d p_affine_0_0__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_0_1__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_0_2__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_0__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_1__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_2__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_0__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_1__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_2__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_0__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_1__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_2__18 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d k_dof_0__18 = _mm256_loadu_pd(
                    &_data_k[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL + ctr_1) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_1__18 = _mm256_loadu_pd(
                    &_data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                             (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_2__18 = _mm256_loadu_pd(
                    &_data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                             (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL + ctr_1) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_3__18 = _mm256_loadu_pd(
                    &_data_k[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                             (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL + ctr_1) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                __m256d q_acc_0_0__18 = _mm256_set1_pd(0.0);
                __m256d q_acc_1_1__18 = _mm256_set1_pd(0.0);
                __m256d q_acc_2_2__18 = _mm256_set1_pd(0.0);
                __m256d q_acc_3_3__18 = _mm256_set1_pd(0.0);
                for (int64_t q__15 = 0LL; q__15 < 1LL; q__15 += 1LL) {
                  const __m256d tmp_qloop_0__18 = _mm256_mul_pd(
                      _mm256_add_pd(
                          _mm256_add_pd(
                              _mm256_add_pd(
                                  _mm256_mul_pd(
                                      k_dof_0__18,
                                      _mm256_set1_pd(phi_0_0__9[4LL * q__15])),
                                  _mm256_mul_pd(
                                      k_dof_1__18,
                                      _mm256_set1_pd(
                                          phi_0_0__9[1LL + 4LL * q__15]))),
                              _mm256_mul_pd(
                                  k_dof_2__18,
                                  _mm256_set1_pd(
                                      phi_0_0__9[2LL + 4LL * q__15]))),
                          _mm256_mul_pd(
                              k_dof_3__18,
                              _mm256_set1_pd(phi_0_0__9[3LL + 4LL * q__15]))),
                      _mm256_set1_pd(q_w[q__15]));
                  const __m256d q_tmp_0_0__18 = _mm256_mul_pd(
                      tmp_qloop_0__18,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__9[10LL * q__15]));
                  const __m256d q_tmp_1_1__18 = _mm256_mul_pd(
                      tmp_qloop_0__18,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__9[4LL + 10LL * q__15]));
                  const __m256d q_tmp_2_2__18 = _mm256_mul_pd(
                      tmp_qloop_0__18,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__9[7LL + 10LL * q__15]));
                  const __m256d q_tmp_3_3__18 = _mm256_mul_pd(
                      tmp_qloop_0__18,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__9[9LL + 10LL * q__15]));
                  q_acc_0_0__18 = _mm256_add_pd(q_acc_0_0__18, q_tmp_0_0__18);
                  q_acc_1_1__18 = _mm256_add_pd(q_acc_1_1__18, q_tmp_1_1__18);
                  q_acc_2_2__18 = _mm256_add_pd(q_acc_2_2__18, q_tmp_2_2__18);
                  q_acc_3_3__18 = _mm256_add_pd(q_acc_3_3__18, q_tmp_3_3__18);
                }
                const __m256d elMatDiag_0__18 = q_acc_0_0__18;
                const __m256d elMatDiag_1__18 = q_acc_1_1__18;
                const __m256d elMatDiag_2__18 = q_acc_2_2__18;
                const __m256d elMatDiag_3__18 = q_acc_3_3__18;
                _mm256_storeu_pd(
                    &_data_invDiag_
                        [1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__1 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatDiag_0__18,
                        _mm256_loadu_pd(
                            &_data_invDiag_
                                [1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (3LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL + ctr_1) * (2LL - ctr_2 +
                                                  micro_edges_per_macro_edge) +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_invDiag_
                        [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__1 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatDiag_1__18,
                        _mm256_loadu_pd(
                            &_data_invDiag_
                                [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                                 (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                     (1LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     ctr_1 +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_invDiag_
                        [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__1 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatDiag_2__18,
                        _mm256_loadu_pd(
                            &_data_invDiag_
                                [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                                 (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                     (1LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL + ctr_1) * (1LL - ctr_2 +
                                                  micro_edges_per_macro_edge) +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_invDiag_
                        [1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__1 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatDiag_3__18,
                        _mm256_loadu_pd(
                            &_data_invDiag_
                                [1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                                 (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                     (1LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL + ctr_1) * (1LL - ctr_2 +
                                                  micro_edges_per_macro_edge) +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
              }
            }
            {
              /* CellType.BLUE_UP */
              {
                const __m256d p_affine_0_0__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_0_1__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_0_2__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_0__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_1__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_2__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_0__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_1__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_2__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_0__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_1__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_2__19 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d k_dof_0__19 = _mm256_loadu_pd(
                    &_data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_1__19 = _mm256_loadu_pd(
                    &_data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL + ctr_1) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_2__19 = _mm256_loadu_pd(
                    &_data_k[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL + ctr_1) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_3__19 = _mm256_loadu_pd(
                    &_data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                             (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                __m256d q_acc_0_0__19 = _mm256_set1_pd(0.0);
                __m256d q_acc_1_1__19 = _mm256_set1_pd(0.0);
                __m256d q_acc_2_2__19 = _mm256_set1_pd(0.0);
                __m256d q_acc_3_3__19 = _mm256_set1_pd(0.0);
                for (int64_t q__14 = 0LL; q__14 < 1LL; q__14 += 1LL) {
                  const __m256d tmp_qloop_0__19 = _mm256_mul_pd(
                      _mm256_add_pd(
                          _mm256_add_pd(
                              _mm256_add_pd(
                                  _mm256_mul_pd(
                                      k_dof_0__19,
                                      _mm256_set1_pd(phi_0_0__8[4LL * q__14])),
                                  _mm256_mul_pd(
                                      k_dof_1__19,
                                      _mm256_set1_pd(
                                          phi_0_0__8[1LL + 4LL * q__14]))),
                              _mm256_mul_pd(
                                  k_dof_2__19,
                                  _mm256_set1_pd(
                                      phi_0_0__8[2LL + 4LL * q__14]))),
                          _mm256_mul_pd(
                              k_dof_3__19,
                              _mm256_set1_pd(phi_0_0__8[3LL + 4LL * q__14]))),
                      _mm256_set1_pd(q_w[q__14]));
                  const __m256d q_tmp_0_0__19 = _mm256_mul_pd(
                      tmp_qloop_0__19,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__8[10LL * q__14]));
                  const __m256d q_tmp_1_1__19 = _mm256_mul_pd(
                      tmp_qloop_0__19,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__8[4LL + 10LL * q__14]));
                  const __m256d q_tmp_2_2__19 = _mm256_mul_pd(
                      tmp_qloop_0__19,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__8[7LL + 10LL * q__14]));
                  const __m256d q_tmp_3_3__19 = _mm256_mul_pd(
                      tmp_qloop_0__19,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__8[9LL + 10LL * q__14]));
                  q_acc_0_0__19 = _mm256_add_pd(q_acc_0_0__19, q_tmp_0_0__19);
                  q_acc_1_1__19 = _mm256_add_pd(q_acc_1_1__19, q_tmp_1_1__19);
                  q_acc_2_2__19 = _mm256_add_pd(q_acc_2_2__19, q_tmp_2_2__19);
                  q_acc_3_3__19 = _mm256_add_pd(q_acc_3_3__19, q_tmp_3_3__19);
                }
                const __m256d elMatDiag_0__19 = q_acc_0_0__19;
                const __m256d elMatDiag_1__19 = q_acc_1_1__19;
                const __m256d elMatDiag_2__19 = q_acc_2_2__19;
                const __m256d elMatDiag_3__19 = q_acc_3_3__19;
                _mm256_storeu_pd(
                    &_data_invDiag_
                        [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__1 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatDiag_0__19,
                        _mm256_loadu_pd(
                            &_data_invDiag_
                                [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (3LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                     ctr_1 +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_invDiag_
                        [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__1 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatDiag_1__19,
                        _mm256_loadu_pd(
                            &_data_invDiag_
                                [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (3LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL + ctr_1) * (2LL - ctr_2 +
                                                  micro_edges_per_macro_edge) +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_invDiag_
                        [1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__1 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatDiag_2__19,
                        _mm256_loadu_pd(
                            &_data_invDiag_
                                [1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (3LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL + ctr_1) * (2LL - ctr_2 +
                                                  micro_edges_per_macro_edge) +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_invDiag_
                        [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__1 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatDiag_3__19,
                        _mm256_loadu_pd(
                            &_data_invDiag_
                                [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                                 (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                     (1LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     ctr_1 +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
              }
            }
            {
              /* CellType.BLUE_DOWN */
              {
                const __m256d p_affine_0_0__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_0_1__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_0_2__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_0__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_1__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_2__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_0__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_1__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_2__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_0__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_1__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_2__20 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d k_dof_0__20 = _mm256_loadu_pd(
                    &_data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL + ctr_1) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_1__20 = _mm256_loadu_pd(
                    &_data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                             (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_2__20 = _mm256_loadu_pd(
                    &_data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                             (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_3__20 = _mm256_loadu_pd(
                    &_data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                             (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL + ctr_1) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                __m256d q_acc_0_0__20 = _mm256_set1_pd(0.0);
                __m256d q_acc_1_1__20 = _mm256_set1_pd(0.0);
                __m256d q_acc_2_2__20 = _mm256_set1_pd(0.0);
                __m256d q_acc_3_3__20 = _mm256_set1_pd(0.0);
                for (int64_t q__13 = 0LL; q__13 < 1LL; q__13 += 1LL) {
                  const __m256d tmp_qloop_0__20 = _mm256_mul_pd(
                      _mm256_add_pd(
                          _mm256_add_pd(
                              _mm256_add_pd(
                                  _mm256_mul_pd(
                                      k_dof_0__20,
                                      _mm256_set1_pd(phi_0_0__7[4LL * q__13])),
                                  _mm256_mul_pd(
                                      k_dof_1__20,
                                      _mm256_set1_pd(
                                          phi_0_0__7[1LL + 4LL * q__13]))),
                              _mm256_mul_pd(
                                  k_dof_2__20,
                                  _mm256_set1_pd(
                                      phi_0_0__7[2LL + 4LL * q__13]))),
                          _mm256_mul_pd(
                              k_dof_3__20,
                              _mm256_set1_pd(phi_0_0__7[3LL + 4LL * q__13]))),
                      _mm256_set1_pd(q_w[q__13]));
                  const __m256d q_tmp_0_0__20 = _mm256_mul_pd(
                      tmp_qloop_0__20,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__7[10LL * q__13]));
                  const __m256d q_tmp_1_1__20 = _mm256_mul_pd(
                      tmp_qloop_0__20,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__7[4LL + 10LL * q__13]));
                  const __m256d q_tmp_2_2__20 = _mm256_mul_pd(
                      tmp_qloop_0__20,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__7[7LL + 10LL * q__13]));
                  const __m256d q_tmp_3_3__20 = _mm256_mul_pd(
                      tmp_qloop_0__20,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__7[9LL + 10LL * q__13]));
                  q_acc_0_0__20 = _mm256_add_pd(q_acc_0_0__20, q_tmp_0_0__20);
                  q_acc_1_1__20 = _mm256_add_pd(q_acc_1_1__20, q_tmp_1_1__20);
                  q_acc_2_2__20 = _mm256_add_pd(q_acc_2_2__20, q_tmp_2_2__20);
                  q_acc_3_3__20 = _mm256_add_pd(q_acc_3_3__20, q_tmp_3_3__20);
                }
                const __m256d elMatDiag_0__20 = q_acc_0_0__20;
                const __m256d elMatDiag_1__20 = q_acc_1_1__20;
                const __m256d elMatDiag_2__20 = q_acc_2_2__20;
                const __m256d elMatDiag_3__20 = q_acc_3_3__20;
                _mm256_storeu_pd(
                    &_data_invDiag_
                        [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__1 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatDiag_0__20,
                        _mm256_loadu_pd(
                            &_data_invDiag_
                                [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (3LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL + ctr_1) * (2LL - ctr_2 +
                                                  micro_edges_per_macro_edge) +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_invDiag_
                        [-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__1 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatDiag_1__20,
                        _mm256_loadu_pd(
                            &_data_invDiag_
                                [-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                                 (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                     (1LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     ctr_1 +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_invDiag_
                        [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__1 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatDiag_2__20,
                        _mm256_loadu_pd(
                            &_data_invDiag_
                                [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                                 (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                     (1LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     ctr_1 +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_invDiag_
                        [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__1 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatDiag_3__20,
                        _mm256_loadu_pd(
                            &_data_invDiag_
                                [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                                 (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                     (1LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL + ctr_1) * (1LL - ctr_2 +
                                                  micro_edges_per_macro_edge) +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
              }
            }
            {
              /* CellType.GREEN_UP */
              {
                const __m256d p_affine_0_0__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_0_1__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_0_2__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_0__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_1__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_2__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_0__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_1__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_2__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_0__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_1__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_2__21 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d k_dof_0__21 = _mm256_loadu_pd(
                    &_data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_1__21 = _mm256_loadu_pd(
                    &_data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL + ctr_1) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_2__21 = _mm256_loadu_pd(
                    &_data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                             (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_3__21 = _mm256_loadu_pd(
                    &_data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                             (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                __m256d q_acc_0_0__21 = _mm256_set1_pd(0.0);
                __m256d q_acc_1_1__21 = _mm256_set1_pd(0.0);
                __m256d q_acc_2_2__21 = _mm256_set1_pd(0.0);
                __m256d q_acc_3_3__21 = _mm256_set1_pd(0.0);
                for (int64_t q__12 = 0LL; q__12 < 1LL; q__12 += 1LL) {
                  const __m256d tmp_qloop_0__21 = _mm256_mul_pd(
                      _mm256_add_pd(
                          _mm256_add_pd(
                              _mm256_add_pd(
                                  _mm256_mul_pd(
                                      k_dof_0__21,
                                      _mm256_set1_pd(phi_0_0__6[4LL * q__12])),
                                  _mm256_mul_pd(
                                      k_dof_1__21,
                                      _mm256_set1_pd(
                                          phi_0_0__6[1LL + 4LL * q__12]))),
                              _mm256_mul_pd(
                                  k_dof_2__21,
                                  _mm256_set1_pd(
                                      phi_0_0__6[2LL + 4LL * q__12]))),
                          _mm256_mul_pd(
                              k_dof_3__21,
                              _mm256_set1_pd(phi_0_0__6[3LL + 4LL * q__12]))),
                      _mm256_set1_pd(q_w[q__12]));
                  const __m256d q_tmp_0_0__21 = _mm256_mul_pd(
                      tmp_qloop_0__21,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__6[10LL * q__12]));
                  const __m256d q_tmp_1_1__21 = _mm256_mul_pd(
                      tmp_qloop_0__21,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__6[4LL + 10LL * q__12]));
                  const __m256d q_tmp_2_2__21 = _mm256_mul_pd(
                      tmp_qloop_0__21,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__6[7LL + 10LL * q__12]));
                  const __m256d q_tmp_3_3__21 = _mm256_mul_pd(
                      tmp_qloop_0__21,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__6[9LL + 10LL * q__12]));
                  q_acc_0_0__21 = _mm256_add_pd(q_acc_0_0__21, q_tmp_0_0__21);
                  q_acc_1_1__21 = _mm256_add_pd(q_acc_1_1__21, q_tmp_1_1__21);
                  q_acc_2_2__21 = _mm256_add_pd(q_acc_2_2__21, q_tmp_2_2__21);
                  q_acc_3_3__21 = _mm256_add_pd(q_acc_3_3__21, q_tmp_3_3__21);
                }
                const __m256d elMatDiag_0__21 = q_acc_0_0__21;
                const __m256d elMatDiag_1__21 = q_acc_1_1__21;
                const __m256d elMatDiag_2__21 = q_acc_2_2__21;
                const __m256d elMatDiag_3__21 = q_acc_3_3__21;
                _mm256_storeu_pd(
                    &_data_invDiag_
                        [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__1 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatDiag_0__21,
                        _mm256_loadu_pd(
                            &_data_invDiag_
                                [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (3LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                     ctr_1 +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_invDiag_
                        [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__1 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatDiag_1__21,
                        _mm256_loadu_pd(
                            &_data_invDiag_
                                [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (3LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL + ctr_1) * (2LL - ctr_2 +
                                                  micro_edges_per_macro_edge) +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_invDiag_
                        [-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__1 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatDiag_2__21,
                        _mm256_loadu_pd(
                            &_data_invDiag_
                                [-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                                 (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                     (1LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     ctr_1 +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_invDiag_
                        [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__1 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatDiag_3__21,
                        _mm256_loadu_pd(
                            &_data_invDiag_
                                [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                                 (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                     (1LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     ctr_1 +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
              }
            }
            {
              /* CellType.GREEN_DOWN */
              {
                const __m256d p_affine_0_0__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_0_1__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_0_2__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_0__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_1__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_1_2__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_set1_epi64x(ctr_2),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_0__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_1__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_2_2__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                     ctr_0__4),
                                    double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_set1_epi64x(ctr_1),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_0__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp0),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp0))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp0),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp0))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp0),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_1__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp1),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp1))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp1),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp1))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp1),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d p_affine_3_2__22 = _mm256_add_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_set1_pd(macro_vertex_coord_id_0comp2),
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_mul_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_div_pd(
                                            _mm256_set1_pd(1.0),
                                            _mm256_set1_pd(
                                                micro_edges_per_macro_edge_float))),
                                    _mm256_sub_pd(
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_1comp2),
                                        _mm256_set1_pd(
                                            macro_vertex_coord_id_0comp2))),
                                __builtin_convertvector(
                                    ctr_0__4, double
                                    __attribute__((__vector_size__(32)))))),
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_mul_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_div_pd(
                                        _mm256_set1_pd(1.0),
                                        _mm256_set1_pd(
                                            micro_edges_per_macro_edge_float))),
                                _mm256_sub_pd(
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_2comp2),
                                    _mm256_set1_pd(
                                        macro_vertex_coord_id_0comp2))),
                            __builtin_convertvector(
                                _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                                 _mm256_set1_epi64x(ctr_1)),
                                double __attribute__((__vector_size__(32)))))),
                    _mm256_mul_pd(
                        _mm256_mul_pd(
                            _mm256_mul_pd(
                                _mm256_set1_pd(1.0),
                                _mm256_div_pd(
                                    _mm256_set1_pd(1.0),
                                    _mm256_set1_pd(
                                        micro_edges_per_macro_edge_float))),
                            _mm256_sub_pd(
                                _mm256_set1_pd(macro_vertex_coord_id_3comp2),
                                _mm256_set1_pd(macro_vertex_coord_id_0comp2))),
                        __builtin_convertvector(
                            _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                             _mm256_set1_epi64x(ctr_2)),
                            double __attribute__((__vector_size__(32))))));
                const __m256d k_dof_0__22 = _mm256_loadu_pd(
                    &_data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL + ctr_1) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_1__22 = _mm256_loadu_pd(
                    &_data_k[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL + ctr_1) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_2__22 = _mm256_loadu_pd(
                    &_data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                             (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                const __m256d k_dof_3__22 = _mm256_loadu_pd(
                    &_data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                             (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL + ctr_1) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) +
                             ctr_0__1 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL]);
                __m256d q_acc_0_0__22 = _mm256_set1_pd(0.0);
                __m256d q_acc_1_1__22 = _mm256_set1_pd(0.0);
                __m256d q_acc_2_2__22 = _mm256_set1_pd(0.0);
                __m256d q_acc_3_3__22 = _mm256_set1_pd(0.0);
                for (int64_t q__11 = 0LL; q__11 < 1LL; q__11 += 1LL) {
                  const __m256d tmp_qloop_0__22 = _mm256_mul_pd(
                      _mm256_add_pd(
                          _mm256_add_pd(
                              _mm256_add_pd(
                                  _mm256_mul_pd(
                                      k_dof_0__22,
                                      _mm256_set1_pd(phi_0_0__5[4LL * q__11])),
                                  _mm256_mul_pd(
                                      k_dof_1__22,
                                      _mm256_set1_pd(
                                          phi_0_0__5[1LL + 4LL * q__11]))),
                              _mm256_mul_pd(
                                  k_dof_2__22,
                                  _mm256_set1_pd(
                                      phi_0_0__5[2LL + 4LL * q__11]))),
                          _mm256_mul_pd(
                              k_dof_3__22,
                              _mm256_set1_pd(phi_0_0__5[3LL + 4LL * q__11]))),
                      _mm256_set1_pd(q_w[q__11]));
                  const __m256d q_tmp_0_0__22 = _mm256_mul_pd(
                      tmp_qloop_0__22,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__5[10LL * q__11]));
                  const __m256d q_tmp_1_1__22 = _mm256_mul_pd(
                      tmp_qloop_0__22,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__5[4LL + 10LL * q__11]));
                  const __m256d q_tmp_2_2__22 = _mm256_mul_pd(
                      tmp_qloop_0__22,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__5[7LL + 10LL * q__11]));
                  const __m256d q_tmp_3_3__22 = _mm256_mul_pd(
                      tmp_qloop_0__22,
                      _mm256_set1_pd(
                          tabulated_and_untitled_0_0__5[9LL + 10LL * q__11]));
                  q_acc_0_0__22 = _mm256_add_pd(q_acc_0_0__22, q_tmp_0_0__22);
                  q_acc_1_1__22 = _mm256_add_pd(q_acc_1_1__22, q_tmp_1_1__22);
                  q_acc_2_2__22 = _mm256_add_pd(q_acc_2_2__22, q_tmp_2_2__22);
                  q_acc_3_3__22 = _mm256_add_pd(q_acc_3_3__22, q_tmp_3_3__22);
                }
                const __m256d elMatDiag_0__22 = q_acc_0_0__22;
                const __m256d elMatDiag_1__22 = q_acc_1_1__22;
                const __m256d elMatDiag_2__22 = q_acc_2_2__22;
                const __m256d elMatDiag_3__22 = q_acc_3_3__22;
                _mm256_storeu_pd(
                    &_data_invDiag_
                        [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__1 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatDiag_0__22,
                        _mm256_loadu_pd(
                            &_data_invDiag_
                                [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (3LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL + ctr_1) * (2LL - ctr_2 +
                                                  micro_edges_per_macro_edge) +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_invDiag_
                        [1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__1 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatDiag_1__22,
                        _mm256_loadu_pd(
                            &_data_invDiag_
                                [1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (3LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL + ctr_1) * (2LL - ctr_2 +
                                                  micro_edges_per_macro_edge) +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_invDiag_
                        [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__1 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatDiag_2__22,
                        _mm256_loadu_pd(
                            &_data_invDiag_
                                [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                                 (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                     (1LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                     ctr_1 +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
                _mm256_storeu_pd(
                    &_data_invDiag_
                        [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__1 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL],
                    _mm256_add_pd(
                        elMatDiag_3__22,
                        _mm256_loadu_pd(
                            &_data_invDiag_
                                [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                                 (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                     (1LL - ctr_2 +
                                      micro_edges_per_macro_edge) *
                                     (2LL - ctr_2 +
                                      micro_edges_per_macro_edge) /
                                     6LL +
                                 (1LL + ctr_1) * (1LL - ctr_2 +
                                                  micro_edges_per_macro_edge) +
                                 ctr_0__1 +
                                 (1LL + micro_edges_per_macro_edge) *
                                     (2LL + micro_edges_per_macro_edge) *
                                     (3LL + micro_edges_per_macro_edge) /
                                     6LL])));
              }
            }
          }
          const int64_t __ctr_0__1_trailing_start =
              __ctr_0__1_simd_stop > 0LL
                  ? ((__ctr_0__1_simd_stop - 1LL) / __ctr_0__1_simd_step +
                     1LL) *
                        __ctr_0__1_simd_step
                  : 0LL;
          for (int64_t ctr_0__3 = __ctr_0__1_trailing_start;
               ctr_0__3 < -2LL - ctr_1 - ctr_2 + micro_edges_per_macro_edge;
               ctr_0__3 += 1LL) {
            {
              /* CellType.WHITE_UP */
              {
                const double p_affine_0_0__10 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_0_1__10 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_0_2__10 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_1_0__10 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_1_1__10 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_1_2__10 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_2_0__10 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_2_1__10 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_2_2__10 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_3_0__10 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_1__10 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_2__10 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double k_dof_0__10 =
                    _data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_1__10 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_2__10 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_3__10 =
                    _data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                double q_acc_0_0__10 = 0.0;
                double q_acc_1_1__10 = 0.0;
                double q_acc_2_2__10 = 0.0;
                double q_acc_3_3__10 = 0.0;
                for (int64_t q__10 = 0LL; q__10 < 1LL; q__10 += 1LL) {
                  const double tmp_qloop_0__10 =
                      (k_dof_0__10 * phi_0_0__10[4LL * q__10] +
                       k_dof_1__10 * phi_0_0__10[1LL + 4LL * q__10] +
                       k_dof_2__10 * phi_0_0__10[2LL + 4LL * q__10] +
                       k_dof_3__10 * phi_0_0__10[3LL + 4LL * q__10]) *
                      q_w[q__10];
                  const double q_tmp_0_0__10 =
                      tmp_qloop_0__10 *
                      tabulated_and_untitled_0_0__10[10LL * q__10];
                  const double q_tmp_1_1__10 =
                      tmp_qloop_0__10 *
                      tabulated_and_untitled_0_0__10[4LL + 10LL * q__10];
                  const double q_tmp_2_2__10 =
                      tmp_qloop_0__10 *
                      tabulated_and_untitled_0_0__10[7LL + 10LL * q__10];
                  const double q_tmp_3_3__10 =
                      tmp_qloop_0__10 *
                      tabulated_and_untitled_0_0__10[9LL + 10LL * q__10];
                  q_acc_0_0__10 = q_acc_0_0__10 + q_tmp_0_0__10;
                  q_acc_1_1__10 = q_acc_1_1__10 + q_tmp_1_1__10;
                  q_acc_2_2__10 = q_acc_2_2__10 + q_tmp_2_2__10;
                  q_acc_3_3__10 = q_acc_3_3__10 + q_tmp_3_3__10;
                }
                const double elMatDiag_0__10 = q_acc_0_0__10;
                const double elMatDiag_1__10 = q_acc_1_1__10;
                const double elMatDiag_2__10 = q_acc_2_2__10;
                const double elMatDiag_3__10 = q_acc_3_3__10;
                _data_invDiag_[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__3 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_0__10 +
                    _data_invDiag_
                        [-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__3 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__3 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_1__10 +
                    _data_invDiag_
                        [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__3 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__3 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_2__10 +
                    _data_invDiag_
                        [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__3 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__3 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_3__10 +
                    _data_invDiag_
                        [-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__3 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
              }
            }
            {
              /* CellType.WHITE_DOWN */
              {
                const double p_affine_0_0__9 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_0_1__9 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_0_2__9 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_1_0__9 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_1_1__9 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_1_2__9 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_0__9 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_1__9 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_2__9 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_0__9 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_1__9 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_2__9 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double k_dof_0__9 =
                    _data_k[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_1__9 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_2__9 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_3__9 =
                    _data_k[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                double q_acc_0_0__9 = 0.0;
                double q_acc_1_1__9 = 0.0;
                double q_acc_2_2__9 = 0.0;
                double q_acc_3_3__9 = 0.0;
                for (int64_t q__9 = 0LL; q__9 < 1LL; q__9 += 1LL) {
                  const double tmp_qloop_0__9 =
                      (k_dof_0__9 * phi_0_0__9[4LL * q__9] +
                       k_dof_1__9 * phi_0_0__9[1LL + 4LL * q__9] +
                       k_dof_2__9 * phi_0_0__9[2LL + 4LL * q__9] +
                       k_dof_3__9 * phi_0_0__9[3LL + 4LL * q__9]) *
                      q_w[q__9];
                  const double q_tmp_0_0__9 =
                      tmp_qloop_0__9 *
                      tabulated_and_untitled_0_0__9[10LL * q__9];
                  const double q_tmp_1_1__9 =
                      tmp_qloop_0__9 *
                      tabulated_and_untitled_0_0__9[4LL + 10LL * q__9];
                  const double q_tmp_2_2__9 =
                      tmp_qloop_0__9 *
                      tabulated_and_untitled_0_0__9[7LL + 10LL * q__9];
                  const double q_tmp_3_3__9 =
                      tmp_qloop_0__9 *
                      tabulated_and_untitled_0_0__9[9LL + 10LL * q__9];
                  q_acc_0_0__9 = q_acc_0_0__9 + q_tmp_0_0__9;
                  q_acc_1_1__9 = q_acc_1_1__9 + q_tmp_1_1__9;
                  q_acc_2_2__9 = q_acc_2_2__9 + q_tmp_2_2__9;
                  q_acc_3_3__9 = q_acc_3_3__9 + q_tmp_3_3__9;
                }
                const double elMatDiag_0__9 = q_acc_0_0__9;
                const double elMatDiag_1__9 = q_acc_1_1__9;
                const double elMatDiag_2__9 = q_acc_2_2__9;
                const double elMatDiag_3__9 = q_acc_3_3__9;
                _data_invDiag_[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__3 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_0__9 +
                    _data_invDiag_
                        [1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__3 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__3 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_1__9 +
                    _data_invDiag_
                        [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__3 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__3 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_2__9 +
                    _data_invDiag_
                        [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__3 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__3 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_3__9 +
                    _data_invDiag_
                        [1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__3 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
              }
            }
            {
              /* CellType.BLUE_UP */
              {
                const double p_affine_0_0__8 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_0_1__8 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_0_2__8 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_1_0__8 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_1_1__8 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_1_2__8 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_2_0__8 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_2_1__8 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_2_2__8 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_3_0__8 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_1__8 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_2__8 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double k_dof_0__8 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_1__8 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_2__8 =
                    _data_k[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_3__8 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                double q_acc_0_0__8 = 0.0;
                double q_acc_1_1__8 = 0.0;
                double q_acc_2_2__8 = 0.0;
                double q_acc_3_3__8 = 0.0;
                for (int64_t q__8 = 0LL; q__8 < 1LL; q__8 += 1LL) {
                  const double tmp_qloop_0__8 =
                      (k_dof_0__8 * phi_0_0__8[4LL * q__8] +
                       k_dof_1__8 * phi_0_0__8[1LL + 4LL * q__8] +
                       k_dof_2__8 * phi_0_0__8[2LL + 4LL * q__8] +
                       k_dof_3__8 * phi_0_0__8[3LL + 4LL * q__8]) *
                      q_w[q__8];
                  const double q_tmp_0_0__8 =
                      tmp_qloop_0__8 *
                      tabulated_and_untitled_0_0__8[10LL * q__8];
                  const double q_tmp_1_1__8 =
                      tmp_qloop_0__8 *
                      tabulated_and_untitled_0_0__8[4LL + 10LL * q__8];
                  const double q_tmp_2_2__8 =
                      tmp_qloop_0__8 *
                      tabulated_and_untitled_0_0__8[7LL + 10LL * q__8];
                  const double q_tmp_3_3__8 =
                      tmp_qloop_0__8 *
                      tabulated_and_untitled_0_0__8[9LL + 10LL * q__8];
                  q_acc_0_0__8 = q_acc_0_0__8 + q_tmp_0_0__8;
                  q_acc_1_1__8 = q_acc_1_1__8 + q_tmp_1_1__8;
                  q_acc_2_2__8 = q_acc_2_2__8 + q_tmp_2_2__8;
                  q_acc_3_3__8 = q_acc_3_3__8 + q_tmp_3_3__8;
                }
                const double elMatDiag_0__8 = q_acc_0_0__8;
                const double elMatDiag_1__8 = q_acc_1_1__8;
                const double elMatDiag_2__8 = q_acc_2_2__8;
                const double elMatDiag_3__8 = q_acc_3_3__8;
                _data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__3 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_0__8 +
                    _data_invDiag_
                        [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__3 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__3 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_1__8 +
                    _data_invDiag_
                        [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__3 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__3 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_2__8 +
                    _data_invDiag_
                        [1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__3 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__3 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_3__8 +
                    _data_invDiag_
                        [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__3 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
              }
            }
            {
              /* CellType.BLUE_DOWN */
              {
                const double p_affine_0_0__7 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_0_1__7 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_0_2__7 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_1_0__7 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_1_1__7 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_1_2__7 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_0__7 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_1__7 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_2__7 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_0__7 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_1__7 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_2__7 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double k_dof_0__7 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_1__7 =
                    _data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_2__7 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_3__7 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                double q_acc_0_0__7 = 0.0;
                double q_acc_1_1__7 = 0.0;
                double q_acc_2_2__7 = 0.0;
                double q_acc_3_3__7 = 0.0;
                for (int64_t q__7 = 0LL; q__7 < 1LL; q__7 += 1LL) {
                  const double tmp_qloop_0__7 =
                      (k_dof_0__7 * phi_0_0__7[4LL * q__7] +
                       k_dof_1__7 * phi_0_0__7[1LL + 4LL * q__7] +
                       k_dof_2__7 * phi_0_0__7[2LL + 4LL * q__7] +
                       k_dof_3__7 * phi_0_0__7[3LL + 4LL * q__7]) *
                      q_w[q__7];
                  const double q_tmp_0_0__7 =
                      tmp_qloop_0__7 *
                      tabulated_and_untitled_0_0__7[10LL * q__7];
                  const double q_tmp_1_1__7 =
                      tmp_qloop_0__7 *
                      tabulated_and_untitled_0_0__7[4LL + 10LL * q__7];
                  const double q_tmp_2_2__7 =
                      tmp_qloop_0__7 *
                      tabulated_and_untitled_0_0__7[7LL + 10LL * q__7];
                  const double q_tmp_3_3__7 =
                      tmp_qloop_0__7 *
                      tabulated_and_untitled_0_0__7[9LL + 10LL * q__7];
                  q_acc_0_0__7 = q_acc_0_0__7 + q_tmp_0_0__7;
                  q_acc_1_1__7 = q_acc_1_1__7 + q_tmp_1_1__7;
                  q_acc_2_2__7 = q_acc_2_2__7 + q_tmp_2_2__7;
                  q_acc_3_3__7 = q_acc_3_3__7 + q_tmp_3_3__7;
                }
                const double elMatDiag_0__7 = q_acc_0_0__7;
                const double elMatDiag_1__7 = q_acc_1_1__7;
                const double elMatDiag_2__7 = q_acc_2_2__7;
                const double elMatDiag_3__7 = q_acc_3_3__7;
                _data_invDiag_[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__3 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_0__7 +
                    _data_invDiag_
                        [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__3 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__3 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_1__7 +
                    _data_invDiag_
                        [-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__3 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__3 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_2__7 +
                    _data_invDiag_
                        [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__3 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__3 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_3__7 +
                    _data_invDiag_
                        [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__3 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
              }
            }
            {
              /* CellType.GREEN_UP */
              {
                const double p_affine_0_0__6 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_0_1__6 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_0_2__6 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_1_0__6 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_1_1__6 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_1_2__6 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_2_0__6 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_1__6 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_2__6 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_0__6 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_1__6 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_2__6 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double k_dof_0__6 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_1__6 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_2__6 =
                    _data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_3__6 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                double q_acc_0_0__6 = 0.0;
                double q_acc_1_1__6 = 0.0;
                double q_acc_2_2__6 = 0.0;
                double q_acc_3_3__6 = 0.0;
                for (int64_t q__6 = 0LL; q__6 < 1LL; q__6 += 1LL) {
                  const double tmp_qloop_0__6 =
                      (k_dof_0__6 * phi_0_0__6[4LL * q__6] +
                       k_dof_1__6 * phi_0_0__6[1LL + 4LL * q__6] +
                       k_dof_2__6 * phi_0_0__6[2LL + 4LL * q__6] +
                       k_dof_3__6 * phi_0_0__6[3LL + 4LL * q__6]) *
                      q_w[q__6];
                  const double q_tmp_0_0__6 =
                      tmp_qloop_0__6 *
                      tabulated_and_untitled_0_0__6[10LL * q__6];
                  const double q_tmp_1_1__6 =
                      tmp_qloop_0__6 *
                      tabulated_and_untitled_0_0__6[4LL + 10LL * q__6];
                  const double q_tmp_2_2__6 =
                      tmp_qloop_0__6 *
                      tabulated_and_untitled_0_0__6[7LL + 10LL * q__6];
                  const double q_tmp_3_3__6 =
                      tmp_qloop_0__6 *
                      tabulated_and_untitled_0_0__6[9LL + 10LL * q__6];
                  q_acc_0_0__6 = q_acc_0_0__6 + q_tmp_0_0__6;
                  q_acc_1_1__6 = q_acc_1_1__6 + q_tmp_1_1__6;
                  q_acc_2_2__6 = q_acc_2_2__6 + q_tmp_2_2__6;
                  q_acc_3_3__6 = q_acc_3_3__6 + q_tmp_3_3__6;
                }
                const double elMatDiag_0__6 = q_acc_0_0__6;
                const double elMatDiag_1__6 = q_acc_1_1__6;
                const double elMatDiag_2__6 = q_acc_2_2__6;
                const double elMatDiag_3__6 = q_acc_3_3__6;
                _data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__3 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_0__6 +
                    _data_invDiag_
                        [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__3 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__3 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_1__6 +
                    _data_invDiag_
                        [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__3 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__3 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_2__6 +
                    _data_invDiag_
                        [-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__3 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__3 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_3__6 +
                    _data_invDiag_
                        [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__3 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
              }
            }
            {
              /* CellType.GREEN_DOWN */
              {
                const double p_affine_0_0__5 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_0_1__5 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_0_2__5 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_1_0__5 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_1_1__5 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_1_2__5 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_2_0__5 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_1__5 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_2__5 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__3) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_0__5 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_1__5 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_2__5 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__3 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double k_dof_0__5 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_1__5 =
                    _data_k[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_2__5 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_3__5 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__3 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                double q_acc_0_0__5 = 0.0;
                double q_acc_1_1__5 = 0.0;
                double q_acc_2_2__5 = 0.0;
                double q_acc_3_3__5 = 0.0;
                for (int64_t q__5 = 0LL; q__5 < 1LL; q__5 += 1LL) {
                  const double tmp_qloop_0__5 =
                      (k_dof_0__5 * phi_0_0__5[4LL * q__5] +
                       k_dof_1__5 * phi_0_0__5[1LL + 4LL * q__5] +
                       k_dof_2__5 * phi_0_0__5[2LL + 4LL * q__5] +
                       k_dof_3__5 * phi_0_0__5[3LL + 4LL * q__5]) *
                      q_w[q__5];
                  const double q_tmp_0_0__5 =
                      tmp_qloop_0__5 *
                      tabulated_and_untitled_0_0__5[10LL * q__5];
                  const double q_tmp_1_1__5 =
                      tmp_qloop_0__5 *
                      tabulated_and_untitled_0_0__5[4LL + 10LL * q__5];
                  const double q_tmp_2_2__5 =
                      tmp_qloop_0__5 *
                      tabulated_and_untitled_0_0__5[7LL + 10LL * q__5];
                  const double q_tmp_3_3__5 =
                      tmp_qloop_0__5 *
                      tabulated_and_untitled_0_0__5[9LL + 10LL * q__5];
                  q_acc_0_0__5 = q_acc_0_0__5 + q_tmp_0_0__5;
                  q_acc_1_1__5 = q_acc_1_1__5 + q_tmp_1_1__5;
                  q_acc_2_2__5 = q_acc_2_2__5 + q_tmp_2_2__5;
                  q_acc_3_3__5 = q_acc_3_3__5 + q_tmp_3_3__5;
                }
                const double elMatDiag_0__5 = q_acc_0_0__5;
                const double elMatDiag_1__5 = q_acc_1_1__5;
                const double elMatDiag_2__5 = q_acc_2_2__5;
                const double elMatDiag_3__5 = q_acc_3_3__5;
                _data_invDiag_[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__3 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_0__5 +
                    _data_invDiag_
                        [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__3 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__3 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_1__5 +
                    _data_invDiag_
                        [1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__3 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__3 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_2__5 +
                    _data_invDiag_
                        [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__3 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__3 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_3__5 +
                    _data_invDiag_
                        [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__3 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
              }
            }
          }
        }
        {
          const int64_t ctr_0__0 =
              -2LL - ctr_1 - ctr_2 + micro_edges_per_macro_edge;
          if (ctr_0__0 >= 0LL) {
            {
              /* CellType.WHITE_UP */
              const double tmp_coords_jac_0__4 =
                  macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_1__4 =
                  1.0 * (1.0 / micro_edges_per_macro_edge_float);
              const double tmp_coords_jac_2__4 = tmp_coords_jac_1__4 * 0.0;
              const double tmp_coords_jac_3__4 =
                  tmp_coords_jac_0__4 * tmp_coords_jac_2__4;
              const double tmp_coords_jac_4__4 =
                  macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_5__4 =
                  tmp_coords_jac_2__4 * tmp_coords_jac_4__4;
              const double tmp_coords_jac_6__4 =
                  macro_vertex_coord_id_3comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_7__4 =
                  tmp_coords_jac_2__4 * tmp_coords_jac_6__4;
              const double tmp_coords_jac_8__4 = macro_vertex_coord_id_0comp0 +
                                                 tmp_coords_jac_5__4 +
                                                 tmp_coords_jac_7__4;
              const double tmp_coords_jac_9__4 =
                  macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_10__4 =
                  tmp_coords_jac_2__4 * tmp_coords_jac_9__4;
              const double tmp_coords_jac_11__4 =
                  macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_12__4 =
                  tmp_coords_jac_11__4 * tmp_coords_jac_2__4;
              const double tmp_coords_jac_13__4 =
                  macro_vertex_coord_id_3comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_14__4 =
                  tmp_coords_jac_13__4 * tmp_coords_jac_2__4;
              const double tmp_coords_jac_15__4 = macro_vertex_coord_id_0comp1 +
                                                  tmp_coords_jac_12__4 +
                                                  tmp_coords_jac_14__4;
              const double tmp_coords_jac_16__4 =
                  macro_vertex_coord_id_1comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_17__4 =
                  tmp_coords_jac_16__4 * tmp_coords_jac_2__4;
              const double tmp_coords_jac_18__4 =
                  macro_vertex_coord_id_2comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_19__4 =
                  tmp_coords_jac_18__4 * tmp_coords_jac_2__4;
              const double tmp_coords_jac_20__4 =
                  macro_vertex_coord_id_3comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_21__4 =
                  tmp_coords_jac_2__4 * tmp_coords_jac_20__4;
              const double tmp_coords_jac_22__4 = macro_vertex_coord_id_0comp2 +
                                                  tmp_coords_jac_19__4 +
                                                  tmp_coords_jac_21__4;
              const double tmp_coords_jac_23__4 = tmp_coords_jac_1__4 * 1.0;
              const double tmp_coords_jac_24__4 =
                  macro_vertex_coord_id_0comp0 + tmp_coords_jac_3__4;
              const double tmp_coords_jac_25__4 =
                  macro_vertex_coord_id_0comp1 + tmp_coords_jac_10__4;
              const double tmp_coords_jac_26__4 =
                  macro_vertex_coord_id_0comp2 + tmp_coords_jac_17__4;
              const double p_affine_const_0_0__4 =
                  tmp_coords_jac_3__4 + tmp_coords_jac_8__4;
              const double p_affine_const_0_1__4 =
                  tmp_coords_jac_10__4 + tmp_coords_jac_15__4;
              const double p_affine_const_0_2__4 =
                  tmp_coords_jac_17__4 + tmp_coords_jac_22__4;
              const double p_affine_const_1_0__4 =
                  tmp_coords_jac_8__4 +
                  tmp_coords_jac_0__4 * tmp_coords_jac_23__4;
              const double p_affine_const_1_1__4 =
                  tmp_coords_jac_15__4 +
                  tmp_coords_jac_23__4 * tmp_coords_jac_9__4;
              const double p_affine_const_1_2__4 =
                  tmp_coords_jac_22__4 +
                  tmp_coords_jac_16__4 * tmp_coords_jac_23__4;
              const double p_affine_const_2_0__4 =
                  tmp_coords_jac_24__4 + tmp_coords_jac_7__4 +
                  tmp_coords_jac_23__4 * tmp_coords_jac_4__4;
              const double p_affine_const_2_1__4 =
                  tmp_coords_jac_14__4 + tmp_coords_jac_25__4 +
                  tmp_coords_jac_11__4 * tmp_coords_jac_23__4;
              const double p_affine_const_2_2__4 =
                  tmp_coords_jac_21__4 + tmp_coords_jac_26__4 +
                  tmp_coords_jac_18__4 * tmp_coords_jac_23__4;
              const double p_affine_const_3_0__4 =
                  tmp_coords_jac_24__4 + tmp_coords_jac_5__4 +
                  tmp_coords_jac_23__4 * tmp_coords_jac_6__4;
              const double p_affine_const_3_1__4 =
                  tmp_coords_jac_12__4 + tmp_coords_jac_25__4 +
                  tmp_coords_jac_13__4 * tmp_coords_jac_23__4;
              const double p_affine_const_3_2__4 =
                  tmp_coords_jac_19__4 + tmp_coords_jac_26__4 +
                  tmp_coords_jac_20__4 * tmp_coords_jac_23__4;
              const double jac_affine_0_0__4 =
                  p_affine_const_1_0__4 - p_affine_const_0_0__4;
              const double jac_affine_0_1__4 =
                  p_affine_const_2_0__4 - p_affine_const_0_0__4;
              const double jac_affine_0_2__4 =
                  p_affine_const_3_0__4 - p_affine_const_0_0__4;
              const double jac_affine_1_0__4 =
                  p_affine_const_1_1__4 - p_affine_const_0_1__4;
              const double jac_affine_1_1__4 =
                  p_affine_const_2_1__4 - p_affine_const_0_1__4;
              const double tmp_coords_jac_31__3 =
                  jac_affine_0_2__4 * jac_affine_1_1__4;
              const double jac_affine_1_2__4 =
                  p_affine_const_3_1__4 - p_affine_const_0_1__4;
              const double tmp_coords_jac_29__4 =
                  jac_affine_0_1__4 * jac_affine_1_2__4;
              const double jac_affine_2_0__4 =
                  p_affine_const_1_2__4 - p_affine_const_0_2__4;
              const double jac_affine_2_1__4 =
                  p_affine_const_2_2__4 - p_affine_const_0_2__4;
              const double tmp_coords_jac_28__4 =
                  jac_affine_1_2__4 * jac_affine_2_1__4;
              const double jac_affine_2_2__4 =
                  p_affine_const_3_2__4 - p_affine_const_0_2__4;
              const double tmp_coords_jac_27__4 =
                  jac_affine_1_1__4 * jac_affine_2_2__4;
              const double tmp_coords_jac_30__4 =
                  jac_affine_0_1__4 * jac_affine_2_2__4;
              const double tmp_coords_jac_32__3 =
                  jac_affine_0_0__4 * tmp_coords_jac_27__4 +
                  jac_affine_2_0__4 * tmp_coords_jac_29__4 -
                  jac_affine_0_0__4 * tmp_coords_jac_28__4 -
                  jac_affine_1_0__4 * tmp_coords_jac_30__4 -
                  jac_affine_2_0__4 * tmp_coords_jac_31__3 +
                  jac_affine_0_2__4 * jac_affine_1_0__4 * jac_affine_2_1__4;
              const double tmp_coords_jac_33__3 = 1.0 / tmp_coords_jac_32__3;
              const double jac_affine_inv_0_0__4 =
                  tmp_coords_jac_33__3 *
                  (tmp_coords_jac_27__4 - tmp_coords_jac_28__4);
              const double jac_affine_inv_0_1__4 =
                  tmp_coords_jac_33__3 *
                  (-1.0 * tmp_coords_jac_30__4 +
                   jac_affine_0_2__4 * jac_affine_2_1__4);
              const double jac_affine_inv_0_2__4 =
                  tmp_coords_jac_33__3 *
                  (tmp_coords_jac_29__4 - tmp_coords_jac_31__3);
              const double jac_affine_inv_1_0__4 =
                  tmp_coords_jac_33__3 *
                  (jac_affine_1_2__4 * jac_affine_2_0__4 -
                   jac_affine_1_0__4 * jac_affine_2_2__4);
              const double jac_affine_inv_1_1__4 =
                  tmp_coords_jac_33__3 *
                  (jac_affine_0_0__4 * jac_affine_2_2__4 -
                   jac_affine_0_2__4 * jac_affine_2_0__4);
              const double jac_affine_inv_1_2__4 =
                  tmp_coords_jac_33__3 *
                  (jac_affine_0_2__4 * jac_affine_1_0__4 -
                   jac_affine_0_0__4 * jac_affine_1_2__4);
              const double jac_affine_inv_2_0__4 =
                  tmp_coords_jac_33__3 *
                  (jac_affine_1_0__4 * jac_affine_2_1__4 -
                   jac_affine_1_1__4 * jac_affine_2_0__4);
              const double jac_affine_inv_2_1__4 =
                  tmp_coords_jac_33__3 *
                  (jac_affine_0_1__4 * jac_affine_2_0__4 -
                   jac_affine_0_0__4 * jac_affine_2_1__4);
              const double jac_affine_inv_2_2__4 =
                  tmp_coords_jac_33__3 *
                  (jac_affine_0_0__4 * jac_affine_1_1__4 -
                   jac_affine_0_1__4 * jac_affine_1_0__4);
              const double abs_det_jac_affine__4 = abs(tmp_coords_jac_32__3);
              double phi_0_0__4[4] = {0.25, 0.25, 0.25, 0.25};
              double tabulated_and_untitled_0_0__4[10] = {
                  abs_det_jac_affine__4 *
                      ((-1.0 * jac_affine_inv_0_0__4 - jac_affine_inv_1_0__4 -
                        jac_affine_inv_2_0__4) *
                           (-1.0 * jac_affine_inv_0_0__4 -
                            jac_affine_inv_1_0__4 - jac_affine_inv_2_0__4) +
                       (-1.0 * jac_affine_inv_0_1__4 - jac_affine_inv_1_1__4 -
                        jac_affine_inv_2_1__4) *
                           (-1.0 * jac_affine_inv_0_1__4 -
                            jac_affine_inv_1_1__4 - jac_affine_inv_2_1__4) +
                       (-1.0 * jac_affine_inv_0_2__4 - jac_affine_inv_1_2__4 -
                        jac_affine_inv_2_2__4) *
                           (-1.0 * jac_affine_inv_0_2__4 -
                            jac_affine_inv_1_2__4 - jac_affine_inv_2_2__4)),
                  abs_det_jac_affine__4 *
                      (jac_affine_inv_0_0__4 *
                           (-1.0 * jac_affine_inv_0_0__4 -
                            jac_affine_inv_1_0__4 - jac_affine_inv_2_0__4) +
                       jac_affine_inv_0_1__4 *
                           (-1.0 * jac_affine_inv_0_1__4 -
                            jac_affine_inv_1_1__4 - jac_affine_inv_2_1__4) +
                       jac_affine_inv_0_2__4 *
                           (-1.0 * jac_affine_inv_0_2__4 -
                            jac_affine_inv_1_2__4 - jac_affine_inv_2_2__4)),
                  abs_det_jac_affine__4 *
                      (jac_affine_inv_1_0__4 *
                           (-1.0 * jac_affine_inv_0_0__4 -
                            jac_affine_inv_1_0__4 - jac_affine_inv_2_0__4) +
                       jac_affine_inv_1_1__4 *
                           (-1.0 * jac_affine_inv_0_1__4 -
                            jac_affine_inv_1_1__4 - jac_affine_inv_2_1__4) +
                       jac_affine_inv_1_2__4 *
                           (-1.0 * jac_affine_inv_0_2__4 -
                            jac_affine_inv_1_2__4 - jac_affine_inv_2_2__4)),
                  abs_det_jac_affine__4 *
                      (jac_affine_inv_2_0__4 *
                           (-1.0 * jac_affine_inv_0_0__4 -
                            jac_affine_inv_1_0__4 - jac_affine_inv_2_0__4) +
                       jac_affine_inv_2_1__4 *
                           (-1.0 * jac_affine_inv_0_1__4 -
                            jac_affine_inv_1_1__4 - jac_affine_inv_2_1__4) +
                       jac_affine_inv_2_2__4 *
                           (-1.0 * jac_affine_inv_0_2__4 -
                            jac_affine_inv_1_2__4 - jac_affine_inv_2_2__4)),
                  abs_det_jac_affine__4 *
                      (jac_affine_inv_0_0__4 * jac_affine_inv_0_0__4 +
                       jac_affine_inv_0_1__4 * jac_affine_inv_0_1__4 +
                       jac_affine_inv_0_2__4 * jac_affine_inv_0_2__4),
                  abs_det_jac_affine__4 *
                      (jac_affine_inv_0_0__4 * jac_affine_inv_1_0__4 +
                       jac_affine_inv_0_1__4 * jac_affine_inv_1_1__4 +
                       jac_affine_inv_0_2__4 * jac_affine_inv_1_2__4),
                  abs_det_jac_affine__4 *
                      (jac_affine_inv_0_0__4 * jac_affine_inv_2_0__4 +
                       jac_affine_inv_0_1__4 * jac_affine_inv_2_1__4 +
                       jac_affine_inv_0_2__4 * jac_affine_inv_2_2__4),
                  abs_det_jac_affine__4 *
                      (jac_affine_inv_1_0__4 * jac_affine_inv_1_0__4 +
                       jac_affine_inv_1_1__4 * jac_affine_inv_1_1__4 +
                       jac_affine_inv_1_2__4 * jac_affine_inv_1_2__4),
                  abs_det_jac_affine__4 *
                      (jac_affine_inv_1_0__4 * jac_affine_inv_2_0__4 +
                       jac_affine_inv_1_1__4 * jac_affine_inv_2_1__4 +
                       jac_affine_inv_1_2__4 * jac_affine_inv_2_2__4),
                  abs_det_jac_affine__4 *
                      (jac_affine_inv_2_0__4 * jac_affine_inv_2_0__4 +
                       jac_affine_inv_2_1__4 * jac_affine_inv_2_1__4 +
                       jac_affine_inv_2_2__4 * jac_affine_inv_2_2__4)};
              {
                const double p_affine_0_0__4 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_0_1__4 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_0_2__4 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_1_0__4 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_1_1__4 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_1_2__4 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_2_0__4 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_2_1__4 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_2_2__4 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_3_0__4 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_1__4 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_2__4 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double k_dof_0__4 =
                    _data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_1__4 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_2__4 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_3__4 =
                    _data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                double q_acc_0_0__4 = 0.0;
                double q_acc_1_1__4 = 0.0;
                double q_acc_2_2__4 = 0.0;
                double q_acc_3_3__4 = 0.0;
                for (int64_t q__4 = 0LL; q__4 < 1LL; q__4 += 1LL) {
                  const double tmp_qloop_0__4 =
                      (k_dof_0__4 * phi_0_0__4[4LL * q__4] +
                       k_dof_1__4 * phi_0_0__4[1LL + 4LL * q__4] +
                       k_dof_2__4 * phi_0_0__4[2LL + 4LL * q__4] +
                       k_dof_3__4 * phi_0_0__4[3LL + 4LL * q__4]) *
                      q_w[q__4];
                  const double q_tmp_0_0__4 =
                      tmp_qloop_0__4 *
                      tabulated_and_untitled_0_0__4[10LL * q__4];
                  const double q_tmp_1_1__4 =
                      tmp_qloop_0__4 *
                      tabulated_and_untitled_0_0__4[4LL + 10LL * q__4];
                  const double q_tmp_2_2__4 =
                      tmp_qloop_0__4 *
                      tabulated_and_untitled_0_0__4[7LL + 10LL * q__4];
                  const double q_tmp_3_3__4 =
                      tmp_qloop_0__4 *
                      tabulated_and_untitled_0_0__4[9LL + 10LL * q__4];
                  q_acc_0_0__4 = q_acc_0_0__4 + q_tmp_0_0__4;
                  q_acc_1_1__4 = q_acc_1_1__4 + q_tmp_1_1__4;
                  q_acc_2_2__4 = q_acc_2_2__4 + q_tmp_2_2__4;
                  q_acc_3_3__4 = q_acc_3_3__4 + q_tmp_3_3__4;
                }
                const double elMatDiag_0__4 = q_acc_0_0__4;
                const double elMatDiag_1__4 = q_acc_1_1__4;
                const double elMatDiag_2__4 = q_acc_2_2__4;
                const double elMatDiag_3__4 = q_acc_3_3__4;
                _data_invDiag_[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__0 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_0__4 +
                    _data_invDiag_
                        [-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__0 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__0 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_1__4 +
                    _data_invDiag_
                        [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__0 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__0 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_2__4 +
                    _data_invDiag_
                        [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__0 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__0 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_3__4 +
                    _data_invDiag_
                        [-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__0 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
              }
            }
            {
              /* CellType.BLUE_UP */
              const double tmp_coords_jac_0__3 =
                  macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_1__3 =
                  1.0 * (1.0 / micro_edges_per_macro_edge_float);
              const double tmp_coords_jac_2__3 = tmp_coords_jac_1__3 * 0.0;
              const double tmp_coords_jac_3__3 =
                  tmp_coords_jac_0__3 * tmp_coords_jac_2__3;
              const double tmp_coords_jac_4__3 =
                  macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_5__3 = tmp_coords_jac_1__3 * 1.0;
              const double tmp_coords_jac_6__3 =
                  tmp_coords_jac_4__3 * tmp_coords_jac_5__3;
              const double tmp_coords_jac_7__3 =
                  macro_vertex_coord_id_3comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_8__3 =
                  macro_vertex_coord_id_0comp0 +
                  tmp_coords_jac_2__3 * tmp_coords_jac_7__3;
              const double tmp_coords_jac_9__3 =
                  tmp_coords_jac_6__3 + tmp_coords_jac_8__3;
              const double tmp_coords_jac_10__3 =
                  macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_11__3 =
                  tmp_coords_jac_10__3 * tmp_coords_jac_2__3;
              const double tmp_coords_jac_12__3 =
                  macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_13__3 =
                  tmp_coords_jac_12__3 * tmp_coords_jac_5__3;
              const double tmp_coords_jac_14__3 =
                  macro_vertex_coord_id_3comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_15__3 =
                  macro_vertex_coord_id_0comp1 +
                  tmp_coords_jac_14__3 * tmp_coords_jac_2__3;
              const double tmp_coords_jac_16__3 =
                  tmp_coords_jac_13__3 + tmp_coords_jac_15__3;
              const double tmp_coords_jac_17__3 =
                  macro_vertex_coord_id_2comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_18__3 =
                  tmp_coords_jac_17__3 * tmp_coords_jac_2__3;
              const double tmp_coords_jac_19__3 =
                  macro_vertex_coord_id_1comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_20__3 =
                  tmp_coords_jac_19__3 * tmp_coords_jac_5__3;
              const double tmp_coords_jac_21__3 =
                  macro_vertex_coord_id_3comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_22__3 =
                  macro_vertex_coord_id_0comp2 +
                  tmp_coords_jac_2__3 * tmp_coords_jac_21__3;
              const double tmp_coords_jac_23__3 =
                  tmp_coords_jac_20__3 + tmp_coords_jac_22__3;
              const double tmp_coords_jac_24__3 =
                  tmp_coords_jac_0__3 * tmp_coords_jac_5__3;
              const double tmp_coords_jac_25__3 =
                  tmp_coords_jac_10__3 * tmp_coords_jac_5__3;
              const double tmp_coords_jac_26__3 =
                  tmp_coords_jac_17__3 * tmp_coords_jac_5__3;
              const double p_affine_const_0_0__3 =
                  tmp_coords_jac_3__3 + tmp_coords_jac_9__3;
              const double p_affine_const_0_1__3 =
                  tmp_coords_jac_11__3 + tmp_coords_jac_16__3;
              const double p_affine_const_0_2__3 =
                  tmp_coords_jac_18__3 + tmp_coords_jac_23__3;
              const double p_affine_const_1_0__3 =
                  tmp_coords_jac_24__3 + tmp_coords_jac_8__3 +
                  tmp_coords_jac_2__3 * tmp_coords_jac_4__3;
              const double p_affine_const_1_1__3 =
                  tmp_coords_jac_15__3 + tmp_coords_jac_25__3 +
                  tmp_coords_jac_12__3 * tmp_coords_jac_2__3;
              const double p_affine_const_1_2__3 =
                  tmp_coords_jac_22__3 + tmp_coords_jac_26__3 +
                  tmp_coords_jac_19__3 * tmp_coords_jac_2__3;
              const double p_affine_const_2_0__3 =
                  tmp_coords_jac_24__3 + tmp_coords_jac_9__3;
              const double p_affine_const_2_1__3 =
                  tmp_coords_jac_16__3 + tmp_coords_jac_25__3;
              const double p_affine_const_2_2__3 =
                  tmp_coords_jac_23__3 + tmp_coords_jac_26__3;
              const double p_affine_const_3_0__3 =
                  macro_vertex_coord_id_0comp0 + tmp_coords_jac_3__3 +
                  tmp_coords_jac_6__3 +
                  tmp_coords_jac_5__3 * tmp_coords_jac_7__3;
              const double p_affine_const_3_1__3 =
                  macro_vertex_coord_id_0comp1 + tmp_coords_jac_11__3 +
                  tmp_coords_jac_13__3 +
                  tmp_coords_jac_14__3 * tmp_coords_jac_5__3;
              const double p_affine_const_3_2__3 =
                  macro_vertex_coord_id_0comp2 + tmp_coords_jac_18__3 +
                  tmp_coords_jac_20__3 +
                  tmp_coords_jac_21__3 * tmp_coords_jac_5__3;
              const double jac_affine_0_0__3 =
                  p_affine_const_1_0__3 - p_affine_const_0_0__3;
              const double jac_affine_0_1__3 =
                  p_affine_const_2_0__3 - p_affine_const_0_0__3;
              const double jac_affine_0_2__3 =
                  p_affine_const_3_0__3 - p_affine_const_0_0__3;
              const double jac_affine_1_0__3 =
                  p_affine_const_1_1__3 - p_affine_const_0_1__3;
              const double jac_affine_1_1__3 =
                  p_affine_const_2_1__3 - p_affine_const_0_1__3;
              const double tmp_coords_jac_31__2 =
                  jac_affine_0_2__3 * jac_affine_1_1__3;
              const double jac_affine_1_2__3 =
                  p_affine_const_3_1__3 - p_affine_const_0_1__3;
              const double tmp_coords_jac_29__3 =
                  jac_affine_0_1__3 * jac_affine_1_2__3;
              const double jac_affine_2_0__3 =
                  p_affine_const_1_2__3 - p_affine_const_0_2__3;
              const double jac_affine_2_1__3 =
                  p_affine_const_2_2__3 - p_affine_const_0_2__3;
              const double tmp_coords_jac_28__3 =
                  jac_affine_1_2__3 * jac_affine_2_1__3;
              const double jac_affine_2_2__3 =
                  p_affine_const_3_2__3 - p_affine_const_0_2__3;
              const double tmp_coords_jac_27__3 =
                  jac_affine_1_1__3 * jac_affine_2_2__3;
              const double tmp_coords_jac_30__3 =
                  jac_affine_0_1__3 * jac_affine_2_2__3;
              const double tmp_coords_jac_32__2 =
                  jac_affine_0_0__3 * tmp_coords_jac_27__3 +
                  jac_affine_2_0__3 * tmp_coords_jac_29__3 -
                  jac_affine_0_0__3 * tmp_coords_jac_28__3 -
                  jac_affine_1_0__3 * tmp_coords_jac_30__3 -
                  jac_affine_2_0__3 * tmp_coords_jac_31__2 +
                  jac_affine_0_2__3 * jac_affine_1_0__3 * jac_affine_2_1__3;
              const double tmp_coords_jac_33__2 = 1.0 / tmp_coords_jac_32__2;
              const double jac_affine_inv_0_0__3 =
                  tmp_coords_jac_33__2 *
                  (tmp_coords_jac_27__3 - tmp_coords_jac_28__3);
              const double jac_affine_inv_0_1__3 =
                  tmp_coords_jac_33__2 *
                  (-1.0 * tmp_coords_jac_30__3 +
                   jac_affine_0_2__3 * jac_affine_2_1__3);
              const double jac_affine_inv_0_2__3 =
                  tmp_coords_jac_33__2 *
                  (tmp_coords_jac_29__3 - tmp_coords_jac_31__2);
              const double jac_affine_inv_1_0__3 =
                  tmp_coords_jac_33__2 *
                  (jac_affine_1_2__3 * jac_affine_2_0__3 -
                   jac_affine_1_0__3 * jac_affine_2_2__3);
              const double jac_affine_inv_1_1__3 =
                  tmp_coords_jac_33__2 *
                  (jac_affine_0_0__3 * jac_affine_2_2__3 -
                   jac_affine_0_2__3 * jac_affine_2_0__3);
              const double jac_affine_inv_1_2__3 =
                  tmp_coords_jac_33__2 *
                  (jac_affine_0_2__3 * jac_affine_1_0__3 -
                   jac_affine_0_0__3 * jac_affine_1_2__3);
              const double jac_affine_inv_2_0__3 =
                  tmp_coords_jac_33__2 *
                  (jac_affine_1_0__3 * jac_affine_2_1__3 -
                   jac_affine_1_1__3 * jac_affine_2_0__3);
              const double jac_affine_inv_2_1__3 =
                  tmp_coords_jac_33__2 *
                  (jac_affine_0_1__3 * jac_affine_2_0__3 -
                   jac_affine_0_0__3 * jac_affine_2_1__3);
              const double jac_affine_inv_2_2__3 =
                  tmp_coords_jac_33__2 *
                  (jac_affine_0_0__3 * jac_affine_1_1__3 -
                   jac_affine_0_1__3 * jac_affine_1_0__3);
              const double abs_det_jac_affine__3 = abs(tmp_coords_jac_32__2);
              double phi_0_0__3[4] = {0.25, 0.25, 0.25, 0.25};
              double tabulated_and_untitled_0_0__3[10] = {
                  abs_det_jac_affine__3 *
                      ((-1.0 * jac_affine_inv_0_0__3 - jac_affine_inv_1_0__3 -
                        jac_affine_inv_2_0__3) *
                           (-1.0 * jac_affine_inv_0_0__3 -
                            jac_affine_inv_1_0__3 - jac_affine_inv_2_0__3) +
                       (-1.0 * jac_affine_inv_0_1__3 - jac_affine_inv_1_1__3 -
                        jac_affine_inv_2_1__3) *
                           (-1.0 * jac_affine_inv_0_1__3 -
                            jac_affine_inv_1_1__3 - jac_affine_inv_2_1__3) +
                       (-1.0 * jac_affine_inv_0_2__3 - jac_affine_inv_1_2__3 -
                        jac_affine_inv_2_2__3) *
                           (-1.0 * jac_affine_inv_0_2__3 -
                            jac_affine_inv_1_2__3 - jac_affine_inv_2_2__3)),
                  abs_det_jac_affine__3 *
                      (jac_affine_inv_0_0__3 *
                           (-1.0 * jac_affine_inv_0_0__3 -
                            jac_affine_inv_1_0__3 - jac_affine_inv_2_0__3) +
                       jac_affine_inv_0_1__3 *
                           (-1.0 * jac_affine_inv_0_1__3 -
                            jac_affine_inv_1_1__3 - jac_affine_inv_2_1__3) +
                       jac_affine_inv_0_2__3 *
                           (-1.0 * jac_affine_inv_0_2__3 -
                            jac_affine_inv_1_2__3 - jac_affine_inv_2_2__3)),
                  abs_det_jac_affine__3 *
                      (jac_affine_inv_1_0__3 *
                           (-1.0 * jac_affine_inv_0_0__3 -
                            jac_affine_inv_1_0__3 - jac_affine_inv_2_0__3) +
                       jac_affine_inv_1_1__3 *
                           (-1.0 * jac_affine_inv_0_1__3 -
                            jac_affine_inv_1_1__3 - jac_affine_inv_2_1__3) +
                       jac_affine_inv_1_2__3 *
                           (-1.0 * jac_affine_inv_0_2__3 -
                            jac_affine_inv_1_2__3 - jac_affine_inv_2_2__3)),
                  abs_det_jac_affine__3 *
                      (jac_affine_inv_2_0__3 *
                           (-1.0 * jac_affine_inv_0_0__3 -
                            jac_affine_inv_1_0__3 - jac_affine_inv_2_0__3) +
                       jac_affine_inv_2_1__3 *
                           (-1.0 * jac_affine_inv_0_1__3 -
                            jac_affine_inv_1_1__3 - jac_affine_inv_2_1__3) +
                       jac_affine_inv_2_2__3 *
                           (-1.0 * jac_affine_inv_0_2__3 -
                            jac_affine_inv_1_2__3 - jac_affine_inv_2_2__3)),
                  abs_det_jac_affine__3 *
                      (jac_affine_inv_0_0__3 * jac_affine_inv_0_0__3 +
                       jac_affine_inv_0_1__3 * jac_affine_inv_0_1__3 +
                       jac_affine_inv_0_2__3 * jac_affine_inv_0_2__3),
                  abs_det_jac_affine__3 *
                      (jac_affine_inv_0_0__3 * jac_affine_inv_1_0__3 +
                       jac_affine_inv_0_1__3 * jac_affine_inv_1_1__3 +
                       jac_affine_inv_0_2__3 * jac_affine_inv_1_2__3),
                  abs_det_jac_affine__3 *
                      (jac_affine_inv_0_0__3 * jac_affine_inv_2_0__3 +
                       jac_affine_inv_0_1__3 * jac_affine_inv_2_1__3 +
                       jac_affine_inv_0_2__3 * jac_affine_inv_2_2__3),
                  abs_det_jac_affine__3 *
                      (jac_affine_inv_1_0__3 * jac_affine_inv_1_0__3 +
                       jac_affine_inv_1_1__3 * jac_affine_inv_1_1__3 +
                       jac_affine_inv_1_2__3 * jac_affine_inv_1_2__3),
                  abs_det_jac_affine__3 *
                      (jac_affine_inv_1_0__3 * jac_affine_inv_2_0__3 +
                       jac_affine_inv_1_1__3 * jac_affine_inv_2_1__3 +
                       jac_affine_inv_1_2__3 * jac_affine_inv_2_2__3),
                  abs_det_jac_affine__3 *
                      (jac_affine_inv_2_0__3 * jac_affine_inv_2_0__3 +
                       jac_affine_inv_2_1__3 * jac_affine_inv_2_1__3 +
                       jac_affine_inv_2_2__3 * jac_affine_inv_2_2__3)};
              {
                const double p_affine_0_0__3 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_0_1__3 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_0_2__3 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_1_0__3 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_1_1__3 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_1_2__3 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_2_0__3 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_2_1__3 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_2_2__3 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_3_0__3 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_1__3 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_2__3 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double k_dof_0__3 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_1__3 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_2__3 =
                    _data_k[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_3__3 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                double q_acc_0_0__3 = 0.0;
                double q_acc_1_1__3 = 0.0;
                double q_acc_2_2__3 = 0.0;
                double q_acc_3_3__3 = 0.0;
                for (int64_t q__3 = 0LL; q__3 < 1LL; q__3 += 1LL) {
                  const double tmp_qloop_0__3 =
                      (k_dof_0__3 * phi_0_0__3[4LL * q__3] +
                       k_dof_1__3 * phi_0_0__3[1LL + 4LL * q__3] +
                       k_dof_2__3 * phi_0_0__3[2LL + 4LL * q__3] +
                       k_dof_3__3 * phi_0_0__3[3LL + 4LL * q__3]) *
                      q_w[q__3];
                  const double q_tmp_0_0__3 =
                      tmp_qloop_0__3 *
                      tabulated_and_untitled_0_0__3[10LL * q__3];
                  const double q_tmp_1_1__3 =
                      tmp_qloop_0__3 *
                      tabulated_and_untitled_0_0__3[4LL + 10LL * q__3];
                  const double q_tmp_2_2__3 =
                      tmp_qloop_0__3 *
                      tabulated_and_untitled_0_0__3[7LL + 10LL * q__3];
                  const double q_tmp_3_3__3 =
                      tmp_qloop_0__3 *
                      tabulated_and_untitled_0_0__3[9LL + 10LL * q__3];
                  q_acc_0_0__3 = q_acc_0_0__3 + q_tmp_0_0__3;
                  q_acc_1_1__3 = q_acc_1_1__3 + q_tmp_1_1__3;
                  q_acc_2_2__3 = q_acc_2_2__3 + q_tmp_2_2__3;
                  q_acc_3_3__3 = q_acc_3_3__3 + q_tmp_3_3__3;
                }
                const double elMatDiag_0__3 = q_acc_0_0__3;
                const double elMatDiag_1__3 = q_acc_1_1__3;
                const double elMatDiag_2__3 = q_acc_2_2__3;
                const double elMatDiag_3__3 = q_acc_3_3__3;
                _data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__0 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_0__3 +
                    _data_invDiag_
                        [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__0 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__0 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_1__3 +
                    _data_invDiag_
                        [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__0 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__0 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_2__3 +
                    _data_invDiag_
                        [1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__0 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__0 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_3__3 +
                    _data_invDiag_
                        [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__0 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
              }
            }
            {
              /* CellType.BLUE_DOWN */
              const double tmp_coords_jac_0__2 =
                  macro_vertex_coord_id_3comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_1__2 =
                  1.0 * (1.0 / micro_edges_per_macro_edge_float);
              const double tmp_coords_jac_2__2 = tmp_coords_jac_1__2 * 0.0;
              const double tmp_coords_jac_3__2 =
                  macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_4__2 = tmp_coords_jac_1__2 * 1.0;
              const double tmp_coords_jac_5__2 =
                  macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_6__2 =
                  macro_vertex_coord_id_0comp0 +
                  tmp_coords_jac_2__2 * tmp_coords_jac_5__2;
              const double tmp_coords_jac_7__2 =
                  tmp_coords_jac_6__2 +
                  tmp_coords_jac_3__2 * tmp_coords_jac_4__2;
              const double tmp_coords_jac_8__2 =
                  macro_vertex_coord_id_3comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_9__2 =
                  macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_10__2 =
                  macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_11__2 =
                  macro_vertex_coord_id_0comp1 +
                  tmp_coords_jac_10__2 * tmp_coords_jac_2__2;
              const double tmp_coords_jac_12__2 =
                  tmp_coords_jac_11__2 +
                  tmp_coords_jac_4__2 * tmp_coords_jac_9__2;
              const double tmp_coords_jac_13__2 =
                  macro_vertex_coord_id_3comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_14__2 =
                  macro_vertex_coord_id_2comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_15__2 =
                  macro_vertex_coord_id_1comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_16__2 =
                  macro_vertex_coord_id_0comp2 +
                  tmp_coords_jac_15__2 * tmp_coords_jac_2__2;
              const double tmp_coords_jac_17__2 =
                  tmp_coords_jac_16__2 +
                  tmp_coords_jac_14__2 * tmp_coords_jac_4__2;
              const double tmp_coords_jac_18__2 =
                  tmp_coords_jac_0__2 * tmp_coords_jac_4__2;
              const double tmp_coords_jac_19__2 =
                  tmp_coords_jac_18__2 +
                  tmp_coords_jac_2__2 * tmp_coords_jac_3__2;
              const double tmp_coords_jac_20__2 =
                  tmp_coords_jac_4__2 * tmp_coords_jac_8__2;
              const double tmp_coords_jac_21__2 =
                  tmp_coords_jac_20__2 +
                  tmp_coords_jac_2__2 * tmp_coords_jac_9__2;
              const double tmp_coords_jac_22__2 =
                  tmp_coords_jac_13__2 * tmp_coords_jac_4__2;
              const double tmp_coords_jac_23__2 =
                  tmp_coords_jac_22__2 +
                  tmp_coords_jac_14__2 * tmp_coords_jac_2__2;
              const double p_affine_const_0_0__2 =
                  tmp_coords_jac_7__2 +
                  tmp_coords_jac_0__2 * tmp_coords_jac_2__2;
              const double p_affine_const_0_1__2 =
                  tmp_coords_jac_12__2 +
                  tmp_coords_jac_2__2 * tmp_coords_jac_8__2;
              const double p_affine_const_0_2__2 =
                  tmp_coords_jac_17__2 +
                  tmp_coords_jac_13__2 * tmp_coords_jac_2__2;
              const double p_affine_const_1_0__2 =
                  tmp_coords_jac_19__2 + tmp_coords_jac_6__2;
              const double p_affine_const_1_1__2 =
                  tmp_coords_jac_11__2 + tmp_coords_jac_21__2;
              const double p_affine_const_1_2__2 =
                  tmp_coords_jac_16__2 + tmp_coords_jac_23__2;
              const double p_affine_const_2_0__2 =
                  macro_vertex_coord_id_0comp0 + tmp_coords_jac_19__2 +
                  tmp_coords_jac_4__2 * tmp_coords_jac_5__2;
              const double p_affine_const_2_1__2 =
                  macro_vertex_coord_id_0comp1 + tmp_coords_jac_21__2 +
                  tmp_coords_jac_10__2 * tmp_coords_jac_4__2;
              const double p_affine_const_2_2__2 =
                  macro_vertex_coord_id_0comp2 + tmp_coords_jac_23__2 +
                  tmp_coords_jac_15__2 * tmp_coords_jac_4__2;
              const double p_affine_const_3_0__2 =
                  tmp_coords_jac_18__2 + tmp_coords_jac_7__2;
              const double p_affine_const_3_1__2 =
                  tmp_coords_jac_12__2 + tmp_coords_jac_20__2;
              const double p_affine_const_3_2__2 =
                  tmp_coords_jac_17__2 + tmp_coords_jac_22__2;
              const double jac_affine_0_0__2 =
                  p_affine_const_1_0__2 - p_affine_const_0_0__2;
              const double jac_affine_0_1__2 =
                  p_affine_const_2_0__2 - p_affine_const_0_0__2;
              const double jac_affine_0_2__2 =
                  p_affine_const_3_0__2 - p_affine_const_0_0__2;
              const double jac_affine_1_0__2 =
                  p_affine_const_1_1__2 - p_affine_const_0_1__2;
              const double jac_affine_1_1__2 =
                  p_affine_const_2_1__2 - p_affine_const_0_1__2;
              const double tmp_coords_jac_28__2 =
                  jac_affine_0_2__2 * jac_affine_1_1__2;
              const double jac_affine_1_2__2 =
                  p_affine_const_3_1__2 - p_affine_const_0_1__2;
              const double tmp_coords_jac_26__2 =
                  jac_affine_0_1__2 * jac_affine_1_2__2;
              const double jac_affine_2_0__2 =
                  p_affine_const_1_2__2 - p_affine_const_0_2__2;
              const double jac_affine_2_1__2 =
                  p_affine_const_2_2__2 - p_affine_const_0_2__2;
              const double tmp_coords_jac_25__2 =
                  jac_affine_1_2__2 * jac_affine_2_1__2;
              const double jac_affine_2_2__2 =
                  p_affine_const_3_2__2 - p_affine_const_0_2__2;
              const double tmp_coords_jac_24__2 =
                  jac_affine_1_1__2 * jac_affine_2_2__2;
              const double tmp_coords_jac_27__2 =
                  jac_affine_0_1__2 * jac_affine_2_2__2;
              const double tmp_coords_jac_29__2 =
                  jac_affine_0_0__2 * tmp_coords_jac_24__2 +
                  jac_affine_2_0__2 * tmp_coords_jac_26__2 -
                  jac_affine_0_0__2 * tmp_coords_jac_25__2 -
                  jac_affine_1_0__2 * tmp_coords_jac_27__2 -
                  jac_affine_2_0__2 * tmp_coords_jac_28__2 +
                  jac_affine_0_2__2 * jac_affine_1_0__2 * jac_affine_2_1__2;
              const double tmp_coords_jac_30__2 = 1.0 / tmp_coords_jac_29__2;
              const double jac_affine_inv_0_0__2 =
                  tmp_coords_jac_30__2 *
                  (tmp_coords_jac_24__2 - tmp_coords_jac_25__2);
              const double jac_affine_inv_0_1__2 =
                  tmp_coords_jac_30__2 *
                  (-1.0 * tmp_coords_jac_27__2 +
                   jac_affine_0_2__2 * jac_affine_2_1__2);
              const double jac_affine_inv_0_2__2 =
                  tmp_coords_jac_30__2 *
                  (tmp_coords_jac_26__2 - tmp_coords_jac_28__2);
              const double jac_affine_inv_1_0__2 =
                  tmp_coords_jac_30__2 *
                  (jac_affine_1_2__2 * jac_affine_2_0__2 -
                   jac_affine_1_0__2 * jac_affine_2_2__2);
              const double jac_affine_inv_1_1__2 =
                  tmp_coords_jac_30__2 *
                  (jac_affine_0_0__2 * jac_affine_2_2__2 -
                   jac_affine_0_2__2 * jac_affine_2_0__2);
              const double jac_affine_inv_1_2__2 =
                  tmp_coords_jac_30__2 *
                  (jac_affine_0_2__2 * jac_affine_1_0__2 -
                   jac_affine_0_0__2 * jac_affine_1_2__2);
              const double jac_affine_inv_2_0__2 =
                  tmp_coords_jac_30__2 *
                  (jac_affine_1_0__2 * jac_affine_2_1__2 -
                   jac_affine_1_1__2 * jac_affine_2_0__2);
              const double jac_affine_inv_2_1__2 =
                  tmp_coords_jac_30__2 *
                  (jac_affine_0_1__2 * jac_affine_2_0__2 -
                   jac_affine_0_0__2 * jac_affine_2_1__2);
              const double jac_affine_inv_2_2__2 =
                  tmp_coords_jac_30__2 *
                  (jac_affine_0_0__2 * jac_affine_1_1__2 -
                   jac_affine_0_1__2 * jac_affine_1_0__2);
              const double abs_det_jac_affine__2 = abs(tmp_coords_jac_29__2);
              double phi_0_0__2[4] = {0.25, 0.25, 0.25, 0.25};
              double tabulated_and_untitled_0_0__2[10] = {
                  abs_det_jac_affine__2 *
                      ((-1.0 * jac_affine_inv_0_0__2 - jac_affine_inv_1_0__2 -
                        jac_affine_inv_2_0__2) *
                           (-1.0 * jac_affine_inv_0_0__2 -
                            jac_affine_inv_1_0__2 - jac_affine_inv_2_0__2) +
                       (-1.0 * jac_affine_inv_0_1__2 - jac_affine_inv_1_1__2 -
                        jac_affine_inv_2_1__2) *
                           (-1.0 * jac_affine_inv_0_1__2 -
                            jac_affine_inv_1_1__2 - jac_affine_inv_2_1__2) +
                       (-1.0 * jac_affine_inv_0_2__2 - jac_affine_inv_1_2__2 -
                        jac_affine_inv_2_2__2) *
                           (-1.0 * jac_affine_inv_0_2__2 -
                            jac_affine_inv_1_2__2 - jac_affine_inv_2_2__2)),
                  abs_det_jac_affine__2 *
                      (jac_affine_inv_0_0__2 *
                           (-1.0 * jac_affine_inv_0_0__2 -
                            jac_affine_inv_1_0__2 - jac_affine_inv_2_0__2) +
                       jac_affine_inv_0_1__2 *
                           (-1.0 * jac_affine_inv_0_1__2 -
                            jac_affine_inv_1_1__2 - jac_affine_inv_2_1__2) +
                       jac_affine_inv_0_2__2 *
                           (-1.0 * jac_affine_inv_0_2__2 -
                            jac_affine_inv_1_2__2 - jac_affine_inv_2_2__2)),
                  abs_det_jac_affine__2 *
                      (jac_affine_inv_1_0__2 *
                           (-1.0 * jac_affine_inv_0_0__2 -
                            jac_affine_inv_1_0__2 - jac_affine_inv_2_0__2) +
                       jac_affine_inv_1_1__2 *
                           (-1.0 * jac_affine_inv_0_1__2 -
                            jac_affine_inv_1_1__2 - jac_affine_inv_2_1__2) +
                       jac_affine_inv_1_2__2 *
                           (-1.0 * jac_affine_inv_0_2__2 -
                            jac_affine_inv_1_2__2 - jac_affine_inv_2_2__2)),
                  abs_det_jac_affine__2 *
                      (jac_affine_inv_2_0__2 *
                           (-1.0 * jac_affine_inv_0_0__2 -
                            jac_affine_inv_1_0__2 - jac_affine_inv_2_0__2) +
                       jac_affine_inv_2_1__2 *
                           (-1.0 * jac_affine_inv_0_1__2 -
                            jac_affine_inv_1_1__2 - jac_affine_inv_2_1__2) +
                       jac_affine_inv_2_2__2 *
                           (-1.0 * jac_affine_inv_0_2__2 -
                            jac_affine_inv_1_2__2 - jac_affine_inv_2_2__2)),
                  abs_det_jac_affine__2 *
                      (jac_affine_inv_0_0__2 * jac_affine_inv_0_0__2 +
                       jac_affine_inv_0_1__2 * jac_affine_inv_0_1__2 +
                       jac_affine_inv_0_2__2 * jac_affine_inv_0_2__2),
                  abs_det_jac_affine__2 *
                      (jac_affine_inv_0_0__2 * jac_affine_inv_1_0__2 +
                       jac_affine_inv_0_1__2 * jac_affine_inv_1_1__2 +
                       jac_affine_inv_0_2__2 * jac_affine_inv_1_2__2),
                  abs_det_jac_affine__2 *
                      (jac_affine_inv_0_0__2 * jac_affine_inv_2_0__2 +
                       jac_affine_inv_0_1__2 * jac_affine_inv_2_1__2 +
                       jac_affine_inv_0_2__2 * jac_affine_inv_2_2__2),
                  abs_det_jac_affine__2 *
                      (jac_affine_inv_1_0__2 * jac_affine_inv_1_0__2 +
                       jac_affine_inv_1_1__2 * jac_affine_inv_1_1__2 +
                       jac_affine_inv_1_2__2 * jac_affine_inv_1_2__2),
                  abs_det_jac_affine__2 *
                      (jac_affine_inv_1_0__2 * jac_affine_inv_2_0__2 +
                       jac_affine_inv_1_1__2 * jac_affine_inv_2_1__2 +
                       jac_affine_inv_1_2__2 * jac_affine_inv_2_2__2),
                  abs_det_jac_affine__2 *
                      (jac_affine_inv_2_0__2 * jac_affine_inv_2_0__2 +
                       jac_affine_inv_2_1__2 * jac_affine_inv_2_1__2 +
                       jac_affine_inv_2_2__2 * jac_affine_inv_2_2__2)};
              {
                const double p_affine_0_0__2 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_0_1__2 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_0_2__2 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_1_0__2 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_1_1__2 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_1_2__2 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_0__2 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_1__2 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_2__2 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_0__2 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_1__2 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_2__2 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double k_dof_0__2 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_1__2 =
                    _data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_2__2 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_3__2 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                double q_acc_0_0__2 = 0.0;
                double q_acc_1_1__2 = 0.0;
                double q_acc_2_2__2 = 0.0;
                double q_acc_3_3__2 = 0.0;
                for (int64_t q__2 = 0LL; q__2 < 1LL; q__2 += 1LL) {
                  const double tmp_qloop_0__2 =
                      (k_dof_0__2 * phi_0_0__2[4LL * q__2] +
                       k_dof_1__2 * phi_0_0__2[1LL + 4LL * q__2] +
                       k_dof_2__2 * phi_0_0__2[2LL + 4LL * q__2] +
                       k_dof_3__2 * phi_0_0__2[3LL + 4LL * q__2]) *
                      q_w[q__2];
                  const double q_tmp_0_0__2 =
                      tmp_qloop_0__2 *
                      tabulated_and_untitled_0_0__2[10LL * q__2];
                  const double q_tmp_1_1__2 =
                      tmp_qloop_0__2 *
                      tabulated_and_untitled_0_0__2[4LL + 10LL * q__2];
                  const double q_tmp_2_2__2 =
                      tmp_qloop_0__2 *
                      tabulated_and_untitled_0_0__2[7LL + 10LL * q__2];
                  const double q_tmp_3_3__2 =
                      tmp_qloop_0__2 *
                      tabulated_and_untitled_0_0__2[9LL + 10LL * q__2];
                  q_acc_0_0__2 = q_acc_0_0__2 + q_tmp_0_0__2;
                  q_acc_1_1__2 = q_acc_1_1__2 + q_tmp_1_1__2;
                  q_acc_2_2__2 = q_acc_2_2__2 + q_tmp_2_2__2;
                  q_acc_3_3__2 = q_acc_3_3__2 + q_tmp_3_3__2;
                }
                const double elMatDiag_0__2 = q_acc_0_0__2;
                const double elMatDiag_1__2 = q_acc_1_1__2;
                const double elMatDiag_2__2 = q_acc_2_2__2;
                const double elMatDiag_3__2 = q_acc_3_3__2;
                _data_invDiag_[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__0 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_0__2 +
                    _data_invDiag_
                        [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__0 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__0 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_1__2 +
                    _data_invDiag_
                        [-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__0 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__0 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_2__2 +
                    _data_invDiag_
                        [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__0 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__0 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_3__2 +
                    _data_invDiag_
                        [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__0 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
              }
            }
            {
              /* CellType.GREEN_UP */
              const double tmp_coords_jac_0__1 =
                  macro_vertex_coord_id_3comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_1__1 =
                  1.0 * (1.0 / micro_edges_per_macro_edge_float);
              const double tmp_coords_jac_2__1 = tmp_coords_jac_1__1 * 0.0;
              const double tmp_coords_jac_3__1 =
                  macro_vertex_coord_id_0comp0 +
                  tmp_coords_jac_0__1 * tmp_coords_jac_2__1;
              const double tmp_coords_jac_4__1 =
                  macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_5__1 = tmp_coords_jac_1__1 * 1.0;
              const double tmp_coords_jac_6__1 =
                  macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_7__1 =
                  tmp_coords_jac_2__1 * tmp_coords_jac_6__1;
              const double tmp_coords_jac_8__1 =
                  tmp_coords_jac_7__1 +
                  tmp_coords_jac_4__1 * tmp_coords_jac_5__1;
              const double tmp_coords_jac_9__1 =
                  macro_vertex_coord_id_3comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_10__1 =
                  macro_vertex_coord_id_0comp1 +
                  tmp_coords_jac_2__1 * tmp_coords_jac_9__1;
              const double tmp_coords_jac_11__1 =
                  macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_12__1 =
                  macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_13__1 =
                  tmp_coords_jac_12__1 * tmp_coords_jac_2__1;
              const double tmp_coords_jac_14__1 =
                  tmp_coords_jac_13__1 +
                  tmp_coords_jac_11__1 * tmp_coords_jac_5__1;
              const double tmp_coords_jac_15__1 =
                  macro_vertex_coord_id_3comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_16__1 =
                  macro_vertex_coord_id_0comp2 +
                  tmp_coords_jac_15__1 * tmp_coords_jac_2__1;
              const double tmp_coords_jac_17__1 =
                  macro_vertex_coord_id_1comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_18__1 =
                  macro_vertex_coord_id_2comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_19__1 =
                  tmp_coords_jac_18__1 * tmp_coords_jac_2__1;
              const double tmp_coords_jac_20__1 =
                  tmp_coords_jac_19__1 +
                  tmp_coords_jac_17__1 * tmp_coords_jac_5__1;
              const double tmp_coords_jac_21__1 =
                  tmp_coords_jac_2__1 * tmp_coords_jac_4__1;
              const double tmp_coords_jac_22__1 =
                  tmp_coords_jac_11__1 * tmp_coords_jac_2__1;
              const double tmp_coords_jac_23__1 =
                  tmp_coords_jac_17__1 * tmp_coords_jac_2__1;
              const double tmp_coords_jac_24__1 =
                  macro_vertex_coord_id_0comp0 +
                  tmp_coords_jac_0__1 * tmp_coords_jac_5__1;
              const double tmp_coords_jac_25__1 =
                  macro_vertex_coord_id_0comp1 +
                  tmp_coords_jac_5__1 * tmp_coords_jac_9__1;
              const double tmp_coords_jac_26__1 =
                  macro_vertex_coord_id_0comp2 +
                  tmp_coords_jac_15__1 * tmp_coords_jac_5__1;
              const double p_affine_const_0_0__1 =
                  tmp_coords_jac_3__1 + tmp_coords_jac_8__1;
              const double p_affine_const_0_1__1 =
                  tmp_coords_jac_10__1 + tmp_coords_jac_14__1;
              const double p_affine_const_0_2__1 =
                  tmp_coords_jac_16__1 + tmp_coords_jac_20__1;
              const double p_affine_const_1_0__1 =
                  tmp_coords_jac_21__1 + tmp_coords_jac_3__1 +
                  tmp_coords_jac_5__1 * tmp_coords_jac_6__1;
              const double p_affine_const_1_1__1 =
                  tmp_coords_jac_10__1 + tmp_coords_jac_22__1 +
                  tmp_coords_jac_12__1 * tmp_coords_jac_5__1;
              const double p_affine_const_1_2__1 =
                  tmp_coords_jac_16__1 + tmp_coords_jac_23__1 +
                  tmp_coords_jac_18__1 * tmp_coords_jac_5__1;
              const double p_affine_const_2_0__1 = tmp_coords_jac_21__1 +
                                                   tmp_coords_jac_24__1 +
                                                   tmp_coords_jac_7__1;
              const double p_affine_const_2_1__1 = tmp_coords_jac_13__1 +
                                                   tmp_coords_jac_22__1 +
                                                   tmp_coords_jac_25__1;
              const double p_affine_const_2_2__1 = tmp_coords_jac_19__1 +
                                                   tmp_coords_jac_23__1 +
                                                   tmp_coords_jac_26__1;
              const double p_affine_const_3_0__1 =
                  tmp_coords_jac_24__1 + tmp_coords_jac_8__1;
              const double p_affine_const_3_1__1 =
                  tmp_coords_jac_14__1 + tmp_coords_jac_25__1;
              const double p_affine_const_3_2__1 =
                  tmp_coords_jac_20__1 + tmp_coords_jac_26__1;
              const double jac_affine_0_0__1 =
                  p_affine_const_1_0__1 - p_affine_const_0_0__1;
              const double jac_affine_0_1__1 =
                  p_affine_const_2_0__1 - p_affine_const_0_0__1;
              const double jac_affine_0_2__1 =
                  p_affine_const_3_0__1 - p_affine_const_0_0__1;
              const double jac_affine_1_0__1 =
                  p_affine_const_1_1__1 - p_affine_const_0_1__1;
              const double jac_affine_1_1__1 =
                  p_affine_const_2_1__1 - p_affine_const_0_1__1;
              const double tmp_coords_jac_31__1 =
                  jac_affine_0_2__1 * jac_affine_1_1__1;
              const double jac_affine_1_2__1 =
                  p_affine_const_3_1__1 - p_affine_const_0_1__1;
              const double tmp_coords_jac_29__1 =
                  jac_affine_0_1__1 * jac_affine_1_2__1;
              const double jac_affine_2_0__1 =
                  p_affine_const_1_2__1 - p_affine_const_0_2__1;
              const double jac_affine_2_1__1 =
                  p_affine_const_2_2__1 - p_affine_const_0_2__1;
              const double tmp_coords_jac_28__1 =
                  jac_affine_1_2__1 * jac_affine_2_1__1;
              const double jac_affine_2_2__1 =
                  p_affine_const_3_2__1 - p_affine_const_0_2__1;
              const double tmp_coords_jac_27__1 =
                  jac_affine_1_1__1 * jac_affine_2_2__1;
              const double tmp_coords_jac_30__1 =
                  jac_affine_0_1__1 * jac_affine_2_2__1;
              const double tmp_coords_jac_32__1 =
                  jac_affine_0_0__1 * tmp_coords_jac_27__1 +
                  jac_affine_2_0__1 * tmp_coords_jac_29__1 -
                  jac_affine_0_0__1 * tmp_coords_jac_28__1 -
                  jac_affine_1_0__1 * tmp_coords_jac_30__1 -
                  jac_affine_2_0__1 * tmp_coords_jac_31__1 +
                  jac_affine_0_2__1 * jac_affine_1_0__1 * jac_affine_2_1__1;
              const double tmp_coords_jac_33__1 = 1.0 / tmp_coords_jac_32__1;
              const double jac_affine_inv_0_0__1 =
                  tmp_coords_jac_33__1 *
                  (tmp_coords_jac_27__1 - tmp_coords_jac_28__1);
              const double jac_affine_inv_0_1__1 =
                  tmp_coords_jac_33__1 *
                  (-1.0 * tmp_coords_jac_30__1 +
                   jac_affine_0_2__1 * jac_affine_2_1__1);
              const double jac_affine_inv_0_2__1 =
                  tmp_coords_jac_33__1 *
                  (tmp_coords_jac_29__1 - tmp_coords_jac_31__1);
              const double jac_affine_inv_1_0__1 =
                  tmp_coords_jac_33__1 *
                  (jac_affine_1_2__1 * jac_affine_2_0__1 -
                   jac_affine_1_0__1 * jac_affine_2_2__1);
              const double jac_affine_inv_1_1__1 =
                  tmp_coords_jac_33__1 *
                  (jac_affine_0_0__1 * jac_affine_2_2__1 -
                   jac_affine_0_2__1 * jac_affine_2_0__1);
              const double jac_affine_inv_1_2__1 =
                  tmp_coords_jac_33__1 *
                  (jac_affine_0_2__1 * jac_affine_1_0__1 -
                   jac_affine_0_0__1 * jac_affine_1_2__1);
              const double jac_affine_inv_2_0__1 =
                  tmp_coords_jac_33__1 *
                  (jac_affine_1_0__1 * jac_affine_2_1__1 -
                   jac_affine_1_1__1 * jac_affine_2_0__1);
              const double jac_affine_inv_2_1__1 =
                  tmp_coords_jac_33__1 *
                  (jac_affine_0_1__1 * jac_affine_2_0__1 -
                   jac_affine_0_0__1 * jac_affine_2_1__1);
              const double jac_affine_inv_2_2__1 =
                  tmp_coords_jac_33__1 *
                  (jac_affine_0_0__1 * jac_affine_1_1__1 -
                   jac_affine_0_1__1 * jac_affine_1_0__1);
              const double abs_det_jac_affine__1 = abs(tmp_coords_jac_32__1);
              double phi_0_0__1[4] = {0.25, 0.25, 0.25, 0.25};
              double tabulated_and_untitled_0_0__1[10] = {
                  abs_det_jac_affine__1 *
                      ((-1.0 * jac_affine_inv_0_0__1 - jac_affine_inv_1_0__1 -
                        jac_affine_inv_2_0__1) *
                           (-1.0 * jac_affine_inv_0_0__1 -
                            jac_affine_inv_1_0__1 - jac_affine_inv_2_0__1) +
                       (-1.0 * jac_affine_inv_0_1__1 - jac_affine_inv_1_1__1 -
                        jac_affine_inv_2_1__1) *
                           (-1.0 * jac_affine_inv_0_1__1 -
                            jac_affine_inv_1_1__1 - jac_affine_inv_2_1__1) +
                       (-1.0 * jac_affine_inv_0_2__1 - jac_affine_inv_1_2__1 -
                        jac_affine_inv_2_2__1) *
                           (-1.0 * jac_affine_inv_0_2__1 -
                            jac_affine_inv_1_2__1 - jac_affine_inv_2_2__1)),
                  abs_det_jac_affine__1 *
                      (jac_affine_inv_0_0__1 *
                           (-1.0 * jac_affine_inv_0_0__1 -
                            jac_affine_inv_1_0__1 - jac_affine_inv_2_0__1) +
                       jac_affine_inv_0_1__1 *
                           (-1.0 * jac_affine_inv_0_1__1 -
                            jac_affine_inv_1_1__1 - jac_affine_inv_2_1__1) +
                       jac_affine_inv_0_2__1 *
                           (-1.0 * jac_affine_inv_0_2__1 -
                            jac_affine_inv_1_2__1 - jac_affine_inv_2_2__1)),
                  abs_det_jac_affine__1 *
                      (jac_affine_inv_1_0__1 *
                           (-1.0 * jac_affine_inv_0_0__1 -
                            jac_affine_inv_1_0__1 - jac_affine_inv_2_0__1) +
                       jac_affine_inv_1_1__1 *
                           (-1.0 * jac_affine_inv_0_1__1 -
                            jac_affine_inv_1_1__1 - jac_affine_inv_2_1__1) +
                       jac_affine_inv_1_2__1 *
                           (-1.0 * jac_affine_inv_0_2__1 -
                            jac_affine_inv_1_2__1 - jac_affine_inv_2_2__1)),
                  abs_det_jac_affine__1 *
                      (jac_affine_inv_2_0__1 *
                           (-1.0 * jac_affine_inv_0_0__1 -
                            jac_affine_inv_1_0__1 - jac_affine_inv_2_0__1) +
                       jac_affine_inv_2_1__1 *
                           (-1.0 * jac_affine_inv_0_1__1 -
                            jac_affine_inv_1_1__1 - jac_affine_inv_2_1__1) +
                       jac_affine_inv_2_2__1 *
                           (-1.0 * jac_affine_inv_0_2__1 -
                            jac_affine_inv_1_2__1 - jac_affine_inv_2_2__1)),
                  abs_det_jac_affine__1 *
                      (jac_affine_inv_0_0__1 * jac_affine_inv_0_0__1 +
                       jac_affine_inv_0_1__1 * jac_affine_inv_0_1__1 +
                       jac_affine_inv_0_2__1 * jac_affine_inv_0_2__1),
                  abs_det_jac_affine__1 *
                      (jac_affine_inv_0_0__1 * jac_affine_inv_1_0__1 +
                       jac_affine_inv_0_1__1 * jac_affine_inv_1_1__1 +
                       jac_affine_inv_0_2__1 * jac_affine_inv_1_2__1),
                  abs_det_jac_affine__1 *
                      (jac_affine_inv_0_0__1 * jac_affine_inv_2_0__1 +
                       jac_affine_inv_0_1__1 * jac_affine_inv_2_1__1 +
                       jac_affine_inv_0_2__1 * jac_affine_inv_2_2__1),
                  abs_det_jac_affine__1 *
                      (jac_affine_inv_1_0__1 * jac_affine_inv_1_0__1 +
                       jac_affine_inv_1_1__1 * jac_affine_inv_1_1__1 +
                       jac_affine_inv_1_2__1 * jac_affine_inv_1_2__1),
                  abs_det_jac_affine__1 *
                      (jac_affine_inv_1_0__1 * jac_affine_inv_2_0__1 +
                       jac_affine_inv_1_1__1 * jac_affine_inv_2_1__1 +
                       jac_affine_inv_1_2__1 * jac_affine_inv_2_2__1),
                  abs_det_jac_affine__1 *
                      (jac_affine_inv_2_0__1 * jac_affine_inv_2_0__1 +
                       jac_affine_inv_2_1__1 * jac_affine_inv_2_1__1 +
                       jac_affine_inv_2_2__1 * jac_affine_inv_2_2__1)};
              {
                const double p_affine_0_0__1 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_0_1__1 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_0_2__1 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_1_0__1 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_1_1__1 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_1_2__1 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_2_0__1 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_1__1 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_2__1 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_0__1 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_1__1 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_2__1 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double k_dof_0__1 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_1__1 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_2__1 =
                    _data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_3__1 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                double q_acc_0_0__1 = 0.0;
                double q_acc_1_1__1 = 0.0;
                double q_acc_2_2__1 = 0.0;
                double q_acc_3_3__1 = 0.0;
                for (int64_t q__1 = 0LL; q__1 < 1LL; q__1 += 1LL) {
                  const double tmp_qloop_0__1 =
                      (k_dof_0__1 * phi_0_0__1[4LL * q__1] +
                       k_dof_1__1 * phi_0_0__1[1LL + 4LL * q__1] +
                       k_dof_2__1 * phi_0_0__1[2LL + 4LL * q__1] +
                       k_dof_3__1 * phi_0_0__1[3LL + 4LL * q__1]) *
                      q_w[q__1];
                  const double q_tmp_0_0__1 =
                      tmp_qloop_0__1 *
                      tabulated_and_untitled_0_0__1[10LL * q__1];
                  const double q_tmp_1_1__1 =
                      tmp_qloop_0__1 *
                      tabulated_and_untitled_0_0__1[4LL + 10LL * q__1];
                  const double q_tmp_2_2__1 =
                      tmp_qloop_0__1 *
                      tabulated_and_untitled_0_0__1[7LL + 10LL * q__1];
                  const double q_tmp_3_3__1 =
                      tmp_qloop_0__1 *
                      tabulated_and_untitled_0_0__1[9LL + 10LL * q__1];
                  q_acc_0_0__1 = q_acc_0_0__1 + q_tmp_0_0__1;
                  q_acc_1_1__1 = q_acc_1_1__1 + q_tmp_1_1__1;
                  q_acc_2_2__1 = q_acc_2_2__1 + q_tmp_2_2__1;
                  q_acc_3_3__1 = q_acc_3_3__1 + q_tmp_3_3__1;
                }
                const double elMatDiag_0__1 = q_acc_0_0__1;
                const double elMatDiag_1__1 = q_acc_1_1__1;
                const double elMatDiag_2__1 = q_acc_2_2__1;
                const double elMatDiag_3__1 = q_acc_3_3__1;
                _data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__0 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_0__1 +
                    _data_invDiag_
                        [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__0 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__0 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_1__1 +
                    _data_invDiag_
                        [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__0 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__0 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_2__1 +
                    _data_invDiag_
                        [-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__0 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__0 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_3__1 +
                    _data_invDiag_
                        [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__0 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
              }
            }
            {
              /* CellType.GREEN_DOWN */
              const double tmp_coords_jac_0__0 =
                  macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_1__0 =
                  1.0 * (1.0 / micro_edges_per_macro_edge_float);
              const double tmp_coords_jac_2__0 = tmp_coords_jac_1__0 * 0.0;
              const double tmp_coords_jac_3__0 =
                  tmp_coords_jac_0__0 * tmp_coords_jac_2__0;
              const double tmp_coords_jac_4__0 =
                  macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_5__0 = tmp_coords_jac_1__0 * 1.0;
              const double tmp_coords_jac_6__0 =
                  tmp_coords_jac_4__0 * tmp_coords_jac_5__0;
              const double tmp_coords_jac_7__0 =
                  macro_vertex_coord_id_3comp0 - macro_vertex_coord_id_0comp0;
              const double tmp_coords_jac_8__0 =
                  macro_vertex_coord_id_0comp0 + tmp_coords_jac_6__0 +
                  tmp_coords_jac_2__0 * tmp_coords_jac_7__0;
              const double tmp_coords_jac_9__0 =
                  macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_10__0 =
                  tmp_coords_jac_2__0 * tmp_coords_jac_9__0;
              const double tmp_coords_jac_11__0 =
                  macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_12__0 =
                  tmp_coords_jac_11__0 * tmp_coords_jac_5__0;
              const double tmp_coords_jac_13__0 =
                  macro_vertex_coord_id_3comp1 - macro_vertex_coord_id_0comp1;
              const double tmp_coords_jac_14__0 =
                  macro_vertex_coord_id_0comp1 + tmp_coords_jac_12__0 +
                  tmp_coords_jac_13__0 * tmp_coords_jac_2__0;
              const double tmp_coords_jac_15__0 =
                  macro_vertex_coord_id_1comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_16__0 =
                  tmp_coords_jac_15__0 * tmp_coords_jac_2__0;
              const double tmp_coords_jac_17__0 =
                  macro_vertex_coord_id_2comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_18__0 =
                  tmp_coords_jac_17__0 * tmp_coords_jac_5__0;
              const double tmp_coords_jac_19__0 =
                  macro_vertex_coord_id_3comp2 - macro_vertex_coord_id_0comp2;
              const double tmp_coords_jac_20__0 =
                  macro_vertex_coord_id_0comp2 + tmp_coords_jac_18__0 +
                  tmp_coords_jac_19__0 * tmp_coords_jac_2__0;
              const double tmp_coords_jac_21__0 =
                  tmp_coords_jac_0__0 * tmp_coords_jac_5__0;
              const double tmp_coords_jac_22__0 =
                  tmp_coords_jac_5__0 * tmp_coords_jac_9__0;
              const double tmp_coords_jac_23__0 =
                  tmp_coords_jac_15__0 * tmp_coords_jac_5__0;
              const double tmp_coords_jac_24__0 =
                  macro_vertex_coord_id_0comp0 +
                  tmp_coords_jac_5__0 * tmp_coords_jac_7__0;
              const double tmp_coords_jac_25__0 =
                  macro_vertex_coord_id_0comp1 +
                  tmp_coords_jac_13__0 * tmp_coords_jac_5__0;
              const double tmp_coords_jac_26__0 =
                  macro_vertex_coord_id_0comp2 +
                  tmp_coords_jac_19__0 * tmp_coords_jac_5__0;
              const double p_affine_const_0_0__0 =
                  tmp_coords_jac_3__0 + tmp_coords_jac_8__0;
              const double p_affine_const_0_1__0 =
                  tmp_coords_jac_10__0 + tmp_coords_jac_14__0;
              const double p_affine_const_0_2__0 =
                  tmp_coords_jac_16__0 + tmp_coords_jac_20__0;
              const double p_affine_const_1_0__0 =
                  tmp_coords_jac_21__0 + tmp_coords_jac_8__0;
              const double p_affine_const_1_1__0 =
                  tmp_coords_jac_14__0 + tmp_coords_jac_22__0;
              const double p_affine_const_1_2__0 =
                  tmp_coords_jac_20__0 + tmp_coords_jac_23__0;
              const double p_affine_const_2_0__0 =
                  tmp_coords_jac_21__0 + tmp_coords_jac_24__0 +
                  tmp_coords_jac_2__0 * tmp_coords_jac_4__0;
              const double p_affine_const_2_1__0 =
                  tmp_coords_jac_22__0 + tmp_coords_jac_25__0 +
                  tmp_coords_jac_11__0 * tmp_coords_jac_2__0;
              const double p_affine_const_2_2__0 =
                  tmp_coords_jac_23__0 + tmp_coords_jac_26__0 +
                  tmp_coords_jac_17__0 * tmp_coords_jac_2__0;
              const double p_affine_const_3_0__0 = tmp_coords_jac_24__0 +
                                                   tmp_coords_jac_3__0 +
                                                   tmp_coords_jac_6__0;
              const double p_affine_const_3_1__0 = tmp_coords_jac_10__0 +
                                                   tmp_coords_jac_12__0 +
                                                   tmp_coords_jac_25__0;
              const double p_affine_const_3_2__0 = tmp_coords_jac_16__0 +
                                                   tmp_coords_jac_18__0 +
                                                   tmp_coords_jac_26__0;
              const double jac_affine_0_0__0 =
                  p_affine_const_1_0__0 - p_affine_const_0_0__0;
              const double jac_affine_0_1__0 =
                  p_affine_const_2_0__0 - p_affine_const_0_0__0;
              const double jac_affine_0_2__0 =
                  p_affine_const_3_0__0 - p_affine_const_0_0__0;
              const double jac_affine_1_0__0 =
                  p_affine_const_1_1__0 - p_affine_const_0_1__0;
              const double jac_affine_1_1__0 =
                  p_affine_const_2_1__0 - p_affine_const_0_1__0;
              const double tmp_coords_jac_31__0 =
                  jac_affine_0_2__0 * jac_affine_1_1__0;
              const double jac_affine_1_2__0 =
                  p_affine_const_3_1__0 - p_affine_const_0_1__0;
              const double tmp_coords_jac_29__0 =
                  jac_affine_0_1__0 * jac_affine_1_2__0;
              const double jac_affine_2_0__0 =
                  p_affine_const_1_2__0 - p_affine_const_0_2__0;
              const double jac_affine_2_1__0 =
                  p_affine_const_2_2__0 - p_affine_const_0_2__0;
              const double tmp_coords_jac_28__0 =
                  jac_affine_1_2__0 * jac_affine_2_1__0;
              const double jac_affine_2_2__0 =
                  p_affine_const_3_2__0 - p_affine_const_0_2__0;
              const double tmp_coords_jac_27__0 =
                  jac_affine_1_1__0 * jac_affine_2_2__0;
              const double tmp_coords_jac_30__0 =
                  jac_affine_0_1__0 * jac_affine_2_2__0;
              const double tmp_coords_jac_32__0 =
                  jac_affine_0_0__0 * tmp_coords_jac_27__0 +
                  jac_affine_2_0__0 * tmp_coords_jac_29__0 -
                  jac_affine_0_0__0 * tmp_coords_jac_28__0 -
                  jac_affine_1_0__0 * tmp_coords_jac_30__0 -
                  jac_affine_2_0__0 * tmp_coords_jac_31__0 +
                  jac_affine_0_2__0 * jac_affine_1_0__0 * jac_affine_2_1__0;
              const double tmp_coords_jac_33__0 = 1.0 / tmp_coords_jac_32__0;
              const double jac_affine_inv_0_0__0 =
                  tmp_coords_jac_33__0 *
                  (tmp_coords_jac_27__0 - tmp_coords_jac_28__0);
              const double jac_affine_inv_0_1__0 =
                  tmp_coords_jac_33__0 *
                  (-1.0 * tmp_coords_jac_30__0 +
                   jac_affine_0_2__0 * jac_affine_2_1__0);
              const double jac_affine_inv_0_2__0 =
                  tmp_coords_jac_33__0 *
                  (tmp_coords_jac_29__0 - tmp_coords_jac_31__0);
              const double jac_affine_inv_1_0__0 =
                  tmp_coords_jac_33__0 *
                  (jac_affine_1_2__0 * jac_affine_2_0__0 -
                   jac_affine_1_0__0 * jac_affine_2_2__0);
              const double jac_affine_inv_1_1__0 =
                  tmp_coords_jac_33__0 *
                  (jac_affine_0_0__0 * jac_affine_2_2__0 -
                   jac_affine_0_2__0 * jac_affine_2_0__0);
              const double jac_affine_inv_1_2__0 =
                  tmp_coords_jac_33__0 *
                  (jac_affine_0_2__0 * jac_affine_1_0__0 -
                   jac_affine_0_0__0 * jac_affine_1_2__0);
              const double jac_affine_inv_2_0__0 =
                  tmp_coords_jac_33__0 *
                  (jac_affine_1_0__0 * jac_affine_2_1__0 -
                   jac_affine_1_1__0 * jac_affine_2_0__0);
              const double jac_affine_inv_2_1__0 =
                  tmp_coords_jac_33__0 *
                  (jac_affine_0_1__0 * jac_affine_2_0__0 -
                   jac_affine_0_0__0 * jac_affine_2_1__0);
              const double jac_affine_inv_2_2__0 =
                  tmp_coords_jac_33__0 *
                  (jac_affine_0_0__0 * jac_affine_1_1__0 -
                   jac_affine_0_1__0 * jac_affine_1_0__0);
              const double abs_det_jac_affine__0 = abs(tmp_coords_jac_32__0);
              double phi_0_0__0[4] = {0.25, 0.25, 0.25, 0.25};
              double tabulated_and_untitled_0_0__0[10] = {
                  abs_det_jac_affine__0 *
                      ((-1.0 * jac_affine_inv_0_0__0 - jac_affine_inv_1_0__0 -
                        jac_affine_inv_2_0__0) *
                           (-1.0 * jac_affine_inv_0_0__0 -
                            jac_affine_inv_1_0__0 - jac_affine_inv_2_0__0) +
                       (-1.0 * jac_affine_inv_0_1__0 - jac_affine_inv_1_1__0 -
                        jac_affine_inv_2_1__0) *
                           (-1.0 * jac_affine_inv_0_1__0 -
                            jac_affine_inv_1_1__0 - jac_affine_inv_2_1__0) +
                       (-1.0 * jac_affine_inv_0_2__0 - jac_affine_inv_1_2__0 -
                        jac_affine_inv_2_2__0) *
                           (-1.0 * jac_affine_inv_0_2__0 -
                            jac_affine_inv_1_2__0 - jac_affine_inv_2_2__0)),
                  abs_det_jac_affine__0 *
                      (jac_affine_inv_0_0__0 *
                           (-1.0 * jac_affine_inv_0_0__0 -
                            jac_affine_inv_1_0__0 - jac_affine_inv_2_0__0) +
                       jac_affine_inv_0_1__0 *
                           (-1.0 * jac_affine_inv_0_1__0 -
                            jac_affine_inv_1_1__0 - jac_affine_inv_2_1__0) +
                       jac_affine_inv_0_2__0 *
                           (-1.0 * jac_affine_inv_0_2__0 -
                            jac_affine_inv_1_2__0 - jac_affine_inv_2_2__0)),
                  abs_det_jac_affine__0 *
                      (jac_affine_inv_1_0__0 *
                           (-1.0 * jac_affine_inv_0_0__0 -
                            jac_affine_inv_1_0__0 - jac_affine_inv_2_0__0) +
                       jac_affine_inv_1_1__0 *
                           (-1.0 * jac_affine_inv_0_1__0 -
                            jac_affine_inv_1_1__0 - jac_affine_inv_2_1__0) +
                       jac_affine_inv_1_2__0 *
                           (-1.0 * jac_affine_inv_0_2__0 -
                            jac_affine_inv_1_2__0 - jac_affine_inv_2_2__0)),
                  abs_det_jac_affine__0 *
                      (jac_affine_inv_2_0__0 *
                           (-1.0 * jac_affine_inv_0_0__0 -
                            jac_affine_inv_1_0__0 - jac_affine_inv_2_0__0) +
                       jac_affine_inv_2_1__0 *
                           (-1.0 * jac_affine_inv_0_1__0 -
                            jac_affine_inv_1_1__0 - jac_affine_inv_2_1__0) +
                       jac_affine_inv_2_2__0 *
                           (-1.0 * jac_affine_inv_0_2__0 -
                            jac_affine_inv_1_2__0 - jac_affine_inv_2_2__0)),
                  abs_det_jac_affine__0 *
                      (jac_affine_inv_0_0__0 * jac_affine_inv_0_0__0 +
                       jac_affine_inv_0_1__0 * jac_affine_inv_0_1__0 +
                       jac_affine_inv_0_2__0 * jac_affine_inv_0_2__0),
                  abs_det_jac_affine__0 *
                      (jac_affine_inv_0_0__0 * jac_affine_inv_1_0__0 +
                       jac_affine_inv_0_1__0 * jac_affine_inv_1_1__0 +
                       jac_affine_inv_0_2__0 * jac_affine_inv_1_2__0),
                  abs_det_jac_affine__0 *
                      (jac_affine_inv_0_0__0 * jac_affine_inv_2_0__0 +
                       jac_affine_inv_0_1__0 * jac_affine_inv_2_1__0 +
                       jac_affine_inv_0_2__0 * jac_affine_inv_2_2__0),
                  abs_det_jac_affine__0 *
                      (jac_affine_inv_1_0__0 * jac_affine_inv_1_0__0 +
                       jac_affine_inv_1_1__0 * jac_affine_inv_1_1__0 +
                       jac_affine_inv_1_2__0 * jac_affine_inv_1_2__0),
                  abs_det_jac_affine__0 *
                      (jac_affine_inv_1_0__0 * jac_affine_inv_2_0__0 +
                       jac_affine_inv_1_1__0 * jac_affine_inv_2_1__0 +
                       jac_affine_inv_1_2__0 * jac_affine_inv_2_2__0),
                  abs_det_jac_affine__0 *
                      (jac_affine_inv_2_0__0 * jac_affine_inv_2_0__0 +
                       jac_affine_inv_2_1__0 * jac_affine_inv_2_1__0 +
                       jac_affine_inv_2_2__0 * jac_affine_inv_2_2__0)};
              {
                const double p_affine_0_0__0 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_0_1__0 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_0_2__0 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_1_0__0 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_2;
                const double p_affine_1_1__0 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_2;
                const double p_affine_1_2__0 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_2;
                const double p_affine_2_0__0 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_1__0 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_2_2__0 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_0__0) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_0__0 =
                    macro_vertex_coord_id_0comp0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp0 -
                         macro_vertex_coord_id_0comp0) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_1__0 =
                    macro_vertex_coord_id_0comp1 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp1 -
                         macro_vertex_coord_id_0comp1) *
                        (double)(1LL + ctr_2);
                const double p_affine_3_2__0 =
                    macro_vertex_coord_id_0comp2 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_1comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)ctr_0__0 +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_2comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_1) +
                    1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                        (macro_vertex_coord_id_3comp2 -
                         macro_vertex_coord_id_0comp2) *
                        (double)(1LL + ctr_2);
                const double k_dof_0__0 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_1__0 =
                    _data_k[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                            (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_2__0 =
                    _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                const double k_dof_3__0 =
                    _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                            (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                6LL +
                            (1LL + ctr_1) *
                                (1LL - ctr_2 + micro_edges_per_macro_edge) +
                            ctr_0__0 +
                            (1LL + micro_edges_per_macro_edge) *
                                (2LL + micro_edges_per_macro_edge) *
                                (3LL + micro_edges_per_macro_edge) / 6LL];
                double q_acc_0_0__0 = 0.0;
                double q_acc_1_1__0 = 0.0;
                double q_acc_2_2__0 = 0.0;
                double q_acc_3_3__0 = 0.0;
                for (int64_t q__0 = 0LL; q__0 < 1LL; q__0 += 1LL) {
                  const double tmp_qloop_0__0 =
                      (k_dof_0__0 * phi_0_0__0[4LL * q__0] +
                       k_dof_1__0 * phi_0_0__0[1LL + 4LL * q__0] +
                       k_dof_2__0 * phi_0_0__0[2LL + 4LL * q__0] +
                       k_dof_3__0 * phi_0_0__0[3LL + 4LL * q__0]) *
                      q_w[q__0];
                  const double q_tmp_0_0__0 =
                      tmp_qloop_0__0 *
                      tabulated_and_untitled_0_0__0[10LL * q__0];
                  const double q_tmp_1_1__0 =
                      tmp_qloop_0__0 *
                      tabulated_and_untitled_0_0__0[4LL + 10LL * q__0];
                  const double q_tmp_2_2__0 =
                      tmp_qloop_0__0 *
                      tabulated_and_untitled_0_0__0[7LL + 10LL * q__0];
                  const double q_tmp_3_3__0 =
                      tmp_qloop_0__0 *
                      tabulated_and_untitled_0_0__0[9LL + 10LL * q__0];
                  q_acc_0_0__0 = q_acc_0_0__0 + q_tmp_0_0__0;
                  q_acc_1_1__0 = q_acc_1_1__0 + q_tmp_1_1__0;
                  q_acc_2_2__0 = q_acc_2_2__0 + q_tmp_2_2__0;
                  q_acc_3_3__0 = q_acc_3_3__0 + q_tmp_3_3__0;
                }
                const double elMatDiag_0__0 = q_acc_0_0__0;
                const double elMatDiag_1__0 = q_acc_1_1__0;
                const double elMatDiag_2__0 = q_acc_2_2__0;
                const double elMatDiag_3__0 = q_acc_3_3__0;
                _data_invDiag_[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__0 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_0__0 +
                    _data_invDiag_
                        [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__0 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__0 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_1__0 +
                    _data_invDiag_
                        [1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL -
                         (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                             (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__0 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   ctr_1 +
                               ctr_0__0 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_2__0 +
                    _data_invDiag_
                        [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                         ctr_0__0 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
                _data_invDiag_[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                               (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                   (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                   6LL +
                               (1LL + ctr_1) *
                                   (1LL - ctr_2 + micro_edges_per_macro_edge) +
                               ctr_0__0 +
                               (1LL + micro_edges_per_macro_edge) *
                                   (2LL + micro_edges_per_macro_edge) *
                                   (3LL + micro_edges_per_macro_edge) / 6LL] =
                    elMatDiag_3__0 +
                    _data_invDiag_
                        [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                         (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                             (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                         (1LL + ctr_1) *
                             (1LL - ctr_2 + micro_edges_per_macro_edge) +
                         ctr_0__0 +
                         (1LL + micro_edges_per_macro_edge) *
                             (2LL + micro_edges_per_macro_edge) *
                             (3LL + micro_edges_per_macro_edge) / 6LL];
              }
            }
          }
        }
        {
          const int64_t ctr_0 =
              -1LL - ctr_1 - ctr_2 + micro_edges_per_macro_edge;
          {
            /* CellType.WHITE_UP */
            {
              const double p_affine_0_0 =
                  macro_vertex_coord_id_0comp0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_3comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_2;
              const double p_affine_0_1 =
                  macro_vertex_coord_id_0comp1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_3comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_2;
              const double p_affine_0_2 =
                  macro_vertex_coord_id_0comp2 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp2 -
                       macro_vertex_coord_id_0comp2) *
                      (double)ctr_0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp2 -
                       macro_vertex_coord_id_0comp2) *
                      (double)ctr_1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_3comp2 -
                       macro_vertex_coord_id_0comp2) *
                      (double)ctr_2;
              const double p_affine_1_0 =
                  macro_vertex_coord_id_0comp0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)(1LL + ctr_0) +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_3comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_2;
              const double p_affine_1_1 =
                  macro_vertex_coord_id_0comp1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)(1LL + ctr_0) +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_3comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_2;
              const double p_affine_1_2 =
                  macro_vertex_coord_id_0comp2 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp2 -
                       macro_vertex_coord_id_0comp2) *
                      (double)(1LL + ctr_0) +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp2 -
                       macro_vertex_coord_id_0comp2) *
                      (double)ctr_1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_3comp2 -
                       macro_vertex_coord_id_0comp2) *
                      (double)ctr_2;
              const double p_affine_2_0 =
                  macro_vertex_coord_id_0comp0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)(1LL + ctr_1) +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_3comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_2;
              const double p_affine_2_1 =
                  macro_vertex_coord_id_0comp1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)(1LL + ctr_1) +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_3comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_2;
              const double p_affine_2_2 =
                  macro_vertex_coord_id_0comp2 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp2 -
                       macro_vertex_coord_id_0comp2) *
                      (double)ctr_0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp2 -
                       macro_vertex_coord_id_0comp2) *
                      (double)(1LL + ctr_1) +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_3comp2 -
                       macro_vertex_coord_id_0comp2) *
                      (double)ctr_2;
              const double p_affine_3_0 =
                  macro_vertex_coord_id_0comp0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_3comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)(1LL + ctr_2);
              const double p_affine_3_1 =
                  macro_vertex_coord_id_0comp1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_3comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)(1LL + ctr_2);
              const double p_affine_3_2 =
                  macro_vertex_coord_id_0comp2 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp2 -
                       macro_vertex_coord_id_0comp2) *
                      (double)ctr_0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp2 -
                       macro_vertex_coord_id_0comp2) *
                      (double)ctr_1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_3comp2 -
                       macro_vertex_coord_id_0comp2) *
                      (double)(1LL + ctr_2);
              const double k_dof_0 =
                  _data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL];
              const double k_dof_1 =
                  _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL];
              const double k_dof_2 =
                  _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                          (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) *
                              (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL + ctr_1) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) +
                          ctr_0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL];
              const double k_dof_3 =
                  _data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                          (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                              (1LL - ctr_2 + micro_edges_per_macro_edge) *
                              (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                          (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0 +
                          (1LL + micro_edges_per_macro_edge) *
                              (2LL + micro_edges_per_macro_edge) *
                              (3LL + micro_edges_per_macro_edge) / 6LL];
              double q_acc_0_0 = 0.0;
              double q_acc_1_1 = 0.0;
              double q_acc_2_2 = 0.0;
              double q_acc_3_3 = 0.0;
              for (int64_t q = 0LL; q < 1LL; q += 1LL) {
                const double tmp_qloop_0 = (k_dof_0 * phi_0_0[4LL * q] +
                                            k_dof_1 * phi_0_0[1LL + 4LL * q] +
                                            k_dof_2 * phi_0_0[2LL + 4LL * q] +
                                            k_dof_3 * phi_0_0[3LL + 4LL * q]) *
                                           q_w[q];
                const double q_tmp_0_0 =
                    tmp_qloop_0 * tabulated_and_untitled_0_0[10LL * q];
                const double q_tmp_1_1 =
                    tmp_qloop_0 * tabulated_and_untitled_0_0[4LL + 10LL * q];
                const double q_tmp_2_2 =
                    tmp_qloop_0 * tabulated_and_untitled_0_0[7LL + 10LL * q];
                const double q_tmp_3_3 =
                    tmp_qloop_0 * tabulated_and_untitled_0_0[9LL + 10LL * q];
                q_acc_0_0 = q_acc_0_0 + q_tmp_0_0;
                q_acc_1_1 = q_acc_1_1 + q_tmp_1_1;
                q_acc_2_2 = q_acc_2_2 + q_tmp_2_2;
                q_acc_3_3 = q_acc_3_3 + q_tmp_3_3;
              }
              const double elMatDiag_0 = q_acc_0_0;
              const double elMatDiag_1 = q_acc_1_1;
              const double elMatDiag_2 = q_acc_2_2;
              const double elMatDiag_3 = q_acc_3_3;
              _data_invDiag_[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL] =
                  elMatDiag_0 +
                  _data_invDiag_
                      [-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                       (1LL - ctr_2 + micro_edges_per_macro_edge) *
                           (2LL - ctr_2 + micro_edges_per_macro_edge) *
                           (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                       (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                       ctr_0 +
                       (1LL + micro_edges_per_macro_edge) *
                           (2LL + micro_edges_per_macro_edge) *
                           (3LL + micro_edges_per_macro_edge) / 6LL];
              _data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL] =
                  elMatDiag_1 +
                  _data_invDiag_
                      [1LL - (1LL + ctr_1) * ctr_1 / 2LL -
                       (1LL - ctr_2 + micro_edges_per_macro_edge) *
                           (2LL - ctr_2 + micro_edges_per_macro_edge) *
                           (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                       (2LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                       ctr_0 +
                       (1LL + micro_edges_per_macro_edge) *
                           (2LL + micro_edges_per_macro_edge) *
                           (3LL + micro_edges_per_macro_edge) / 6LL];
              _data_invDiag_[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (3LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL + ctr_1) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) +
                             ctr_0 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL] =
                  elMatDiag_2 +
                  _data_invDiag_
                      [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) -
                       (1LL - ctr_2 + micro_edges_per_macro_edge) *
                           (2LL - ctr_2 + micro_edges_per_macro_edge) *
                           (3LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                       (1LL + ctr_1) *
                           (2LL - ctr_2 + micro_edges_per_macro_edge) +
                       ctr_0 +
                       (1LL + micro_edges_per_macro_edge) *
                           (2LL + micro_edges_per_macro_edge) *
                           (3LL + micro_edges_per_macro_edge) / 6LL];
              _data_invDiag_[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                             (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                                 (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 (2LL - ctr_2 + micro_edges_per_macro_edge) /
                                 6LL +
                             (1LL - ctr_2 + micro_edges_per_macro_edge) *
                                 ctr_1 +
                             ctr_0 +
                             (1LL + micro_edges_per_macro_edge) *
                                 (2LL + micro_edges_per_macro_edge) *
                                 (3LL + micro_edges_per_macro_edge) / 6LL] =
                  elMatDiag_3 +
                  _data_invDiag_
                      [-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) -
                       (-1LL * ctr_2 + micro_edges_per_macro_edge) *
                           (1LL - ctr_2 + micro_edges_per_macro_edge) *
                           (2LL - ctr_2 + micro_edges_per_macro_edge) / 6LL +
                       (1LL - ctr_2 + micro_edges_per_macro_edge) * ctr_1 +
                       ctr_0 +
                       (1LL + micro_edges_per_macro_edge) *
                           (2LL + micro_edges_per_macro_edge) *
                           (3LL + micro_edges_per_macro_edge) / 6LL];
            }
          }
        }
      }
    }
  }
}
void P1ElementwiseDivKGrad_cubes_const_vect_fused_quadloops_tab::
    computeInverseDiagonalOperatorValues_P1ElementwiseDivKGrad_cubes_const_vect_fused_quadloops_tab_macro_2D(
        double *RESTRICT const _data_invDiag_, double *RESTRICT const _data_k,
        const double macro_vertex_coord_id_0comp0,
        const double macro_vertex_coord_id_0comp1,
        const double macro_vertex_coord_id_1comp0,
        const double macro_vertex_coord_id_1comp1,
        const double macro_vertex_coord_id_2comp0,
        const double macro_vertex_coord_id_2comp1,
        const int64_t micro_edges_per_macro_edge,
        const double micro_edges_per_macro_edge_float) const {
  {
    double q_w[1] = {0.5};
    const double tmp_coords_jac_0__1 =
        macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_1__1 =
        1.0 * (1.0 / micro_edges_per_macro_edge_float);
    const double tmp_coords_jac_2__1 = tmp_coords_jac_1__1 * 0.0;
    const double tmp_coords_jac_3__1 =
        tmp_coords_jac_0__1 * tmp_coords_jac_2__1;
    const double tmp_coords_jac_4__1 =
        macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_5__1 =
        macro_vertex_coord_id_0comp0 +
        tmp_coords_jac_2__1 * tmp_coords_jac_4__1;
    const double tmp_coords_jac_6__1 =
        macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_7__1 =
        tmp_coords_jac_2__1 * tmp_coords_jac_6__1;
    const double tmp_coords_jac_8__1 =
        macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_9__1 =
        macro_vertex_coord_id_0comp1 +
        tmp_coords_jac_2__1 * tmp_coords_jac_8__1;
    const double tmp_coords_jac_10__1 = tmp_coords_jac_1__1 * 1.0;
    const double p_affine_const_0_0__1 =
        tmp_coords_jac_3__1 + tmp_coords_jac_5__1;
    const double p_affine_const_0_1__1 =
        tmp_coords_jac_7__1 + tmp_coords_jac_9__1;
    const double p_affine_const_1_0__1 =
        tmp_coords_jac_5__1 + tmp_coords_jac_0__1 * tmp_coords_jac_10__1;
    const double p_affine_const_1_1__1 =
        tmp_coords_jac_9__1 + tmp_coords_jac_10__1 * tmp_coords_jac_6__1;
    const double p_affine_const_2_0__1 =
        macro_vertex_coord_id_0comp0 + tmp_coords_jac_3__1 +
        tmp_coords_jac_10__1 * tmp_coords_jac_4__1;
    const double p_affine_const_2_1__1 =
        macro_vertex_coord_id_0comp1 + tmp_coords_jac_7__1 +
        tmp_coords_jac_10__1 * tmp_coords_jac_8__1;
    const double jac_affine_0_0__1 =
        p_affine_const_1_0__1 - p_affine_const_0_0__1;
    const double jac_affine_0_1__1 =
        p_affine_const_2_0__1 - p_affine_const_0_0__1;
    const double jac_affine_1_0__1 =
        p_affine_const_1_1__1 - p_affine_const_0_1__1;
    const double jac_affine_1_1__1 =
        p_affine_const_2_1__1 - p_affine_const_0_1__1;
    const double tmp_coords_jac_11__1 = jac_affine_0_0__1 * jac_affine_1_1__1 -
                                        jac_affine_0_1__1 * jac_affine_1_0__1;
    const double tmp_coords_jac_12__1 = 1.0 / tmp_coords_jac_11__1;
    const double jac_affine_inv_0_0__1 =
        jac_affine_1_1__1 * tmp_coords_jac_12__1;
    const double jac_affine_inv_0_1__1 =
        -1.0 * jac_affine_0_1__1 * tmp_coords_jac_12__1;
    const double jac_affine_inv_1_0__1 =
        -1.0 * jac_affine_1_0__1 * tmp_coords_jac_12__1;
    const double jac_affine_inv_1_1__1 =
        jac_affine_0_0__1 * tmp_coords_jac_12__1;
    const double abs_det_jac_affine__1 = abs(tmp_coords_jac_11__1);
    double phi_0_0__1[3] = {0.3333333333333334, 0.3333333333333333,
                            0.3333333333333333};
    double tabulated_and_untitled_0_0__1[6] = {
        abs_det_jac_affine__1 *
            ((-1.0 * jac_affine_inv_0_0__1 - jac_affine_inv_1_0__1) *
                 (-1.0 * jac_affine_inv_0_0__1 - jac_affine_inv_1_0__1) +
             (-1.0 * jac_affine_inv_0_1__1 - jac_affine_inv_1_1__1) *
                 (-1.0 * jac_affine_inv_0_1__1 - jac_affine_inv_1_1__1)),
        abs_det_jac_affine__1 *
            (jac_affine_inv_0_0__1 *
                 (-1.0 * jac_affine_inv_0_0__1 - jac_affine_inv_1_0__1) +
             jac_affine_inv_0_1__1 *
                 (-1.0 * jac_affine_inv_0_1__1 - jac_affine_inv_1_1__1)),
        abs_det_jac_affine__1 *
            (jac_affine_inv_1_0__1 *
                 (-1.0 * jac_affine_inv_0_0__1 - jac_affine_inv_1_0__1) +
             jac_affine_inv_1_1__1 *
                 (-1.0 * jac_affine_inv_0_1__1 - jac_affine_inv_1_1__1)),
        abs_det_jac_affine__1 * (jac_affine_inv_0_0__1 * jac_affine_inv_0_0__1 +
                                 jac_affine_inv_0_1__1 * jac_affine_inv_0_1__1),
        abs_det_jac_affine__1 * (jac_affine_inv_0_0__1 * jac_affine_inv_1_0__1 +
                                 jac_affine_inv_0_1__1 * jac_affine_inv_1_1__1),
        abs_det_jac_affine__1 *
            (jac_affine_inv_1_0__1 * jac_affine_inv_1_0__1 +
             jac_affine_inv_1_1__1 * jac_affine_inv_1_1__1)};
    const double tmp_coords_jac_0__0 =
        macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_1__0 =
        1.0 * (1.0 / micro_edges_per_macro_edge_float);
    const double tmp_coords_jac_2__0 = tmp_coords_jac_1__0 * 0.0;
    const double tmp_coords_jac_3__0 =
        macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_4__0 = tmp_coords_jac_1__0 * 1.0;
    const double tmp_coords_jac_5__0 =
        macro_vertex_coord_id_0comp0 +
        tmp_coords_jac_3__0 * tmp_coords_jac_4__0;
    const double tmp_coords_jac_6__0 =
        macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_7__0 =
        macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_8__0 =
        macro_vertex_coord_id_0comp1 +
        tmp_coords_jac_4__0 * tmp_coords_jac_7__0;
    const double tmp_coords_jac_9__0 =
        tmp_coords_jac_0__0 * tmp_coords_jac_4__0;
    const double tmp_coords_jac_10__0 =
        tmp_coords_jac_4__0 * tmp_coords_jac_6__0;
    const double p_affine_const_0_0__0 =
        tmp_coords_jac_5__0 + tmp_coords_jac_0__0 * tmp_coords_jac_2__0;
    const double p_affine_const_0_1__0 =
        tmp_coords_jac_8__0 + tmp_coords_jac_2__0 * tmp_coords_jac_6__0;
    const double p_affine_const_1_0__0 =
        macro_vertex_coord_id_0comp0 + tmp_coords_jac_9__0 +
        tmp_coords_jac_2__0 * tmp_coords_jac_3__0;
    const double p_affine_const_1_1__0 =
        macro_vertex_coord_id_0comp1 + tmp_coords_jac_10__0 +
        tmp_coords_jac_2__0 * tmp_coords_jac_7__0;
    const double p_affine_const_2_0__0 =
        tmp_coords_jac_5__0 + tmp_coords_jac_9__0;
    const double p_affine_const_2_1__0 =
        tmp_coords_jac_10__0 + tmp_coords_jac_8__0;
    const double jac_affine_0_0__0 =
        p_affine_const_1_0__0 - p_affine_const_0_0__0;
    const double jac_affine_0_1__0 =
        p_affine_const_2_0__0 - p_affine_const_0_0__0;
    const double jac_affine_1_0__0 =
        p_affine_const_1_1__0 - p_affine_const_0_1__0;
    const double jac_affine_1_1__0 =
        p_affine_const_2_1__0 - p_affine_const_0_1__0;
    const double tmp_coords_jac_11__0 = jac_affine_0_0__0 * jac_affine_1_1__0 -
                                        jac_affine_0_1__0 * jac_affine_1_0__0;
    const double tmp_coords_jac_12__0 = 1.0 / tmp_coords_jac_11__0;
    const double jac_affine_inv_0_0__0 =
        jac_affine_1_1__0 * tmp_coords_jac_12__0;
    const double jac_affine_inv_0_1__0 =
        -1.0 * jac_affine_0_1__0 * tmp_coords_jac_12__0;
    const double jac_affine_inv_1_0__0 =
        -1.0 * jac_affine_1_0__0 * tmp_coords_jac_12__0;
    const double jac_affine_inv_1_1__0 =
        jac_affine_0_0__0 * tmp_coords_jac_12__0;
    const double abs_det_jac_affine__0 = abs(tmp_coords_jac_11__0);
    double phi_0_0__0[3] = {0.3333333333333334, 0.3333333333333333,
                            0.3333333333333333};
    double tabulated_and_untitled_0_0__0[6] = {
        abs_det_jac_affine__0 *
            ((-1.0 * jac_affine_inv_0_0__0 - jac_affine_inv_1_0__0) *
                 (-1.0 * jac_affine_inv_0_0__0 - jac_affine_inv_1_0__0) +
             (-1.0 * jac_affine_inv_0_1__0 - jac_affine_inv_1_1__0) *
                 (-1.0 * jac_affine_inv_0_1__0 - jac_affine_inv_1_1__0)),
        abs_det_jac_affine__0 *
            (jac_affine_inv_0_0__0 *
                 (-1.0 * jac_affine_inv_0_0__0 - jac_affine_inv_1_0__0) +
             jac_affine_inv_0_1__0 *
                 (-1.0 * jac_affine_inv_0_1__0 - jac_affine_inv_1_1__0)),
        abs_det_jac_affine__0 *
            (jac_affine_inv_1_0__0 *
                 (-1.0 * jac_affine_inv_0_0__0 - jac_affine_inv_1_0__0) +
             jac_affine_inv_1_1__0 *
                 (-1.0 * jac_affine_inv_0_1__0 - jac_affine_inv_1_1__0)),
        abs_det_jac_affine__0 * (jac_affine_inv_0_0__0 * jac_affine_inv_0_0__0 +
                                 jac_affine_inv_0_1__0 * jac_affine_inv_0_1__0),
        abs_det_jac_affine__0 * (jac_affine_inv_0_0__0 * jac_affine_inv_1_0__0 +
                                 jac_affine_inv_0_1__0 * jac_affine_inv_1_1__0),
        abs_det_jac_affine__0 *
            (jac_affine_inv_1_0__0 * jac_affine_inv_1_0__0 +
             jac_affine_inv_1_1__0 * jac_affine_inv_1_1__0)};
    const double tmp_coords_jac_0 =
        macro_vertex_coord_id_1comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_1 =
        1.0 * (1.0 / micro_edges_per_macro_edge_float);
    const double tmp_coords_jac_2 = tmp_coords_jac_1 * 0.0;
    const double tmp_coords_jac_3 = tmp_coords_jac_0 * tmp_coords_jac_2;
    const double tmp_coords_jac_4 =
        macro_vertex_coord_id_2comp0 - macro_vertex_coord_id_0comp0;
    const double tmp_coords_jac_5 =
        macro_vertex_coord_id_0comp0 + tmp_coords_jac_2 * tmp_coords_jac_4;
    const double tmp_coords_jac_6 =
        macro_vertex_coord_id_1comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_7 = tmp_coords_jac_2 * tmp_coords_jac_6;
    const double tmp_coords_jac_8 =
        macro_vertex_coord_id_2comp1 - macro_vertex_coord_id_0comp1;
    const double tmp_coords_jac_9 =
        macro_vertex_coord_id_0comp1 + tmp_coords_jac_2 * tmp_coords_jac_8;
    const double tmp_coords_jac_10 = tmp_coords_jac_1 * 1.0;
    const double p_affine_const_0_0 = tmp_coords_jac_3 + tmp_coords_jac_5;
    const double p_affine_const_0_1 = tmp_coords_jac_7 + tmp_coords_jac_9;
    const double p_affine_const_1_0 =
        tmp_coords_jac_5 + tmp_coords_jac_0 * tmp_coords_jac_10;
    const double p_affine_const_1_1 =
        tmp_coords_jac_9 + tmp_coords_jac_10 * tmp_coords_jac_6;
    const double p_affine_const_2_0 = macro_vertex_coord_id_0comp0 +
                                      tmp_coords_jac_3 +
                                      tmp_coords_jac_10 * tmp_coords_jac_4;
    const double p_affine_const_2_1 = macro_vertex_coord_id_0comp1 +
                                      tmp_coords_jac_7 +
                                      tmp_coords_jac_10 * tmp_coords_jac_8;
    const double jac_affine_0_0 = p_affine_const_1_0 - p_affine_const_0_0;
    const double jac_affine_0_1 = p_affine_const_2_0 - p_affine_const_0_0;
    const double jac_affine_1_0 = p_affine_const_1_1 - p_affine_const_0_1;
    const double jac_affine_1_1 = p_affine_const_2_1 - p_affine_const_0_1;
    const double tmp_coords_jac_11 =
        jac_affine_0_0 * jac_affine_1_1 - jac_affine_0_1 * jac_affine_1_0;
    const double tmp_coords_jac_12 = 1.0 / tmp_coords_jac_11;
    const double jac_affine_inv_0_0 = jac_affine_1_1 * tmp_coords_jac_12;
    const double jac_affine_inv_0_1 = -1.0 * jac_affine_0_1 * tmp_coords_jac_12;
    const double jac_affine_inv_1_0 = -1.0 * jac_affine_1_0 * tmp_coords_jac_12;
    const double jac_affine_inv_1_1 = jac_affine_0_0 * tmp_coords_jac_12;
    const double abs_det_jac_affine = abs(tmp_coords_jac_11);
    double phi_0_0[3] = {0.3333333333333334, 0.3333333333333333,
                         0.3333333333333333};
    double tabulated_and_untitled_0_0[6] = {
        abs_det_jac_affine *
            ((-1.0 * jac_affine_inv_0_0 - jac_affine_inv_1_0) *
                 (-1.0 * jac_affine_inv_0_0 - jac_affine_inv_1_0) +
             (-1.0 * jac_affine_inv_0_1 - jac_affine_inv_1_1) *
                 (-1.0 * jac_affine_inv_0_1 - jac_affine_inv_1_1)),
        abs_det_jac_affine * (jac_affine_inv_0_0 * (-1.0 * jac_affine_inv_0_0 -
                                                    jac_affine_inv_1_0) +
                              jac_affine_inv_0_1 * (-1.0 * jac_affine_inv_0_1 -
                                                    jac_affine_inv_1_1)),
        abs_det_jac_affine * (jac_affine_inv_1_0 * (-1.0 * jac_affine_inv_0_0 -
                                                    jac_affine_inv_1_0) +
                              jac_affine_inv_1_1 * (-1.0 * jac_affine_inv_0_1 -
                                                    jac_affine_inv_1_1)),
        abs_det_jac_affine * (jac_affine_inv_0_0 * jac_affine_inv_0_0 +
                              jac_affine_inv_0_1 * jac_affine_inv_0_1),
        abs_det_jac_affine * (jac_affine_inv_0_0 * jac_affine_inv_1_0 +
                              jac_affine_inv_0_1 * jac_affine_inv_1_1),
        abs_det_jac_affine * (jac_affine_inv_1_0 * jac_affine_inv_1_0 +
                              jac_affine_inv_1_1 * jac_affine_inv_1_1)};
    for (int64_t ctr_1 = 0LL; ctr_1 < micro_edges_per_macro_edge;
         ctr_1 += 1LL) {
      {
        const int64_t __ctr_0__0_simd_stop =
            -1LL - ctr_1 + micro_edges_per_macro_edge - 3LL;
        const int64_t __ctr_0__0_simd_step = 4LL;
        for (int64_t ctr_0__0 = 0LL; ctr_0__0 < __ctr_0__0_simd_stop;
             ctr_0__0 += __ctr_0__0_simd_step) {
          const __m256i ctr_0__3 =
              _mm256_add_epi64(_mm256_set1_epi64x(ctr_0__0),
                               _mm256_set_epi64x(3LL, 2LL, 1LL, 0LL));
          {
            /* FaceType.GRAY */
            {
              const __m256d p_affine_0_0__4 = _mm256_add_pd(
                  _mm256_add_pd(
                      _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_mul_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_div_pd(
                                      _mm256_set1_pd(1.0),
                                      _mm256_set1_pd(
                                          micro_edges_per_macro_edge_float))),
                              _mm256_sub_pd(
                                  _mm256_set1_pd(macro_vertex_coord_id_1comp0),
                                  _mm256_set1_pd(
                                      macro_vertex_coord_id_0comp0))),
                          __builtin_convertvector(
                              ctr_0__3,
                              double __attribute__((__vector_size__(32)))))),
                  _mm256_mul_pd(
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_set1_pd(1.0),
                              _mm256_div_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_set1_pd(
                                      micro_edges_per_macro_edge_float))),
                          _mm256_sub_pd(
                              _mm256_set1_pd(macro_vertex_coord_id_2comp0),
                              _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                      __builtin_convertvector(
                          _mm256_set1_epi64x(ctr_1),
                          double __attribute__((__vector_size__(32))))));
              const __m256d p_affine_0_1__4 = _mm256_add_pd(
                  _mm256_add_pd(
                      _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_mul_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_div_pd(
                                      _mm256_set1_pd(1.0),
                                      _mm256_set1_pd(
                                          micro_edges_per_macro_edge_float))),
                              _mm256_sub_pd(
                                  _mm256_set1_pd(macro_vertex_coord_id_1comp1),
                                  _mm256_set1_pd(
                                      macro_vertex_coord_id_0comp1))),
                          __builtin_convertvector(
                              ctr_0__3,
                              double __attribute__((__vector_size__(32)))))),
                  _mm256_mul_pd(
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_set1_pd(1.0),
                              _mm256_div_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_set1_pd(
                                      micro_edges_per_macro_edge_float))),
                          _mm256_sub_pd(
                              _mm256_set1_pd(macro_vertex_coord_id_2comp1),
                              _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                      __builtin_convertvector(
                          _mm256_set1_epi64x(ctr_1),
                          double __attribute__((__vector_size__(32))))));
              const __m256d p_affine_1_0__4 = _mm256_add_pd(
                  _mm256_add_pd(
                      _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_mul_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_div_pd(
                                      _mm256_set1_pd(1.0),
                                      _mm256_set1_pd(
                                          micro_edges_per_macro_edge_float))),
                              _mm256_sub_pd(
                                  _mm256_set1_pd(macro_vertex_coord_id_1comp0),
                                  _mm256_set1_pd(
                                      macro_vertex_coord_id_0comp0))),
                          __builtin_convertvector(
                              _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                               ctr_0__3),
                              double __attribute__((__vector_size__(32)))))),
                  _mm256_mul_pd(
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_set1_pd(1.0),
                              _mm256_div_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_set1_pd(
                                      micro_edges_per_macro_edge_float))),
                          _mm256_sub_pd(
                              _mm256_set1_pd(macro_vertex_coord_id_2comp0),
                              _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                      __builtin_convertvector(
                          _mm256_set1_epi64x(ctr_1),
                          double __attribute__((__vector_size__(32))))));
              const __m256d p_affine_1_1__4 = _mm256_add_pd(
                  _mm256_add_pd(
                      _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_mul_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_div_pd(
                                      _mm256_set1_pd(1.0),
                                      _mm256_set1_pd(
                                          micro_edges_per_macro_edge_float))),
                              _mm256_sub_pd(
                                  _mm256_set1_pd(macro_vertex_coord_id_1comp1),
                                  _mm256_set1_pd(
                                      macro_vertex_coord_id_0comp1))),
                          __builtin_convertvector(
                              _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                               ctr_0__3),
                              double __attribute__((__vector_size__(32)))))),
                  _mm256_mul_pd(
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_set1_pd(1.0),
                              _mm256_div_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_set1_pd(
                                      micro_edges_per_macro_edge_float))),
                          _mm256_sub_pd(
                              _mm256_set1_pd(macro_vertex_coord_id_2comp1),
                              _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                      __builtin_convertvector(
                          _mm256_set1_epi64x(ctr_1),
                          double __attribute__((__vector_size__(32))))));
              const __m256d p_affine_2_0__4 = _mm256_add_pd(
                  _mm256_add_pd(
                      _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_mul_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_div_pd(
                                      _mm256_set1_pd(1.0),
                                      _mm256_set1_pd(
                                          micro_edges_per_macro_edge_float))),
                              _mm256_sub_pd(
                                  _mm256_set1_pd(macro_vertex_coord_id_1comp0),
                                  _mm256_set1_pd(
                                      macro_vertex_coord_id_0comp0))),
                          __builtin_convertvector(
                              ctr_0__3,
                              double __attribute__((__vector_size__(32)))))),
                  _mm256_mul_pd(
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_set1_pd(1.0),
                              _mm256_div_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_set1_pd(
                                      micro_edges_per_macro_edge_float))),
                          _mm256_sub_pd(
                              _mm256_set1_pd(macro_vertex_coord_id_2comp0),
                              _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                      __builtin_convertvector(
                          _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                           _mm256_set1_epi64x(ctr_1)),
                          double __attribute__((__vector_size__(32))))));
              const __m256d p_affine_2_1__4 = _mm256_add_pd(
                  _mm256_add_pd(
                      _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_mul_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_div_pd(
                                      _mm256_set1_pd(1.0),
                                      _mm256_set1_pd(
                                          micro_edges_per_macro_edge_float))),
                              _mm256_sub_pd(
                                  _mm256_set1_pd(macro_vertex_coord_id_1comp1),
                                  _mm256_set1_pd(
                                      macro_vertex_coord_id_0comp1))),
                          __builtin_convertvector(
                              ctr_0__3,
                              double __attribute__((__vector_size__(32)))))),
                  _mm256_mul_pd(
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_set1_pd(1.0),
                              _mm256_div_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_set1_pd(
                                      micro_edges_per_macro_edge_float))),
                          _mm256_sub_pd(
                              _mm256_set1_pd(macro_vertex_coord_id_2comp1),
                              _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                      __builtin_convertvector(
                          _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                           _mm256_set1_epi64x(ctr_1)),
                          double __attribute__((__vector_size__(32))))));
              const __m256d k_dof_0__4 = _mm256_loadu_pd(
                  &_data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) +
                           (2LL + micro_edges_per_macro_edge) * ctr_1 +
                           ctr_0__0]);
              const __m256d k_dof_1__4 = _mm256_loadu_pd(
                  &_data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                           (2LL + micro_edges_per_macro_edge) * ctr_1 +
                           ctr_0__0]);
              const __m256d k_dof_2__4 = _mm256_loadu_pd(
                  &_data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                           (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                           ctr_0__0]);
              __m256d q_acc_0_0__4 = _mm256_set1_pd(0.0);
              __m256d q_acc_1_1__4 = _mm256_set1_pd(0.0);
              __m256d q_acc_2_2__4 = _mm256_set1_pd(0.0);
              for (int64_t q__3 = 0LL; q__3 < 1LL; q__3 += 1LL) {
                const __m256d tmp_qloop_0__4 = _mm256_mul_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(
                                k_dof_0__4,
                                _mm256_set1_pd(phi_0_0__1[3LL * q__3])),
                            _mm256_mul_pd(
                                k_dof_1__4,
                                _mm256_set1_pd(phi_0_0__1[1LL + 3LL * q__3]))),
                        _mm256_mul_pd(
                            k_dof_2__4,
                            _mm256_set1_pd(phi_0_0__1[2LL + 3LL * q__3]))),
                    _mm256_set1_pd(q_w[q__3]));
                const __m256d q_tmp_0_0__4 = _mm256_mul_pd(
                    tmp_qloop_0__4,
                    _mm256_set1_pd(tabulated_and_untitled_0_0__1[6LL * q__3]));
                const __m256d q_tmp_1_1__4 = _mm256_mul_pd(
                    tmp_qloop_0__4,
                    _mm256_set1_pd(
                        tabulated_and_untitled_0_0__1[3LL + 6LL * q__3]));
                const __m256d q_tmp_2_2__4 = _mm256_mul_pd(
                    tmp_qloop_0__4,
                    _mm256_set1_pd(
                        tabulated_and_untitled_0_0__1[5LL + 6LL * q__3]));
                q_acc_0_0__4 = _mm256_add_pd(q_acc_0_0__4, q_tmp_0_0__4);
                q_acc_1_1__4 = _mm256_add_pd(q_acc_1_1__4, q_tmp_1_1__4);
                q_acc_2_2__4 = _mm256_add_pd(q_acc_2_2__4, q_tmp_2_2__4);
              }
              const __m256d elMatDiag_0__4 = q_acc_0_0__4;
              const __m256d elMatDiag_1__4 = q_acc_1_1__4;
              const __m256d elMatDiag_2__4 = q_acc_2_2__4;
              _mm256_storeu_pd(
                  &_data_invDiag_[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) +
                                  (2LL + micro_edges_per_macro_edge) * ctr_1 +
                                  ctr_0__0],
                  _mm256_add_pd(
                      elMatDiag_0__4,
                      _mm256_loadu_pd(
                          &_data_invDiag_[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) +
                                          (2LL + micro_edges_per_macro_edge) *
                                              ctr_1 +
                                          ctr_0__0])));
              _mm256_storeu_pd(
                  &_data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                                  (2LL + micro_edges_per_macro_edge) * ctr_1 +
                                  ctr_0__0],
                  _mm256_add_pd(
                      elMatDiag_1__4,
                      _mm256_loadu_pd(
                          &_data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                                          (2LL + micro_edges_per_macro_edge) *
                                              ctr_1 +
                                          ctr_0__0])));
              _mm256_storeu_pd(
                  &_data_invDiag_[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                                  (1LL + ctr_1) *
                                      (2LL + micro_edges_per_macro_edge) +
                                  ctr_0__0],
                  _mm256_add_pd(
                      elMatDiag_2__4,
                      _mm256_loadu_pd(
                          &_data_invDiag_
                              [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                               (1LL + ctr_1) *
                                   (2LL + micro_edges_per_macro_edge) +
                               ctr_0__0])));
            }
          }
          {
            /* FaceType.BLUE */
            {
              const __m256d p_affine_0_0__5 = _mm256_add_pd(
                  _mm256_add_pd(
                      _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_mul_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_div_pd(
                                      _mm256_set1_pd(1.0),
                                      _mm256_set1_pd(
                                          micro_edges_per_macro_edge_float))),
                              _mm256_sub_pd(
                                  _mm256_set1_pd(macro_vertex_coord_id_1comp0),
                                  _mm256_set1_pd(
                                      macro_vertex_coord_id_0comp0))),
                          __builtin_convertvector(
                              _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                               ctr_0__3),
                              double __attribute__((__vector_size__(32)))))),
                  _mm256_mul_pd(
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_set1_pd(1.0),
                              _mm256_div_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_set1_pd(
                                      micro_edges_per_macro_edge_float))),
                          _mm256_sub_pd(
                              _mm256_set1_pd(macro_vertex_coord_id_2comp0),
                              _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                      __builtin_convertvector(
                          _mm256_set1_epi64x(ctr_1),
                          double __attribute__((__vector_size__(32))))));
              const __m256d p_affine_0_1__5 = _mm256_add_pd(
                  _mm256_add_pd(
                      _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_mul_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_div_pd(
                                      _mm256_set1_pd(1.0),
                                      _mm256_set1_pd(
                                          micro_edges_per_macro_edge_float))),
                              _mm256_sub_pd(
                                  _mm256_set1_pd(macro_vertex_coord_id_1comp1),
                                  _mm256_set1_pd(
                                      macro_vertex_coord_id_0comp1))),
                          __builtin_convertvector(
                              _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                               ctr_0__3),
                              double __attribute__((__vector_size__(32)))))),
                  _mm256_mul_pd(
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_set1_pd(1.0),
                              _mm256_div_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_set1_pd(
                                      micro_edges_per_macro_edge_float))),
                          _mm256_sub_pd(
                              _mm256_set1_pd(macro_vertex_coord_id_2comp1),
                              _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                      __builtin_convertvector(
                          _mm256_set1_epi64x(ctr_1),
                          double __attribute__((__vector_size__(32))))));
              const __m256d p_affine_1_0__5 = _mm256_add_pd(
                  _mm256_add_pd(
                      _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_mul_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_div_pd(
                                      _mm256_set1_pd(1.0),
                                      _mm256_set1_pd(
                                          micro_edges_per_macro_edge_float))),
                              _mm256_sub_pd(
                                  _mm256_set1_pd(macro_vertex_coord_id_1comp0),
                                  _mm256_set1_pd(
                                      macro_vertex_coord_id_0comp0))),
                          __builtin_convertvector(
                              ctr_0__3,
                              double __attribute__((__vector_size__(32)))))),
                  _mm256_mul_pd(
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_set1_pd(1.0),
                              _mm256_div_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_set1_pd(
                                      micro_edges_per_macro_edge_float))),
                          _mm256_sub_pd(
                              _mm256_set1_pd(macro_vertex_coord_id_2comp0),
                              _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                      __builtin_convertvector(
                          _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                           _mm256_set1_epi64x(ctr_1)),
                          double __attribute__((__vector_size__(32))))));
              const __m256d p_affine_1_1__5 = _mm256_add_pd(
                  _mm256_add_pd(
                      _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_mul_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_div_pd(
                                      _mm256_set1_pd(1.0),
                                      _mm256_set1_pd(
                                          micro_edges_per_macro_edge_float))),
                              _mm256_sub_pd(
                                  _mm256_set1_pd(macro_vertex_coord_id_1comp1),
                                  _mm256_set1_pd(
                                      macro_vertex_coord_id_0comp1))),
                          __builtin_convertvector(
                              ctr_0__3,
                              double __attribute__((__vector_size__(32)))))),
                  _mm256_mul_pd(
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_set1_pd(1.0),
                              _mm256_div_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_set1_pd(
                                      micro_edges_per_macro_edge_float))),
                          _mm256_sub_pd(
                              _mm256_set1_pd(macro_vertex_coord_id_2comp1),
                              _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                      __builtin_convertvector(
                          _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                           _mm256_set1_epi64x(ctr_1)),
                          double __attribute__((__vector_size__(32))))));
              const __m256d p_affine_2_0__5 = _mm256_add_pd(
                  _mm256_add_pd(
                      _mm256_set1_pd(macro_vertex_coord_id_0comp0),
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_mul_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_div_pd(
                                      _mm256_set1_pd(1.0),
                                      _mm256_set1_pd(
                                          micro_edges_per_macro_edge_float))),
                              _mm256_sub_pd(
                                  _mm256_set1_pd(macro_vertex_coord_id_1comp0),
                                  _mm256_set1_pd(
                                      macro_vertex_coord_id_0comp0))),
                          __builtin_convertvector(
                              _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                               ctr_0__3),
                              double __attribute__((__vector_size__(32)))))),
                  _mm256_mul_pd(
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_set1_pd(1.0),
                              _mm256_div_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_set1_pd(
                                      micro_edges_per_macro_edge_float))),
                          _mm256_sub_pd(
                              _mm256_set1_pd(macro_vertex_coord_id_2comp0),
                              _mm256_set1_pd(macro_vertex_coord_id_0comp0))),
                      __builtin_convertvector(
                          _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                           _mm256_set1_epi64x(ctr_1)),
                          double __attribute__((__vector_size__(32))))));
              const __m256d p_affine_2_1__5 = _mm256_add_pd(
                  _mm256_add_pd(
                      _mm256_set1_pd(macro_vertex_coord_id_0comp1),
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_mul_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_div_pd(
                                      _mm256_set1_pd(1.0),
                                      _mm256_set1_pd(
                                          micro_edges_per_macro_edge_float))),
                              _mm256_sub_pd(
                                  _mm256_set1_pd(macro_vertex_coord_id_1comp1),
                                  _mm256_set1_pd(
                                      macro_vertex_coord_id_0comp1))),
                          __builtin_convertvector(
                              _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                               ctr_0__3),
                              double __attribute__((__vector_size__(32)))))),
                  _mm256_mul_pd(
                      _mm256_mul_pd(
                          _mm256_mul_pd(
                              _mm256_set1_pd(1.0),
                              _mm256_div_pd(
                                  _mm256_set1_pd(1.0),
                                  _mm256_set1_pd(
                                      micro_edges_per_macro_edge_float))),
                          _mm256_sub_pd(
                              _mm256_set1_pd(macro_vertex_coord_id_2comp1),
                              _mm256_set1_pd(macro_vertex_coord_id_0comp1))),
                      __builtin_convertvector(
                          _mm256_add_epi64(_mm256_set1_epi64x(1LL),
                                           _mm256_set1_epi64x(ctr_1)),
                          double __attribute__((__vector_size__(32))))));
              const __m256d k_dof_0__5 = _mm256_loadu_pd(
                  &_data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                           (2LL + micro_edges_per_macro_edge) * ctr_1 +
                           ctr_0__0]);
              const __m256d k_dof_1__5 = _mm256_loadu_pd(
                  &_data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                           (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                           ctr_0__0]);
              const __m256d k_dof_2__5 = _mm256_loadu_pd(
                  &_data_k[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL +
                           (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                           ctr_0__0]);
              __m256d q_acc_0_0__5 = _mm256_set1_pd(0.0);
              __m256d q_acc_1_1__5 = _mm256_set1_pd(0.0);
              __m256d q_acc_2_2__5 = _mm256_set1_pd(0.0);
              for (int64_t q__2 = 0LL; q__2 < 1LL; q__2 += 1LL) {
                const __m256d tmp_qloop_0__5 = _mm256_mul_pd(
                    _mm256_add_pd(
                        _mm256_add_pd(
                            _mm256_mul_pd(
                                k_dof_0__5,
                                _mm256_set1_pd(phi_0_0__0[3LL * q__2])),
                            _mm256_mul_pd(
                                k_dof_1__5,
                                _mm256_set1_pd(phi_0_0__0[1LL + 3LL * q__2]))),
                        _mm256_mul_pd(
                            k_dof_2__5,
                            _mm256_set1_pd(phi_0_0__0[2LL + 3LL * q__2]))),
                    _mm256_set1_pd(q_w[q__2]));
                const __m256d q_tmp_0_0__5 = _mm256_mul_pd(
                    tmp_qloop_0__5,
                    _mm256_set1_pd(tabulated_and_untitled_0_0__0[6LL * q__2]));
                const __m256d q_tmp_1_1__5 = _mm256_mul_pd(
                    tmp_qloop_0__5,
                    _mm256_set1_pd(
                        tabulated_and_untitled_0_0__0[3LL + 6LL * q__2]));
                const __m256d q_tmp_2_2__5 = _mm256_mul_pd(
                    tmp_qloop_0__5,
                    _mm256_set1_pd(
                        tabulated_and_untitled_0_0__0[5LL + 6LL * q__2]));
                q_acc_0_0__5 = _mm256_add_pd(q_acc_0_0__5, q_tmp_0_0__5);
                q_acc_1_1__5 = _mm256_add_pd(q_acc_1_1__5, q_tmp_1_1__5);
                q_acc_2_2__5 = _mm256_add_pd(q_acc_2_2__5, q_tmp_2_2__5);
              }
              const __m256d elMatDiag_0__5 = q_acc_0_0__5;
              const __m256d elMatDiag_1__5 = q_acc_1_1__5;
              const __m256d elMatDiag_2__5 = q_acc_2_2__5;
              _mm256_storeu_pd(
                  &_data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                                  (2LL + micro_edges_per_macro_edge) * ctr_1 +
                                  ctr_0__0],
                  _mm256_add_pd(
                      elMatDiag_0__5,
                      _mm256_loadu_pd(
                          &_data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                                          (2LL + micro_edges_per_macro_edge) *
                                              ctr_1 +
                                          ctr_0__0])));
              _mm256_storeu_pd(
                  &_data_invDiag_[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                                  (1LL + ctr_1) *
                                      (2LL + micro_edges_per_macro_edge) +
                                  ctr_0__0],
                  _mm256_add_pd(
                      elMatDiag_1__5,
                      _mm256_loadu_pd(
                          &_data_invDiag_
                              [-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                               (1LL + ctr_1) *
                                   (2LL + micro_edges_per_macro_edge) +
                               ctr_0__0])));
              _mm256_storeu_pd(
                  &_data_invDiag_[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL +
                                  (1LL + ctr_1) *
                                      (2LL + micro_edges_per_macro_edge) +
                                  ctr_0__0],
                  _mm256_add_pd(
                      elMatDiag_2__5,
                      _mm256_loadu_pd(
                          &_data_invDiag_
                              [1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL +
                               (1LL + ctr_1) *
                                   (2LL + micro_edges_per_macro_edge) +
                               ctr_0__0])));
            }
          }
        }
        const int64_t __ctr_0__0_trailing_start =
            __ctr_0__0_simd_stop > 0LL
                ? ((__ctr_0__0_simd_stop - 1LL) / __ctr_0__0_simd_step + 1LL) *
                      __ctr_0__0_simd_step
                : 0LL;
        for (int64_t ctr_0__2 = __ctr_0__0_trailing_start;
             ctr_0__2 < -1LL - ctr_1 + micro_edges_per_macro_edge;
             ctr_0__2 += 1LL) {
          {
            /* FaceType.GRAY */
            {
              const double p_affine_0_0__1 =
                  macro_vertex_coord_id_0comp0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_0__2 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_1;
              const double p_affine_0_1__1 =
                  macro_vertex_coord_id_0comp1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_0__2 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_1;
              const double p_affine_1_0__1 =
                  macro_vertex_coord_id_0comp0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)(1LL + ctr_0__2) +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_1;
              const double p_affine_1_1__1 =
                  macro_vertex_coord_id_0comp1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)(1LL + ctr_0__2) +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_1;
              const double p_affine_2_0__1 =
                  macro_vertex_coord_id_0comp0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_0__2 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)(1LL + ctr_1);
              const double p_affine_2_1__1 =
                  macro_vertex_coord_id_0comp1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_0__2 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)(1LL + ctr_1);
              const double k_dof_0__1 =
                  _data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) +
                          (2LL + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__2];
              const double k_dof_1__1 =
                  _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                          (2LL + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__2];
              const double k_dof_2__1 =
                  _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                          (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                          ctr_0__2];
              double q_acc_0_0__1 = 0.0;
              double q_acc_1_1__1 = 0.0;
              double q_acc_2_2__1 = 0.0;
              for (int64_t q__1 = 0LL; q__1 < 1LL; q__1 += 1LL) {
                const double tmp_qloop_0__1 =
                    (k_dof_0__1 * phi_0_0__1[3LL * q__1] +
                     k_dof_1__1 * phi_0_0__1[1LL + 3LL * q__1] +
                     k_dof_2__1 * phi_0_0__1[2LL + 3LL * q__1]) *
                    q_w[q__1];
                const double q_tmp_0_0__1 =
                    tmp_qloop_0__1 * tabulated_and_untitled_0_0__1[6LL * q__1];
                const double q_tmp_1_1__1 =
                    tmp_qloop_0__1 *
                    tabulated_and_untitled_0_0__1[3LL + 6LL * q__1];
                const double q_tmp_2_2__1 =
                    tmp_qloop_0__1 *
                    tabulated_and_untitled_0_0__1[5LL + 6LL * q__1];
                q_acc_0_0__1 = q_acc_0_0__1 + q_tmp_0_0__1;
                q_acc_1_1__1 = q_acc_1_1__1 + q_tmp_1_1__1;
                q_acc_2_2__1 = q_acc_2_2__1 + q_tmp_2_2__1;
              }
              const double elMatDiag_0__1 = q_acc_0_0__1;
              const double elMatDiag_1__1 = q_acc_1_1__1;
              const double elMatDiag_2__1 = q_acc_2_2__1;
              _data_invDiag_[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) +
                             (2LL + micro_edges_per_macro_edge) * ctr_1 +
                             ctr_0__2] =
                  elMatDiag_0__1 +
                  _data_invDiag_[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) +
                                 (2LL + micro_edges_per_macro_edge) * ctr_1 +
                                 ctr_0__2];
              _data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                             (2LL + micro_edges_per_macro_edge) * ctr_1 +
                             ctr_0__2] =
                  elMatDiag_1__1 +
                  _data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                                 (2LL + micro_edges_per_macro_edge) * ctr_1 +
                                 ctr_0__2];
              _data_invDiag_[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                             (1LL + ctr_1) *
                                 (2LL + micro_edges_per_macro_edge) +
                             ctr_0__2] =
                  elMatDiag_2__1 +
                  _data_invDiag_[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                                 (1LL + ctr_1) *
                                     (2LL + micro_edges_per_macro_edge) +
                                 ctr_0__2];
            }
          }
          {
            /* FaceType.BLUE */
            {
              const double p_affine_0_0__0 =
                  macro_vertex_coord_id_0comp0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)(1LL + ctr_0__2) +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_1;
              const double p_affine_0_1__0 =
                  macro_vertex_coord_id_0comp1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)(1LL + ctr_0__2) +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_1;
              const double p_affine_1_0__0 =
                  macro_vertex_coord_id_0comp0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)ctr_0__2 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)(1LL + ctr_1);
              const double p_affine_1_1__0 =
                  macro_vertex_coord_id_0comp1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)ctr_0__2 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)(1LL + ctr_1);
              const double p_affine_2_0__0 =
                  macro_vertex_coord_id_0comp0 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)(1LL + ctr_0__2) +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp0 -
                       macro_vertex_coord_id_0comp0) *
                      (double)(1LL + ctr_1);
              const double p_affine_2_1__0 =
                  macro_vertex_coord_id_0comp1 +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_1comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)(1LL + ctr_0__2) +
                  1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                      (macro_vertex_coord_id_2comp1 -
                       macro_vertex_coord_id_0comp1) *
                      (double)(1LL + ctr_1);
              const double k_dof_0__0 =
                  _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                          (2LL + micro_edges_per_macro_edge) * ctr_1 +
                          ctr_0__2];
              const double k_dof_1__0 =
                  _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                          (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                          ctr_0__2];
              const double k_dof_2__0 =
                  _data_k[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL +
                          (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                          ctr_0__2];
              double q_acc_0_0__0 = 0.0;
              double q_acc_1_1__0 = 0.0;
              double q_acc_2_2__0 = 0.0;
              for (int64_t q__0 = 0LL; q__0 < 1LL; q__0 += 1LL) {
                const double tmp_qloop_0__0 =
                    (k_dof_0__0 * phi_0_0__0[3LL * q__0] +
                     k_dof_1__0 * phi_0_0__0[1LL + 3LL * q__0] +
                     k_dof_2__0 * phi_0_0__0[2LL + 3LL * q__0]) *
                    q_w[q__0];
                const double q_tmp_0_0__0 =
                    tmp_qloop_0__0 * tabulated_and_untitled_0_0__0[6LL * q__0];
                const double q_tmp_1_1__0 =
                    tmp_qloop_0__0 *
                    tabulated_and_untitled_0_0__0[3LL + 6LL * q__0];
                const double q_tmp_2_2__0 =
                    tmp_qloop_0__0 *
                    tabulated_and_untitled_0_0__0[5LL + 6LL * q__0];
                q_acc_0_0__0 = q_acc_0_0__0 + q_tmp_0_0__0;
                q_acc_1_1__0 = q_acc_1_1__0 + q_tmp_1_1__0;
                q_acc_2_2__0 = q_acc_2_2__0 + q_tmp_2_2__0;
              }
              const double elMatDiag_0__0 = q_acc_0_0__0;
              const double elMatDiag_1__0 = q_acc_1_1__0;
              const double elMatDiag_2__0 = q_acc_2_2__0;
              _data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                             (2LL + micro_edges_per_macro_edge) * ctr_1 +
                             ctr_0__2] =
                  elMatDiag_0__0 +
                  _data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                                 (2LL + micro_edges_per_macro_edge) * ctr_1 +
                                 ctr_0__2];
              _data_invDiag_[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                             (1LL + ctr_1) *
                                 (2LL + micro_edges_per_macro_edge) +
                             ctr_0__2] =
                  elMatDiag_1__0 +
                  _data_invDiag_[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                                 (1LL + ctr_1) *
                                     (2LL + micro_edges_per_macro_edge) +
                                 ctr_0__2];
              _data_invDiag_[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL +
                             (1LL + ctr_1) *
                                 (2LL + micro_edges_per_macro_edge) +
                             ctr_0__2] =
                  elMatDiag_2__0 +
                  _data_invDiag_[1LL - (1LL + ctr_1) * (2LL + ctr_1) / 2LL +
                                 (1LL + ctr_1) *
                                     (2LL + micro_edges_per_macro_edge) +
                                 ctr_0__2];
            }
          }
        }
      }
      {
        const int64_t ctr_0 = -1LL - ctr_1 + micro_edges_per_macro_edge;
        {
          /* FaceType.GRAY */
          {
            const double p_affine_0_0 =
                macro_vertex_coord_id_0comp0 +
                1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                    (macro_vertex_coord_id_1comp0 -
                     macro_vertex_coord_id_0comp0) *
                    (double)ctr_0 +
                1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                    (macro_vertex_coord_id_2comp0 -
                     macro_vertex_coord_id_0comp0) *
                    (double)ctr_1;
            const double p_affine_0_1 =
                macro_vertex_coord_id_0comp1 +
                1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                    (macro_vertex_coord_id_1comp1 -
                     macro_vertex_coord_id_0comp1) *
                    (double)ctr_0 +
                1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                    (macro_vertex_coord_id_2comp1 -
                     macro_vertex_coord_id_0comp1) *
                    (double)ctr_1;
            const double p_affine_1_0 =
                macro_vertex_coord_id_0comp0 +
                1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                    (macro_vertex_coord_id_1comp0 -
                     macro_vertex_coord_id_0comp0) *
                    (double)(1LL + ctr_0) +
                1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                    (macro_vertex_coord_id_2comp0 -
                     macro_vertex_coord_id_0comp0) *
                    (double)ctr_1;
            const double p_affine_1_1 =
                macro_vertex_coord_id_0comp1 +
                1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                    (macro_vertex_coord_id_1comp1 -
                     macro_vertex_coord_id_0comp1) *
                    (double)(1LL + ctr_0) +
                1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                    (macro_vertex_coord_id_2comp1 -
                     macro_vertex_coord_id_0comp1) *
                    (double)ctr_1;
            const double p_affine_2_0 =
                macro_vertex_coord_id_0comp0 +
                1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                    (macro_vertex_coord_id_1comp0 -
                     macro_vertex_coord_id_0comp0) *
                    (double)ctr_0 +
                1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                    (macro_vertex_coord_id_2comp0 -
                     macro_vertex_coord_id_0comp0) *
                    (double)(1LL + ctr_1);
            const double p_affine_2_1 =
                macro_vertex_coord_id_0comp1 +
                1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                    (macro_vertex_coord_id_1comp1 -
                     macro_vertex_coord_id_0comp1) *
                    (double)ctr_0 +
                1.0 * (1.0 / micro_edges_per_macro_edge_float) *
                    (macro_vertex_coord_id_2comp1 -
                     macro_vertex_coord_id_0comp1) *
                    (double)(1LL + ctr_1);
            const double k_dof_0 =
                _data_k[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) +
                        (2LL + micro_edges_per_macro_edge) * ctr_1 + ctr_0];
            const double k_dof_1 =
                _data_k[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                        (2LL + micro_edges_per_macro_edge) * ctr_1 + ctr_0];
            const double k_dof_2 =
                _data_k[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                        (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                        ctr_0];
            double q_acc_0_0 = 0.0;
            double q_acc_1_1 = 0.0;
            double q_acc_2_2 = 0.0;
            for (int64_t q = 0LL; q < 1LL; q += 1LL) {
              const double tmp_qloop_0 = (k_dof_0 * phi_0_0[3LL * q] +
                                          k_dof_1 * phi_0_0[1LL + 3LL * q] +
                                          k_dof_2 * phi_0_0[2LL + 3LL * q]) *
                                         q_w[q];
              const double q_tmp_0_0 =
                  tmp_qloop_0 * tabulated_and_untitled_0_0[6LL * q];
              const double q_tmp_1_1 =
                  tmp_qloop_0 * tabulated_and_untitled_0_0[3LL + 6LL * q];
              const double q_tmp_2_2 =
                  tmp_qloop_0 * tabulated_and_untitled_0_0[5LL + 6LL * q];
              q_acc_0_0 = q_acc_0_0 + q_tmp_0_0;
              q_acc_1_1 = q_acc_1_1 + q_tmp_1_1;
              q_acc_2_2 = q_acc_2_2 + q_tmp_2_2;
            }
            const double elMatDiag_0 = q_acc_0_0;
            const double elMatDiag_1 = q_acc_1_1;
            const double elMatDiag_2 = q_acc_2_2;
            _data_invDiag_[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) +
                           (2LL + micro_edges_per_macro_edge) * ctr_1 + ctr_0] =
                elMatDiag_0 +
                _data_invDiag_[-1LL * ((1LL + ctr_1) * ctr_1 / 2LL) +
                               (2LL + micro_edges_per_macro_edge) * ctr_1 +
                               ctr_0];
            _data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                           (2LL + micro_edges_per_macro_edge) * ctr_1 + ctr_0] =
                elMatDiag_1 +
                _data_invDiag_[1LL - (1LL + ctr_1) * ctr_1 / 2LL +
                               (2LL + micro_edges_per_macro_edge) * ctr_1 +
                               ctr_0];
            _data_invDiag_[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                           (1LL + ctr_1) * (2LL + micro_edges_per_macro_edge) +
                           ctr_0] =
                elMatDiag_2 +
                _data_invDiag_[-1LL * ((1LL + ctr_1) * (2LL + ctr_1) / 2LL) +
                               (1LL + ctr_1) *
                                   (2LL + micro_edges_per_macro_edge) +
                               ctr_0];
          }
        }
      }
    }
  }
}

} // namespace operatorgeneration

} // namespace hyteg
